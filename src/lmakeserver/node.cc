// This file is part of the open-lmake distribution (git@github.com:cesar-douady/open-lmake.git)
// Copyright (c) 2023-2025 Doliam
// This program is free software: you can redistribute/modify under the terms of the GPL-v3 (https://www.gnu.org/licenses/gpl-3.0.html).
// This program is distributed WITHOUT ANY WARRANTY, without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

#include "core.hh" // must be first to include Python.h first

namespace Engine {
	using namespace Disk ;
	using namespace Time ;

	//
	// NodeReqInfo
	//

	::string& operator+=( ::string& os , NodeReqInfo const& ri ) {
		/**/                          os << "NRI(" << ri.req <<','<< ri.goal <<',' ;
		if (ri.prio_idx==Node::NoIdx) os << "NoIdx"                                ;
		else                          os <<                  ri.prio_idx           ;
		if (+ri.done_               ) os <<",Done@"       << ri.done_              ;
		if ( ri.n_wait              ) os <<",wait:"       << ri.n_wait             ;
		if (+ri.overwritten         ) os <<",overwritten:"<<ri.overwritten         ;
		if (+ri.manual              ) os <<','            <<ri.manual              ;
		return                        os <<')'                                     ;
	}

	//
	// Node
	//

	Hash::Crc Node::_s_src_dirs_crc ;

	::string& operator+=( ::string& os , Node const n ) {
		/**/    os << "N(" ;
		if (+n) os << +n   ;
		return  os << ')'  ;
	}

	Hash::Crc Node::s_src_dirs_crc() {
		if (!_s_src_dirs_crc) {
			Targets   srcs = s_srcs(true/*dirs*/) ;
			Hash::Xxh h    { srcs.size() }        ;
			for( const Node s : s_srcs(true/*dirs*/) ) h += s->name() ; // ensure it works in read-only mode
			_s_src_dirs_crc = h.digest() ;
		}
		return _s_src_dirs_crc ;
	}

	//
	// NodeData
	//

	Mutex<MutexLvl::NodeCrcDate> NodeData::s_crc_date_mutex ;

	::string& operator+=( ::string& os , NodeData const& nd ) {
		/**/                    os <<'('<< nd.crc ;
		if (nd.is_plain()) {
			/**/                os <<',' << nd.date()       ;
			if (!nd.match_ok()) os << ",~job:"              ;
			/**/                os << ",job:"               ;
			/**/                os << +Job(nd.actual_job()) ;
		} else {
			/**/                os <<','<< nd.log_date()   ;
			if (nd.is_encode()) os <<','<< nd.codec_code() ;
			else                os <<','<< nd.codec_val () ;
		}
		return                  os <<')' ;
	}

	Manual NodeData::manual_wash( ReqInfo& ri , bool query , bool dangling ) {
		if (ri.manual!=Manual::Unknown) return ri.manual ;
		Req    req      = ri.req              ;
		Manual res      = manual_refresh(req) ;
		bool   stamp    = true                ;
		dangling &= !( +polluted || +actual_job() ) ; // if polluted, we have been generated by a job
		switch (res) {
			case Manual::Ok      :
			case Manual::Unlnked : break ;
			case Manual::Empty :
				if      (dangling) {}
				else if (query   ) stamp = false ;    // the final state will be to wash the file, in the mean time, dont stamp result
				else {
					Trace trace("manual_wash",idx(),"unlnk") ;
					::string n = name() ;
					SWEAR(is_lcl(n),n) ;
					unlnk(n) ;
					req->audit_node( Color::Note , "unlinked (empty)" , idx() ) ;
					res = Manual::Unlnked ;
					break ;
				}
			[[fallthrough]] ;
			case Manual::Modif : {
				Trace trace("manual_wash",idx(),"modif",STR(dangling),STR(query)) ;
				if (dangling) {
					/**/                  req->audit_node( Color::Err  , "dangling"           , idx()                                        ) ;
					if (has_actual_job()) req->audit_info( Color::Note , "generated as a side effect of "+mk_file(actual_job()->name())  , 1 ) ;
					else                  req->audit_node( Color::Note , "consider : git add" , idx()                                    , 1 ) ;
				} else if (query) {
					stamp = false ;                   // the final state will be to wash the file, in the mean time, dont stamp result
				} else {
					::string n = name() ;
					if (::rename( n.c_str() , dir_guard(QuarantineDirS+n).c_str() )==0) {
						req->audit_node( Color::Warning , "quarantined" , idx() ) ;
						res = Manual::Unlnked ;
					} else {
						req->audit_node( Color::Err , "failed to quarantine" , idx() ) ;
					}
				}
			} break ;
		DF}
		if (!query) SWEAR(stamp) ;                    // so ri.manual is guaranteed up to date after manual_wash with !query
		if (stamp) {
			if ( +res && res!=ri.manual ) Trace trace("manual_wash",idx(),"stamp",res) ;
			ri.manual = res ;
		}
		return res ;
	}

	void NodeData::_do_set_pressure( ReqInfo& ri ) const {
		g_kpi.n_node_set_pressure++ ;
		for( Job j : conform_job_tgts(ri) ) j->set_pressure(j->req_info(ri.req),ri.pressure) ; // go through current analysis level as this is where we may have deps we are waiting for
	}

	bool/*modified*/ NodeData::refresh_src_anti( bool report_no_file , ::vector<Req> const& reqs_ , ::string const& name_ ) { // reqss_ are for reporting only
		bool     prev_ok   = crc.valid() && crc.exists() ;
		bool     frozen    = idx().frozen()              ;
		::string msg       ;
		NfsGuard nfs_guard { g_config->reliable_dirs }   ;
		FileInfo fi        { nfs_guard.access(name_) }   ;
		FileSig  sig       { fi  }                       ;
		auto lazy_msg = [&]()->string const& {
			static ::string const Frozen = "frozen" ;
			static ::string const Src    = "src"    ;
			if      (+msg                        ) {}
			else if (frozen                      ) msg = Frozen ;
			else if (buildable!=Buildable::DynSrc) msg = Src    ;
			else {
				::vector<RuleTgt> v = rule_tgts().view() ; SWEAR(v.size()==1,idx(),v,status()) ;
				msg = v[0]->rule->name ;
			}
			return msg ;
		} ;
		Trace trace("refresh_src_anti",STR(report_no_file),reqs_,sig) ;
		if (frozen) for( Req r : reqs_  ) r->frozen_nodes.emplace(idx(),r->frozen_nodes.size()) ;
		if (!fi.exists()) {
			if (report_no_file) for( Req r : reqs_  ) r->audit_job( Color::Err , "missing" , lazy_msg() , name_ ) ;
			if (crc==Crc::None) return false/*updated*/ ;
			//vvvvvvvvvvvvvvvv
			refresh(Crc::None) ;
			//^^^^^^^^^^^^^^^^
		} else {
			if ( crc.valid() && sig==date().sig ) return false/*updated*/ ;
			Crc crc_ = Crc::Reg ;
			while ( +crc_ && !crc_.valid() ) crc_ = Crc( name_ , /*out*/sig ) ;                                               // ensure file is stable when computing crc
			Accesses mismatch = crc.diff_accesses(crc_) ;
			//vvvvvvvvvvvvvvvvvvv
			refresh( crc_ , sig ) ;
			//^^^^^^^^^^^^^^^^^^^
			const char* step = !prev_ok ? "new" : +mismatch ? "changed" : "steady" ;
			Color       c    = frozen ? Color::Warning : Color::HiddenOk           ;
			for( Req r : reqs() ) { ReqInfo      & ri  = req_info  (r) ; if (fi.date>r->start_ddate              ) ri.overwritten |= mismatch ;                    }
			for( Req r : reqs_  ) { ReqInfo const& cri = c_req_info(r) ; if (!cri.done(cri.goal|NodeGoal::Status)) r->audit_job( c , step , lazy_msg() , name_ ) ; }
			if (!mismatch) return false/*updated*/ ;
		}
		return true/*updated*/ ;
	}

	void NodeData::set_infinite(::vector<Node> const& deps) {
		Trace trace("set_infinite",idx(),deps) ;
		job_tgts().assign(::vector<JobTgt>({{
			Job( Special::Infinite , idx() , Deps(deps,{}/*accesses*/,{}/*dflags*/,false/*parallel*/) )
		,	true/*is_sure*/
		}})) ;
		Buildable buildable_ = Buildable::Yes ;
		for( Node const& d : deps )
			if (d->buildable==Buildable::Unknown) buildable_ &= Buildable::Maybe ; // if not computed yet, well note we do not know
			else                                  buildable_ &= d->buildable     ; // could break as soon as !Yes is seen, but this way, we can have a more agressive swear
		SWEAR(buildable_>Buildable::No) ;
		if (buildable_>=Buildable::Yes) rule_tgts().clear() ;
		buildable = buildable_ ;
		_set_match_ok() ;
	}

	::span<JobTgt const> NodeData::prio_job_tgts(RuleIdx prio_idx) const {
		if (prio_idx==NoIdx) return {} ;
		JobTgts const& jts = job_tgts() ; // /!\ jts is a Crunch vector, so if single element, a subvec would point to it, so it *must* be a ref
		if (prio_idx>=jts.size()) {
			SWEAR( prio_idx==jts.size() , prio_idx , jts.size() ) ;
			return {} ;
		}
		RuleIdx              sz   = 0                    ;
		::span<JobTgt const> sjts = jts.subvec(prio_idx) ;
		RuleIdx              prio = 0                    ;
		for( JobTgt jt : sjts ) {
			RuleIdx new_prio = jt->rule()->prio ;
			if (new_prio<prio) break ;
			prio = new_prio ;
			sz++ ;
		}
		return sjts.subspan(0,sz) ;
	}

	::span<JobTgt const> NodeData::candidate_job_tgts() const {
		RuleIdx ci = conform_idx() ;
		if (ci==NoIdx) return {} ;
		JobTgts const& jts  = job_tgts()            ; // /!\ jts is a Crunch vector, so if single element, a subvec would point to it, so it *must* be a ref
		RuleIdx        prio = jts[ci]->rule()->prio ;
		RuleIdx        idx  = ci                    ;
		for( JobTgt jt : jts.subvec(ci) ) {
			if (jt->rule()->prio<prio) break ;
			idx++ ;
		}
		return jts.subvec(0,idx) ;
	}

	struct JobTgtIter {
		// cxtors
		JobTgtIter( NodeData& n , NodeReqInfo const& ri ) : node{n} , idx{ri.prio_idx} , single{ri.single} {}
		// services
		JobTgtIter& operator++(int) {
			_prev_prio = _cur_prio() ;
			if (single) idx = node.job_tgts().size() ;
			else        idx++ ;
			return self ;
		}
		JobTgt        operator* () const { return node.job_tgts()[idx] ;                                  }
		JobTgt const* operator->() const { return node.job_tgts().begin()+idx ;                           }
		JobTgt      * operator->()       { return node.job_tgts().begin()+idx ;                           }
		operator bool           () const { return idx<node.job_tgts().size() && _cur_prio()>=_prev_prio ; }
	private :
		RuleIdx _cur_prio() const { return (*self)->rule()->prio ; }
		// data
	public :
		NodeData& node   ;
		RuleIdx   idx    = 0    /*garbage*/ ;
		bool      single = false/*garbage*/ ;
	private :
		RuleIdx _prev_prio = 0 ;
	} ;

	// check rule_tgts special rules and set rule_tgts accordingly
	Buildable NodeData::_gather_special_rule_tgts(::string const& name_) {
		job_tgts().clear() ;
		rule_tgts() = Node::s_rule_tgts(name_) ;
		//
		RuleIdx  n_skip = 0 ;
		for( RuleTgt const& rt : rule_tgts().view() ) {
			Rule r = rt->rule ; if (!r) continue ;
			if (r->special==Special::Plain                  ) { rule_tgts().shorten_by(n_skip) ; return Buildable::Maybe ; } // no special rule applies, avoid pattern matching
			if (!rt.pattern().match(name_,false/*chk_psfx*/)) { n_skip++                       ; continue                ; } // rule is pre-filtered, so no need to match prefix and suffix
			rule_tgts() = ::vector<RuleTgt>({rt}) ;
			if (r->special==Special::Anti      ) return Buildable::DynAnti ;
			if (r->special==Special::GenericSrc) return Buildable::DynSrc  ;
			FAIL("unexpected special rule",r->full_name(),r->special) ;
		}
		rule_tgts().clear() ;
		return Buildable::Maybe ;                                                                                            // node may be buildable from dir
	}

	// instantiate rule_tgts into job_tgts by taking the first iso-prio chunk and set rule_tgts accordingly
	// - special rules (always first) are already processed
	// - if a sure job is found, then all rule_tgts are consumed as there will be no further match
	Buildable NodeData::_gather_prio_job_tgts( ::string const& name_ , Req req , DepDepth lvl ) {
		//
		RuleIdx           prio       = 0                  ;                    // initially, we are ready to accept any rule
		RuleIdx           n          = 0                  ;
		Buildable         buildable  = Buildable::No      ;                    // return val if we find no job candidate
		::vector<RuleTgt> rule_tgts_ = rule_tgts().view() ;
		//
		SWEAR(is_lcl(name_),name_) ;
		::vector<JobTgt> jts ; jts.reserve(rule_tgts_.size()) ;                // typically, there is a single priority
		for( RuleTgt const& rt : rule_tgts_ ) {
			Rule r = rt->rule ; if (!r) continue ;
			SWEAR(!r->is_special()) ;
			if (r->prio<prio) goto Done ;
			if (lvl>=g_config->max_dep_depth) throw ::vector<Node>() ;         // too deep, must be an infinite dep path
			//          vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
			JobTgt jt = JobTgt(rt,name_,false/*chk_psfx*/,req,lvl+1) ;         // rule is pre-filtered, so no need to match prefix and suffix
			//          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
			if (+jt) {
				if (jt.sure()) { buildable  = Buildable::Yes   ; n = NoIdx ; } // after a sure job, we can forget about rules at lower prio
				else             buildable |= Buildable::Maybe ;
				jts.push_back(jt) ;
				prio = r->prio ;
			}
			if (n!=NoIdx) n++ ;
		}
		n = NoIdx ;                                                            // we have exhausted all rules
	Done :
		//            vvvvvvvvvvvvvvvvvvvvvvvvvvv
		if (+jts    ) job_tgts ().append    (jts) ;
		if (n==NoIdx) rule_tgts().clear     (   ) ;
		else          rule_tgts().shorten_by(n  ) ;
		//            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
		return buildable ;
	}

	void NodeData::_do_set_buildable( Req req , DepDepth lvl ) {
		Trace trace("_do_set_buildable",idx(),req,lvl) ;
		switch (buildable) {                                                                                        // ensure we do no update sources
			case Buildable::Src    :
			case Buildable::SrcDir :
			case Buildable::Anti   : SWEAR(!rule_tgts(),rule_tgts()) ; goto Return ;
			case Buildable::Decode :
			case Buildable::Encode :
			case Buildable::Loop   :                                   goto Return ;
		DN}
		status(NodeStatus::Unknown) ;
		//
		{	::string name_ = name() ;
			//
			{	Buildable buildable_ = _gather_special_rule_tgts(name_) ;
				//                                     vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
				if (buildable_<=Buildable::No      ) { buildable = Buildable::No       ; goto Return            ; } // AntiRule have priority so no warning message is generated
				if (name_.size()>g_config->path_max) {                                   throw ::vector<Node>() ; } // path is ridiculously long, pretend an infinite recursion (most probable cause)
				if (buildable_>=Buildable::Yes     ) { buildable = buildable_          ; goto Return            ; }
				//                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
			}
			buildable = Buildable::Loop ;                                     // during analysis, temporarily set buildable to break loops (will be caught at exec time) ...
			try {                                                             // ... in case of crash, rescue mode is used and ensures all matches are recomputed
				Buildable db = Buildable::No ;
				if (+dir()) {
					//vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
					dir()->set_buildable_throw(req,lvl) ;                     // dir is necessarily shorter than us, no need to increment lvl, and this is not user-visible level
					//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
					switch ((db=dir()->buildable)) {
						case Buildable::DynAnti   :
						case Buildable::Anti      :
						case Buildable::No        :
						case Buildable::Maybe     :                                    break       ;
						//                          vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
						case Buildable::Yes       : buildable = Buildable::Yes       ; goto Return ;
						case Buildable::DynSrc    :
						case Buildable::Src       :
						case Buildable::SubSrc    : buildable = Buildable::SubSrc    ; goto Return ;
						case Buildable::SrcDir    :
						case Buildable::SubSrcDir : buildable = Buildable::SubSrcDir ; goto Return ;
						//                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
					DF}
				}
				//                    vvvvvvvvvvvvvvvvvvvvvvvvv
				if (!is_lcl(name_)) { buildable = Buildable::No ; goto Return ; }
				//                    ^^^^^^^^^^^^^^^^^^^^^^^^^
				//
				Buildable buildable_ = _gather_prio_job_tgts(name_,req,lvl) ;
				if (db==Buildable::Maybe) buildable_ |= Buildable::Maybe ;    // we are at least as buildable as our dir
				//vvvvvvvvvvvvvvvvvvvv
				buildable = buildable_ ;
				//^^^^^^^^^^^^^^^^^^^^
				goto Return ;
			} catch (::vector<Node>& e) {
				buildable = Buildable::Unknown ;                              // restore Unknown as we do not want to appear as having been analyzed
				match_gen = 0                  ;
				e.push_back(idx()) ;
				throw ;
			}
		}
	Return :
		_set_match_ok() ;
		trace("done",buildable) ;
		return ;
	}

	bool/*solved*/ NodeData::_make_pre( ReqInfo& ri , bool query ) {
		Trace trace("Nmake_pre",idx(),ri) ;
		Req      req   = ri.req ;
		::string name_ ;                                                                                // lazy evaluated
		auto lazy_name = [&]()->::string const& {
			if (!name_) name_ = name() ;
			return name_ ;
		} ;
		// step 1 : handle what can be done without dir
		switch (buildable) {
			case Buildable::DynAnti :
			case Buildable::Anti    :
			case Buildable::SrcDir  :
			case Buildable::No      : status(NodeStatus::None) ; goto NoSrc ;
			case Buildable::DynSrc  :
			case Buildable::Src     : status(NodeStatus::Src ) ; goto Src   ;
			case Buildable::Decode  :
			case Buildable::Encode  : status(NodeStatus::Src ) ; goto Codec ;
			case Buildable::Unknown :                            FAIL()     ;
			default                 :                            break      ;
		}
		if (!dir()) goto NotDone ;
		// step 2 : handle what can be done without making dir
		switch (dir()->buildable) {
			case Buildable::DynAnti :
			case Buildable::Anti    :
			case Buildable::No      :                            goto NotDone ;
			case Buildable::SrcDir  : status(NodeStatus::None) ; goto Src     ;                         // status is overwritten Src if node actually exists
			default                 :                            break        ;
		}
		if ( ReqInfo& dri = dir()->req_info(req) ; !dir()->done(dri,NodeGoal::Status) ) {               // fast path : no need to call make if dir is done
			if (!dri.waiting()) {
				ReqInfo::WaitInc sav_n_wait{ri} ;                                                       // appear waiting in case of recursion loop (loop will be caught because of no job on going)
				dir()->asking = idx() ;
				//vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
				dir()->make( dri , query?MakeAction::Query:MakeAction::Status , ri.speculate ) ;
				//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
			}
			trace("dir",dir(),STR(dir()->done(dri,NodeGoal::Status)),ri) ;
			//
			if (dri.waiting()) {
				dir()->add_watcher(dri,idx(),ri,ri.pressure) ;
				status(NodeStatus::Uphill) ;                                                            // temporarily, until dir() is built and we know the definitive answer
				goto NotDone ;                                                                          // return value is meaningless when waiting
			}
			if ( query && !dir()->done(dri) ) { trace("query","dir") ; return false ; }
			SWEAR(dir()->done(dri)) ;                                                                   // after having called make, dep must be either waiting or done
		}
		// step 3 : handle what needs dir status
		switch (dir()->buildable) {
			case Buildable::Maybe :
				if (dir()->status()==NodeStatus::None) { status(NodeStatus::Unknown) ; goto NotDone ; } // not Uphill anymore
				[[fallthrough]] ;
			case Buildable::Yes :
				if (buildable==Buildable::Maybe) buildable = Buildable::Yes ;                           // propagate as dir->buildable may have changed from Maybe to Yes when made
				[[fallthrough]] ;
			case Buildable::SubSrc    :
			case Buildable::SubSrcDir :
				switch (dir()->status()) {
					case NodeStatus::Transient :                              goto Transient ;          // forward
					case NodeStatus::Uphill    : status(NodeStatus::Uphill) ; goto NoSrc     ;          // .
				DN}
			break ;
		DN}
		// step 4 : handle what needs dir crc
		switch (dir()->buildable) {
			case Buildable::Maybe :
			case Buildable::Yes   :
				if (dir()->crc==Crc::None) { status(NodeStatus::Unknown) ; goto NotDone ; }             // uphill is buildable, but does not actually exist
				goto DirSrc ;
			case Buildable::SubSrcDir :
				if (dir()->crc==Crc::None) { status(NodeStatus::None   ) ; goto Src     ; }             // status is overwritten Src if node actually exists
				[[fallthrough]] ;
			case Buildable::DynSrc :
			case Buildable::Src    :
			DirSrc :
				if (dir()->crc.is_lnk()) goto Transient ;                                               // our dir is a link, we are transient
				status(NodeStatus::Uphill) ;                                                            // a non-existent source stays a source, hence its sub-files are uphill
				goto NoSrc ;
		DF}
		FAIL() ;
	Codec :
		{	SWEAR(crc.valid()) ;
			if (!Codec::refresh(+idx(),+ri.req)) status(NodeStatus::None) ;
			if (log_date()>req->start_ddate    ) ri.overwritten = Access::Reg ;                         // date is only updated when actual content is modified and codec cannot be links
			trace("codec",ri.overwritten) ;
			goto DoneDsk ;
		}
		FAIL() ;
	Src :
		{	bool modified = refresh_src_anti( status()!=NodeStatus::None , {req} , lazy_name() ) ;
			if      (crc            !=Crc::None) status(NodeStatus::Src) ;                              // overwrite status if it was pre-set to None
			else if (status()==NodeStatus::None) goto NoSrc ;                                           // if status was pre-set to None, it means we accept NoSrc
			if      (modified                  ) actual_job() = {} ;
			/**/                                 goto DoneDsk ;                                         // sources are always done on disk, as it is by probing it that we are done
		}
		FAIL() ;
	Transient :
		{	refresh(Crc::Unknown) ;                                                                     // if depending on a transient node, a job must be rerun in all cases
			status(NodeStatus::Transient) ;
			actual_job() = {} ;
			goto DoneDsk ;
		}
		FAIL() ;
	NoSrc :
		{	if (ri.goal>=NodeGoal::Dsk) {
				Manual manual = manual_wash(ri,query,true/*dangling*/) ;                                // always check manual if asking for disk
				trace("no_src",ri.goal,crc,manual,actual_job()) ;
				if (crc!=Crc::None) {
					if (manual==Manual::Ok) {                                                           // if already unlinked, no need to unlink it again
						SWEAR(is_lcl(lazy_name()),lazy_name()) ;
						if (query) { trace("query","unlnk") ; return false ; }
						unlnk(lazy_name(),true/*dir_ok*/) ;                                             // wash pollution if not manual
						req->audit_job( Color::Warning , "unlink" , "no_rule" , lazy_name() ) ;
					}
					refresh(Crc::None) ;                                                                // if not physically unlinked, node will be manual
					actual_job() = {} ;
				}
				goto DoneDsk ;
			} else {
				trace("no_src",ri.goal,crc,actual_job()) ;
				if (crc!=Crc::None) {
					refresh(Crc::None) ;                                                                // if not physically unlinked, node will be manual
					if (+actual_job()) {
						polluted      = Polluted::Job ;                                                 // disk has been modified, actual_job cannot be the official job
						polluting_job = actual_job()  ;
					}
					actual_job() = {} ;
				}
				goto Done ;
			}
		}
		FAIL() ;
	Done :
		ri.done_ = ri.goal ;
		goto NotDone ;
		FAIL() ;
	DoneDsk :
		ri.done_ = NodeGoal::Dsk   ;                                                                    // disk is de facto updated
		polluted = Polluted::Clean ;
	NotDone :
		trace("done",idx(),status(),crc,ri) ;
		return true ;
	}

	static bool _may_need_regenerate( NodeData const& nd , NodeReqInfo& ri , NodeMakeAction make_action ) {
		/**/                                if (make_action==NodeMakeAction::Wakeup               ) return false ;                 // do plain analysis
		/**/                                if (!ri.done(NodeGoal::Status)                        ) return false ;                 // do plain analysis
		JobTgt cjt = nd.conform_job_tgt() ; if (!( +cjt && cjt.produces(nd.idx(),true/*actual*/) )) return false ;                 // no hope to regenerate, proceed normally
		/**/                                if ( +nd.polluted || nd.busy                          ) ri.done_ &= NodeGoal::Status ; // disk cannot be ok if node was polluted or is busy, ...
		/**/                                if (ri.done()                                         ) return false ;                 // ... does not change conform_job_tgt()
		Trace trace("_may_need_regenerate",nd.idx(),ri,cjt,nd.polluted) ;
		ri.prio_idx = nd.conform_idx() ;                                                                                           // ask to run only conform job
		ri.single   = true             ;                                                                                           // .
		return true ;
	}
	void NodeData::_do_make( ReqInfo& ri , MakeAction make_action , Bool3 speculate ) {
		RuleIdx            prod_idx       = NoIdx                              ;
		Req                req            = ri.req                             ;
		Bool3              clean          = Maybe                              ;                                                   // lazy evaluate manual()==No
		::array<RuleIdx,2> multi          = {NoIdx,NoIdx}                      ;
		bool               stop_speculate = speculate<ri.speculate && +ri.goal ;
		bool               query          = make_action==MakeAction::Query     ;
		bool               first          = true                               ;                                                   // anti infinite loop : may only regenerate once
		Trace trace("Nmake",idx(),ri,make_action) ;
		ri.speculate &= speculate ;
		//vvvvvvvvvvvvvvvv
		set_buildable(req) ;
		//^^^^^^^^^^^^^^^^
		if (make_action==MakeAction::Wakeup) ri.dec_wait() ;
		else                                 ri.goal = ri.goal | mk_goal(make_action) ;
		if      ( ri.waiting()             ) goto Wait ;
		else if ( req.zombie()             ) ri.done_ |= NodeGoal::Dsk ;
		//
		if (ri.prio_idx==NoIdx) {
			if (ri.done()) goto Wakeup ;
			//            vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
			bool solved = _make_pre( ri, make_action==MakeAction::Query ) ;
			//            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
			if (!solved     ) { SWEAR(query) ; goto Wait   ; }
			if (ri.waiting())                  goto Wait   ;
			if (ri.done()   )                  goto Wakeup ;
			ri.prio_idx = 0 ;
		} else {
			if ( _may_need_regenerate(self,ri,make_action) ) goto Make   ;
			if ( ri.done()                                 ) goto Wakeup ;
			// fast path : check jobs we were waiting for, lighter than full analysis
			JobTgtIter it{self,ri} ;
			for(; it ; it++ ) {
				JobTgt jt   = *it                        ;
				bool   done = jt->c_req_info(req).done() ;
				trace("check",jt,jt->c_req_info(req)) ;
				if (!done             ) { prod_idx = NoIdx ; goto Make ;                                            }              // we waited for it and it is not done, retry
				if (jt.produces(idx())) { if (prod_idx==NoIdx) prod_idx = it.idx ; else multi = {prod_idx,it.idx} ; }              // jobs in error are deemed to produce all their potential targets
			}
			if (prod_idx!=NoIdx) goto DoWakeup ;                                             // we have at least one done job, no need to investigate any further
			if (ri.single) ri.single   = false  ;                                            // if regenerating but job does not generate us, something strange happened, retry this prio
			else           ri.prio_idx = it.idx ;                                            // else go on with next prio
		}
	Make :
		g_kpi.n_node_make++ ;
		SWEAR(prod_idx==NoIdx,prod_idx) ;
		for(;; first=false ) {
			for (;;) {
				SWEAR(ri.prio_idx!=NoIdx) ;
				if (ri.prio_idx>=job_tgts().size()) {                                        // gather new job_tgts from rule_tgts
					SWEAR(!ri.single) ;                                                      // we only regenerate using an existing job
					try {
						//                      vvvvvvvvvvvvvvvvvvvvvvvvvv
						buildable = buildable | _gather_prio_job_tgts(req) ;
						//                      ^^^^^^^^^^^^^^^^^^^^^^^^^^
						if (ri.prio_idx>=job_tgts().size()) break ;                          // fast path
					} catch (::vector<Node> const& e) {
						set_infinite(e) ;
						break ;
					}
				}
				if (!ri.single) {                                                            // fast path : cannot have several jobs if we consider only a single job
					for( JobTgtIter it{self,ri} ; it ; it++ ) {                              // check if we obviously have several jobs, in which case make nothing
						JobTgt jt = *it ;
						if      ( jt.sure()                 )   buildable = Buildable::Yes ; // buildable is data independent & pessimistic (may be Maybe instead of Yes)
						else if (!jt->c_req_info(req).done())   continue ;
						else if (!jt.produces(idx())        )   continue ;
						if      (prod_idx!=NoIdx            ) { multi = {prod_idx,it.idx} ; goto DoWakeup ; }
						prod_idx = it.idx ;
					}
					prod_idx = NoIdx ;
				}
				// make eligible jobs
				JobTgtIter it { self , ri } ;
				{	ReqInfo::WaitInc sav_n_wait{ri} ;                                        // ensure we appear waiting while making jobs to block loops (caught in Req::chk_end)
					for(; it ; it++ ) {
						JobTgt      jt     = *it               ;
						JobReason   reason ;
						JobReqInfo& jri    = jt->req_info(req) ;
						if (busy) {
								/**/                      reason = {JobReasonTag::BusyTarget    ,+idx()} ;
						} else if (+polluted) {
							if (crc==Crc::None) {
								/**/                      reason = {JobReasonTag::NoTarget      ,+idx()} ;
							} else switch (polluted) {
								case Polluted::Old      : reason = {JobReasonTag::OldTarget     ,+idx()} ; break ;
								case Polluted::PreExist : reason = {JobReasonTag::PrevTarget    ,+idx()} ; break ;
								case Polluted::Job      : reason = {JobReasonTag::PollutedTarget,+idx()} ; break ;                          // polluting job is already set
							DF}
						} else if (ri.goal!=NodeGoal::Status) {                                                                             // dont check disk if asked for Status
							if (jt->running(true/*with_zombies*/))
								/**/                      reason = {JobReasonTag::BusyTarget    ,+idx()} ;
							else switch (manual_wash(ri,false/*query*/,false/*dangling*/)) {
								case Manual::Ok         :                                                  break ;
								case Manual::Unlnked    : reason = {JobReasonTag::NoTarget      ,+idx()} ; break ;
								case Manual::Empty      :
								case Manual::Modif      : reason = {JobReasonTag::ManualTarget  ,+idx()} ; break ;
							DF}
						}
						if ( !reason && !has_actual_job(jt) && jt.produces(idx(),true/*actual*/) ) {                                        // ensure we dont let go a node with the wrong job
								if (has_actual_job())   { reason = {JobReasonTag::PollutedTarget,+idx()} ; polluting_job = actual_job() ; }
								else                      reason = {JobReasonTag::NoTarget      ,+idx()} ;
						}
						if (ri.live_out) jri.live_out = ri.live_out ;                                                              // transmit user request to job for last level live output
						jt->asking = idx() ;
						//                vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
						if      (!query ) jt->make( jri , JobMakeAction::Status , reason , ri.speculate ) ;
						else if (!reason) jt->make( jri , JobMakeAction::Query  , reason , ri.speculate ) ;                        // if we have a reason to run job, answer to query is known
						//                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
						trace("job",ri,clean,STR(query),jt,STR(jri.waiting()),STR(jt.produces(idx())),polluted,STR(busy)) ;
						if      (jri.waiting()     )   jt->add_watcher(jri,idx(),ri,ri.pressure) ;
						else if (!jri.done()       ) { SWEAR(query) ; goto Wait ;                                                }
						else if (jt.produces(idx())) { if (prod_idx==NoIdx) prod_idx = it.idx ; else multi = {prod_idx,it.idx} ; } // jobs in error are deemed to produce all their potential targets
					}
				}
				if (ri.waiting()   ) goto Wait ;
				if (prod_idx!=NoIdx) break     ;
				ri.prio_idx = it.idx ;
			}
		DoWakeup :
			if (prod_idx==NoIdx) {
				if ( ri.goal==NodeGoal::Dsk && !query ) manual_wash(ri,false/*query*/,true/*dangling*/) ; // no producing job, check for dangling if asked to do so
				status(NodeStatus::None) ;
			} else if (multi[0]!=NoIdx) {
				SWEAR(multi[1]!=NoIdx) ;                                                                  // both must contain a valid index or none of them
				status(NodeStatus::Multi) ;
				trace("multi",ri,multi) ;
				/**/                     req->audit_node(Color::Err ,"multi",idx()                       ) ;
				/**/                     req->audit_info(Color::Note,"at least 2 rules match :"        ,1) ;
				for( RuleIdx i : multi ) req->audit_info(Color::Note,job_tgts()[i]->rule()->full_name(),2) ;
			} else {
				conform_idx(prod_idx) ;
			}
			ri.done_ = ri.goal ;
			if (!_may_need_regenerate(self,ri,make_action)) break ;
			SWEAR(first) ;                                                                                // avoid infinite loop : we should not need to regenerate more than once
			prod_idx = NoIdx ;
		}
	Wakeup :
		SWEAR(done(ri)) ;
		trace("wakeup",ri,conform_idx(),is_plain()?actual_job():Job()) ;
		ri.wakeup_watchers() ;
	Wait :
		if (stop_speculate) _propag_speculate(ri) ;
		trace("done",ri) ;
	}

	void NodeData::_propag_speculate(ReqInfo const& cri) const {
		switch (status()) {
			case NodeStatus::Uphill    :
			case NodeStatus::Transient : { Node n = dir()             ;         n->propag_speculate( cri.req , cri.speculate ) ; } break ;
			case NodeStatus::Plain     : { Job  j = conform_job_tgt() ;         j->propag_speculate( cri.req , cri.speculate ) ; } break ;
			case NodeStatus::Multi     : { for( Job j : conform_job_tgts(cri) ) j->propag_speculate( cri.req , cri.speculate ) ; } break ;
			case NodeStatus::Unknown   :                                                                                           break ; // node is not built, nowhere to propagate
			default :
				SWEAR(status()<NodeStatus::Uphill,status()) ;                                                                              // ensure we have not forgotten a case
		}
	}

	bool/*ok*/ NodeData::forget( bool targets , bool deps ) {
		Trace trace("Nforget",idx(),STR(targets),STR(deps),STR(waiting()),conform_job_tgts()) ;
		if (waiting()) return false ;
		//
		bool    res  = true ;
		RuleIdx k    = 0    ;
		RuleIdx prio = 0    ;
		for( Job j : job_tgts() ) {
			RuleIdx p = j->rule()->prio ;
			if (p<prio) break ;              // all jobs above or besides conform job(s)
			res &= j->forget(targets,deps) ;
			if (k==conform_idx()) prio = p ;
			k++ ;
		}
		match_gen = 0 ;
		return res ;
	}

	void NodeData::mk_old() {
		Trace trace("mk_old",idx()) ;
		busy      = false ;           // possibly old
		match_gen = 0     ;
	}

	void NodeData::mk_no_src() {
		Trace trace("mk_no_src",idx()) ;
		buildable = Buildable::Unknown ;
		match_gen = 0                  ;
		fence() ;
		rule_tgts ().clear() ;
		job_tgts  ().clear() ;
		actual_job().clear() ;
		refresh() ;
	}

	void NodeData::mk_src(Buildable b) {
		Trace trace("mk_src",idx()) ;
		buildable = b ;
		fence() ;
		rule_tgts ().clear() ;
		job_tgts  ().clear() ;
		actual_job().clear() ;
		_set_match_ok() ;
	}

	void NodeData::mk_src(FileTag tag) {
		Trace trace("mk_src",idx(),tag) ;
		switch (tag) {
			case FileTag::None  : mk_src(Buildable::Anti  ) ;                      break ;
			case FileTag::Dir   : mk_src(Buildable::SrcDir) ;                      break ;
			case FileTag::Empty : mk_src(Buildable::Src   ) ; tag = FileTag::Reg ; break ; // do not remember file is empty, so it is marked new instead of steady/changed when first seen
			default             : mk_src(Buildable::Src   ) ;                      break ;
		}
		refresh(tag) ;
	}

	bool/*modified*/ NodeData::refresh( Crc crc_ , SigDate const& sd ) {
		bool modified = !crc.match(crc_) ;
		//
		Trace trace( "refresh" , STR(modified) , idx() , reqs() , crc ,"->", crc_ , date() ,"->", sd ) ;
		//
		{	Lock lock { s_crc_date_mutex } ;
			if (modified) crc_date(crc_,sd) ;
			else          date() = sd ;
		}
		for( Req r : reqs() ) {
			ReqInfo& ri = req_info(r) ;
			if (modified) ri.done_  &= NodeGoal::Status ; // target is not conform on disk any more
			if (+sd     ) ri.manual  = Manual::Ok       ; // if we passed a sig, we know the disk state, and we just updated our records
		}
		return modified ;
	}

	static ::pair<Manual,bool/*refreshed*/> _manual_refresh( NodeData& nd , FileSig const& sig ) {
		Manual m = nd.manual(sig) ;
		if (m<Manual::Changed) return {m,false/*refreshed*/} ;      // file was not modified
		if (nd.crc==Crc::None) return {m,false/*refreshed*/} ;      // file appeared, it cannot be steady
		//
		::string ndn = nd.name() ;
		if ( m==Manual::Empty && nd.crc==Crc::Empty ) {             // fast path : no need to open file
			nd.date() = FileSig(ndn) ;
		} else {
			FileSig sig ;
			Crc     crc { ndn , /*out*/sig } ;
			if (!nd.crc.match(crc)) return {m,false/*refreshed*/} ; // real modif
			nd.date() = sig ;
		}
		return {Manual::Ok,true/*refreshed*/} ;                     // file is steady
	}
	Manual NodeData::manual_refresh( Req req , FileSig const& sig ) {
		auto [m,refreshed] = _manual_refresh(self,sig) ;
		if ( refreshed && +req ) req->audit_node(Color::Note,"manual_steady",idx()) ;
		return m ;
	}
	Manual NodeData::manual_refresh( JobData const& j , FileSig const& sig ) {
		auto [m,refreshed] = _manual_refresh(self,sig) ;
		if (refreshed) for( Req r : j.reqs() ) r->audit_node(Color::Note,"manual_steady",idx()) ;
		return m ;
	}

	//
	// Target
	//

	::string& operator+=( ::string& os , Target const t ) {
		/**/           os << "T("         ;
		if (+t       ) os << +t           ;
		if (+t.tflags) os <<','<<t.tflags ;
		return         os << ')'          ;
	}


	//
	// Dep
	//

	::string& operator+=( ::string& os , Dep const& d ) {
		return os << static_cast<DepDigestBase<Node> const&>(d) ;
	}

	::string& operator+=( ::string& os , GenericDep const& gd ) {
		os << "GenericDep(" ;
		if (gd.hdr.sz) {
			os << gd.hdr.chunk_accesses            <<',' ;
			os << ::span((&gd)[1].chunk,gd.hdr.sz) <<',' ;
		}
		os << gd.hdr ;
		return os << ')' ;
	}

	::string Dep::accesses_str() const {
		::string res ; res.reserve(N<Access>) ;
		for( Access a : iota(All<Access>) ) res.push_back( accesses[a] ? AccessChars[+a].second : '-' ) ; // NOLINT(clang-analyzer-core.CallAndMessage) XXX! : for some reason, clang-tidy fires up here
		return res ;
	}

	::string Dep::dflags_str() const {
		::string res ; res.reserve(N<Dflag>) ;
		for( Dflag df : iota(All<Dflag>) ) res.push_back( dflags[df] ? DflagChars[+df].second : '-' ) ;
		return res ;
	}

	//
	// Deps
	//

	::string& operator+=( ::string& os , DepsIter::Digest const& did ) {
		return os <<'('<< did.hdr <<','<< did.i_chunk <<')'  ;
	}

	static void _append_dep( ::vector<GenericDep>& deps , Dep const& dep , size_t& hole ) {
		bool can_compress = dep.is_crc && dep.crc()==Crc::None && !dep.dflags && !dep.parallel ;
		if (hole==Npos) {
			if (can_compress) {                                                                       // create new open chunk
				/**/ hole                         = deps.size()             ;
				Dep& hdr                          = deps.emplace_back().hdr ;
				/**/ hdr.sz                       = 1                       ;
				/**/ hdr.chunk_accesses           = dep.accesses            ;
				/**/ deps.emplace_back().chunk[0] = dep                     ;
			} else {                                                                                  // create a chunk just for dep
				deps.push_back(dep) ;
				deps.back().hdr.sz             = 0  ;                                                 // dep may have a non-null sz (which is not significant as far as the dep alone is concerned)
				deps.back().hdr.chunk_accesses = {} ;                                                 // useless, just to avoid a random value hanging around
			}
		} else {
			Dep& hdr = deps[hole].hdr ;
			if ( can_compress && dep.accesses==hdr.chunk_accesses && hdr.sz<lsb_msk(Dep::NSzBits) ) { // append dep to open chunk
				uint8_t i = hdr.sz%GenericDep::NodesPerDep ;
				if (i==0) deps.emplace_back() ;
				deps.back().chunk[i] = dep ;
				hdr.sz++ ;
			} else {                                                                                  // close chunk : copy dep to hdr, excetp sz and chunk_accesses fields
				uint8_t  sz                 = hdr.sz             ;
				Accesses chunk_accesses     = hdr.chunk_accesses ;
				/**/     hdr                = dep                ;
				/**/     hdr.sz             = sz                 ;
				/**/     hdr.chunk_accesses = chunk_accesses     ;
				/**/     hole               = Npos               ;
			}
		}
	}

	static void _fill_hole(GenericDep& hdr) {
		SWEAR(hdr.hdr.sz!=0) ;
		uint8_t  sz                     = hdr.hdr.sz-1                                                 ;
		Accesses chunk_accesses         = hdr.hdr.chunk_accesses                                       ;
		/**/     hdr.hdr                = { (&hdr)[1].chunk[sz] , hdr.hdr.chunk_accesses , Crc::None } ;
		/**/     hdr.hdr.sz             = sz                                                           ;
		/**/     hdr.hdr.chunk_accesses = chunk_accesses                                               ;
	}
	static void _fill_hole( ::vector<GenericDep>& deps , size_t hole ) {
		if (hole==Npos) return ;
		GenericDep& d = deps[hole] ;
		_fill_hole(d) ;
		if (d.hdr.sz%GenericDep::NodesPerDep==0) deps.pop_back() ;
	}

	void Deps::_chk( ::vector<Node> const& deps , size_t is_tail ) {
		::vector<Node> stored ; for( Dep const& d : self ) stored.push_back(d) ;
		if (is_tail) SWEAR(stored.size()>=deps.size(),stored.size(),deps.size()) ;
		else         SWEAR(stored.size()==deps.size(),stored.size(),deps.size()) ;
		for( size_t i : iota(deps.size())) SWEAR(deps[i]==stored[i+stored.size()-deps.size()],i,deps,stored) ;
	}

	Deps::Deps(::vmap<Node,Dflags> const& deps , Accesses accesses , bool parallel ) {
		::vector<GenericDep> ds   ;        ds.reserve(deps.size()) ;                   // reserving deps.size() is comfortable and guarantees no reallocaiton
		size_t               hole = Npos ;
		for( auto const& [d,df] : deps ) _append_dep( ds , {d,accesses,df,parallel} , hole ) ;
		_fill_hole(ds,hole) ;
		self = {ds} ;
	}

	Deps::Deps( ::vector<Node> const& deps , Accesses accesses , Dflags dflags , bool parallel ) {
		::vector<GenericDep> ds   ;        ds.reserve(deps.size()) ;                               // reserving deps.size() is comfortable and guarantees no reallocaiton
		size_t               hole = Npos ;
		for( auto const& d : deps ) _append_dep( ds , {d,accesses,dflags,parallel} , hole ) ;
		_fill_hole(ds,hole) ;
		self = {ds} ;
	}

	void Deps::assign(::vector<Dep> const& deps) {
		::vector<GenericDep> ds   ;        ds.reserve(deps.size()) ; // reserving deps.size() is comfortable and guarantees no reallocaiton
		size_t               hole = Npos ;
		for( auto const& d : deps ) _append_dep( ds , d , hole ) ;
		_fill_hole(ds,hole) ;
		DepsBase::assign(ds) ;
	}

	void Deps::replace_tail( DepsIter it , ::vector<Dep> const& deps ) {
		SWEAR(it!=end()) ;                                                          // else current chunk is already closed
		// close current chunk
		GenericDep* cur_dep = const_cast<GenericDep*>(it.hdr) ;
		cur_dep->hdr.sz = it.i_chunk ;
		if (it.i_chunk!=0) {
			_fill_hole(*cur_dep) ;
			cur_dep = cur_dep->next() ;
		}
		// create new tail
		::vector<GenericDep> ds   ;
		size_t               hole = Npos ;
		for( auto const& d : deps ) _append_dep( ds , d , hole ) ;
		_fill_hole(ds,hole) ;
		// splice it
		NodeIdx tail_sz = items()+DepsBase::size()-cur_dep ;
		if (ds.size()<=tail_sz) {
			for( GenericDep const& d : ds ) *cur_dep++ = d ;                        // copy all
			shorten_by(tail_sz-ds.size()) ;                                         // and shorten
		} else {
			for( GenericDep const& d : ::span(ds.data(),tail_sz) ) *cur_dep++ = d ; // copy what can be fitted
			append(::span( &ds[tail_sz] , ds.size()-tail_sz ) ) ;                   // and append for the remaining
		}
	}

}
