// This file is part of the open-lmake distribution (git@github.com:cesar-douady/open-lmake.git)
// Copyright (c) 2023-2025 Doliam
// This program is free software: you can redistribute/modify under the terms of the GPL-v3 (https://www.gnu.org/licenses/gpl-3.0.html).
// This program is distributed WITHOUT ANY WARRANTY, without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

#include "core.hh" // /!\ must be first to include Python.h first

namespace Engine {
	using namespace Disk ;
	using namespace Time ;

	//
	// NodeReqInfo
	//

	::string& operator+=( ::string& os , NodeReqInfo const& ri ) {                   // START_OF_NO_COV
		/**/                          os << "NRI(" << ri.req <<','<< ri.goal <<',' ;
		if (ri.prio_idx==Node::NoIdx) os << "NoIdx"                                ;
		else                          os <<                  ri.prio_idx           ;
		if (+ri.done_               ) os <<",Done@"       << ri.done_              ;
		if ( ri.n_wait              ) os <<",wait:"       << ri.n_wait             ;
		if (+ri.overwritten         ) os <<",overwritten:"<<ri.overwritten         ;
		if (+ri.manual              ) os <<','            <<ri.manual              ;
		return                        os <<')'                                     ;
	}                                                                                // END_OF_NO_COV

	//
	// Node
	//

	Hash::Crc Node::_s_src_dirs_crc ;

	::string& operator+=( ::string& os , Node const n ) { // START_OF_NO_COV
		/**/    os << "N(" ;
		if (+n) os << +n   ;
		return  os << ')'  ;
	}                                                     // END_OF_NO_COV

	Hash::Crc Node::s_src_dirs_crc() {
		if (!_s_src_dirs_crc) {
			Targets   srcs = s_srcs(true/*dirs*/) ;
			Hash::Xxh h    { srcs.size() }        ;
			for( const Node s : s_srcs(true/*dirs*/) ) h += s->name() ; // ensure it works in read-only mode
			_s_src_dirs_crc = h.digest() ;
		}
		return _s_src_dirs_crc ;
	}

	//
	// NodeData
	//

	Mutex<MutexLvl::NodeCrcDate> NodeData::s_crc_date_mutex ;

	::string& operator+=( ::string& os , NodeData const& nd ) { // START_OF_NO_COV
		/**/                    os <<'('<< nd.crc ;
		if (nd.is_plain()) {
			/**/                os <<',' << nd.date()       ;
			if (!nd.match_ok()) os << ",~job:"              ;
			/**/                os << ",job:"               ;
			/**/                os << +Job(nd.actual_job()) ;
		} else {
			/**/                os <<','<< nd.log_date()   ;
			if (nd.is_encode()) os <<','<< nd.codec_code() ;
			else                os <<','<< nd.codec_val () ;
		}
		return                  os <<')' ;
	}                                                           // END_OF_NO_COV

	Manual NodeData::manual_wash( ReqInfo& ri , bool query , bool dangling ) {
		if (ri.manual!=Manual::Unknown) return ri.manual ;
		Req    req      = ri.req              ;
		Manual res      = manual_refresh(req) ;
		bool   stamp    = true                ;
		dangling &= !( +polluted || +actual_job() ) ; // if polluted, we have been generated by a job
		switch (res) {
			case Manual::Ok      :
			case Manual::Unlnked : break ;
			case Manual::Empty :
				if      (dangling) {}
				else if (query   ) stamp = false ;    // the final state will be to wash the file, in the mean time, dont stamp result
				else {
					Trace trace("manual_wash",idx(),"unlnk") ;
					::string n = name() ;
					SWEAR(is_lcl(n),n) ;
					unlnk(n) ;
					req->audit_node( Color::Note , "unlinked (empty)" , idx() ) ;
					res = Manual::Unlnked ;
					break ;
				}
			[[fallthrough]] ;
			case Manual::Modif : {
				Trace trace("manual_wash",idx(),"modif",STR(dangling),STR(query)) ;
				if (dangling) {
					/**/                  req->audit_node( Color::Err  , "dangling"           , idx()                                        ) ;
					if (has_actual_job()) req->audit_info( Color::Note , "generated as a side effect of "+mk_file(actual_job()->name())  , 1 ) ;
					else                  req->audit_node( Color::Note , "consider : git add" , idx()                                    , 1 ) ;
				} else if (query) {
					stamp = false ;                   // the final state will be to wash the file, in the mean time, dont stamp result
				} else {
					::string n = name() ;
					if (::rename( n.c_str() , dir_guard(QuarantineDirS+n).c_str() )==0) {
						req->audit_node( Color::Warning , "quarantined" , idx() ) ;
						res = Manual::Unlnked ;
					} else {
						req->audit_node( Color::Err , "failed to quarantine" , idx() ) ;
					}
				}
			} break ;
		DF}                                           // NO_COV
		if (!query) SWEAR(stamp) ;                    // so ri.manual is guaranteed up to date after manual_wash with !query
		if (stamp) {
			if ( +res && res!=ri.manual ) Trace trace("manual_wash",idx(),"stamp",res) ;
			ri.manual = res ;
		}
		return res ;
	}

	void NodeData::_do_set_pressure( ReqInfo& ri ) const {
		g_kpi.n_node_set_pressure++ ;
		for( Job j : conform_job_tgts(ri) ) j->set_pressure(j->req_info(ri.req),ri.pressure) ; // go through current analysis level as this is where we may have deps we are waiting for
	}

	bool/*modified*/ NodeData::refresh_src_anti( bool report_no_file , ::vector<Req> const& reqs_ , ::string const& name_ ) { // reqss_ are for reporting only
		bool             prev_ok   = crc.valid() && crc.exists() ;
		bool             frozen    = idx().frozen()              ;
		::string/*lazy*/ msg       ;
		NfsGuard         nfs_guard { g_config->file_sync     }   ;
		FileInfo         fi        { nfs_guard.access(name_) }   ;
		FileSig          sig       { fi                      }   ;
		auto lazy_msg = [&]()->string const& {
			static ::string const Frozen = "frozen" ;
			static ::string const Src    = "src"    ;
			if (!msg) {
				if      (frozen                      )                                                                                    msg = Frozen           ;
				else if (buildable!=Buildable::DynSrc)                                                                                    msg = Src              ;
				else                                   { ::vector<RuleTgt> v = rule_tgts().view() ; SWEAR(v.size()==1,idx(),v,status()) ; msg = v[0]->rule->name ; }
			}
			return msg ;
		} ;
		Trace trace("refresh_src_anti",idx(),STR(report_no_file),reqs_,sig) ;
		if (frozen) for( Req r : reqs_ ) r->frozen_nodes.push(idx()) ;
		if (!fi.exists()) {
			if (report_no_file) for( Req r : reqs_  ) r->audit_job( Color::Err , "missing" , lazy_msg() , name_ ) ;
			if (crc==Crc::None) return false/*updated*/ ;
			//vvvvvvvvvvvvvvvv
			refresh(Crc::None) ;
			//^^^^^^^^^^^^^^^^
		} else {
			if ( crc.valid() && sig==date().sig ) return false/*updated*/ ;
			Crc crc_ = Crc::Reg ;
			while ( +crc_ && !crc_.valid() ) crc_ = Crc( name_ , /*out*/sig ) ;                                               // ensure file is stable when computing crc
			Accesses mismatch = crc.diff_accesses(crc_) ;
			//vvvvvvvvvvvvvvvvvvv
			refresh( crc_ , sig ) ;
			//^^^^^^^^^^^^^^^^^^^
			const char* step = !prev_ok ? "new" : +mismatch ? "changed" : "steady" ;
			Color       c    = frozen ? Color::Warning : Color::HiddenOk           ;
			for( Req r : reqs() ) { ReqInfo      & ri  = req_info  (r) ; if (fi.date>r->start_ddate                     ) ri.overwritten |= mismatch ;                    }
			for( Req r : reqs_  ) { ReqInfo const& cri = c_req_info(r) ; if (!cri.done(::max(cri.goal,NodeGoal::Status))) r->audit_job( c , step , lazy_msg() , name_ ) ; }
			if (!mismatch) return false/*updated*/ ;
		}
		return true/*updated*/ ;
	}

	void NodeData::set_infinite( Special s , ::vector<Node> const& deps ) {
		Trace trace("set_infinite",idx(),buildable,s,deps) ;
		if (buildable>Buildable::No) {
			job_tgts().assign(::vector<JobTgt>({{
				Job( s , idx() , Deps(deps,{}/*accesses*/,{}/*dflags*/,false/*parallel*/) )
			,	true/*is_sure*/
			}})) ;
			n_job_tgts = 1 ;
			buildable = Buildable::Yes ;
			for( Node const& d : deps )
				switch (d->buildable) {
					case Buildable::Unknown     :
					case Buildable::PathTooLong : break ;
					default                     : buildable = ::min(buildable,d->buildable) ;
				}
		}
		rule_tgts().clear() ;
		_set_match_ok() ;
	}

	::span<JobTgt const> NodeData::prio_job_tgts(RuleIdx prio_idx) const {
		if (prio_idx==NoIdx) return {} ;
		if (prio_idx>=n_job_tgts) {
			SWEAR( prio_idx==n_job_tgts , prio_idx,n_job_tgts ) ;
			return {} ;
		}
		RuleIdx              sz   = 0                                               ;
		::span<JobTgt const> sjts = job_tgts().subvec(prio_idx,n_job_tgts-prio_idx) ;
		RuleIdx              prio = 0                                               ;
		for( JobTgt jt : sjts ) {
			RuleIdx new_prio = jt->rule()->prio ;
			if (new_prio<prio) break ;
			prio = new_prio ;
			sz++ ;
		}
		return sjts.subspan(0,sz) ;
	}

	::span<JobTgt const> NodeData::candidate_job_tgts() const {
		RuleIdx ci = conform_idx() ;
		if (ci==NoIdx) return {} ;
		SWEAR( ci<n_job_tgts , ci,n_job_tgts ) ;
		JobTgts const& jts  = job_tgts()            ; // /!\ jts is a Crunch vector, so if single element, a subvec would point to it, so it *must* be a ref
		RuleIdx        prio = jts[ci]->rule()->prio ;
		RuleIdx        idx  = ci                    ;
		for( JobTgt jt : jts.subvec(ci,n_job_tgts-ci) ) {
			if (jt->rule()->prio<prio) break ;
			idx++ ;
		}
		return jts.subvec(0,idx) ;
	}

	struct JobTgtIter {
		// cxtors
		JobTgtIter( NodeData& n , NodeReqInfo const& ri ) : node{n} , idx{ri.prio_idx} , single{ri.single} {}
		// services
		JobTgtIter& operator++(int) {
			_prev_prio = _cur_prio() ;
			if (single) idx = node.n_job_tgts ;
			else        idx++ ;
			return self ;
		}
		JobTgt        operator* () const { SWEAR( idx<node.n_job_tgts , idx,node.n_job_tgts ) ; return node.job_tgts()[idx]                           ; }
		JobTgt const* operator->() const { SWEAR( idx<node.n_job_tgts , idx,node.n_job_tgts ) ; return node.job_tgts().begin()+idx                    ; }
		JobTgt      * operator->()       { SWEAR( idx<node.n_job_tgts , idx,node.n_job_tgts ) ; return node.job_tgts().begin()+idx                    ; }
		operator bool           () const {                                                      return idx<node.n_job_tgts && _cur_prio()>=_prev_prio ; }
	private :
		RuleIdx _cur_prio() const { return (*self)->rule()->prio ; }
		// data
	public :
		NodeData& node   ;
		RuleIdx   idx    = 0    /*garbage*/ ;
		bool      single = false/*garbage*/ ;
	private :
		RuleIdx _prev_prio = 0 ;
	} ;

	// check rule_tgts special rules and set rule_tgts accordingly
	Buildable NodeData::_gather_special_rule_tgts( ::string const& name_ , RejectSet&/*lazy*/ known_rejected ) {
		n_job_tgts  = 0                        ;
		rule_tgts() = Node::s_rule_tgts(name_) ;
		//
		RuleIdx n_skip = 0 ;
		for( RuleTgt const& rt : rule_tgts().view() ) {
			Rule r = rt->rule ; if (!r) continue ;
			if (r->special==Special::Plain                  ) { rule_tgts().shorten_by(n_skip) ; return Buildable::Maybe ; } // no special rule applies, avoid pattern matching
			if (known_rejected.contains(rt)                 ) { n_skip++ ;                             continue ;          }
			if (!rt.pattern().match(name_,Maybe/*chk_psfx*/)) { n_skip++ ; known_rejected.insert(rt) ; continue ;          } // rule is pre-filtered, so dont match prefix and ...
			rule_tgts() = ::vector<RuleTgt>({rt}) ;                                                                          // ... suffix, check size as pfx and sfx could overlap
			switch (r->special) {
				case Special::Anti       : return Buildable::DynAnti ;
				case Special::GenericSrc : return Buildable::DynSrc  ;
			DF}                                                                                                              // NO_COV
		}
		rule_tgts().clear() ;
		return Buildable::Maybe ;                                                                                            // node may be buildable from dir
	}

	// instantiate rule_tgts into job_tgts by taking the first iso-prio chunk and set rule_tgts accordingly
	// - special rules (always first) are already processed
	// - if a sure job is found, then all rule_tgts are consumed as there will be no further match
	Buildable NodeData::_gather_prio_job_tgts( ::string&/*lazy*/ name_ , Req req , RejectSet&/*lazy*/ known_rejected , DepDepth lvl ) {
		if (!rule_tgts()                ) return Buildable::No                                ;
		if (lvl>=g_config->max_dep_depth) throw ::pair(Special::InfiniteDep,::vector<Node>()) ;        // too deep, must be an infinite dep path
		//
		RuleIdx           n_rules    = 0                  ;
		Buildable         b          = Buildable::No      ;                                            // return val if we find no job candidate
		::vector<RuleTgt> rule_tgts_ = rule_tgts().view() ;
		JobTgts&          jts        = job_tgts()         ;
		::vector<JobTgt>  new_jts    ;                                                                 // typically, there is a single matching job, so dont reserve
		bool              name_chked = false              ;
		Rule              prev_rule  ;
		for( RuleTgt const& rt : rule_tgts_ ) {
			Rule            r  = rt->rule ; if (!r) continue ;
			RuleData const& rd = *r       ;
			SWEAR(!rd.is_special()) ;
			if ( +prev_rule && rd.prio<prev_rule->prio ) goto Done ;
			if ( n_rules!=NoIdx                        ) n_rules++ ;                                   // in all cases, rule is consumed, whether it matches or not
			if ( r==prev_rule                          ) continue  ;                                   // only match first target candidate for any given rule
			if ( known_rejected.contains(rt)           ) continue  ;                                   // this is the major purpose of known_rejected
			//
			bool   from_reservoir = !new_jts && n_job_tgts<jts.size() && r==jts[n_job_tgts]->rule() ;  // once a job is in new_jts, we cant simply extend job_tgts by incrementing n_job_tgts
			JobTgt jt             ;
			//
			if (from_reservoir) {                                                                      // fast path : avoid matching (the only purpose of keeping jobs in reservoir)
				//   vvvvvvvvvvvvvvv
				jt = jts[n_job_tgts] ;                                                                 // gather from reservoir
				//   ^^^^^^^^^^^^^^^
				size_t n_sdeps = rd.deps_attrs.spec.dyn_deps ? Npos : rd.deps_attrs.spec.deps.size() ; // number of static deps, if known
				if (n_sdeps) {
					NodeIdx n_seen_sdeps = 0 ;
					for ( Dep const& d : jt->deps ) {                                                  // check static deps : if one is not buildable, rule does not apply ...
						if (!d.dflags[Dflag::Static]) continue ;                                       // ... note that name computation is avoided for both self and jt
						Node(d)->set_buildable( req , lvl , true/*throw_if_infinite*/ ) ;
						if (d->buildable<=Buildable::No) {
							prev_rule = r ;                                                            // prevent further matching of same rule
							goto NextRuleTgt ;
						}
						n_seen_sdeps++ ;
						if (n_seen_sdeps==n_sdeps) break ;                                             // all static deps have been seen, no need to explore any further
					}
					if (n_sdeps!=Npos) SWEAR( n_seen_sdeps<=n_sdeps , n_seen_sdeps,n_sdeps ) ;         // usually n_seen_sdeps==n_sdeps, but if 2 deps are identical, they are fused in job ...
				}                                                                                      // ... and checking would require to generate names, which is too expensive
				n_job_tgts++ ;                                                                         // simply extend official size as reservoir job is ok
			} else {
				if (!name_     )   name_ = name() ;                                                    // solve lazy
				if (!name_chked) { SWEAR(is_lcl(name_),name_) ; name_chked = true ; }
				//
				Rule::RuleMatch rm = { rt , name_ , Maybe/*chk_psfx*/ } ;                              // no adequate job in reservoir, matching is unavoidable
				//
				if (!rm) { known_rejected.insert(rt) ; continue ; }
				//   vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
				jt = { ::move(rm) , rt.sure() , req , RuleIdx(lvl+1) } ; if (!jt) continue ;
				//   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
				new_jts.push_back(jt) ;
			}
			if (jt.sure()) { b =         Buildable::Yes    ; n_rules = NoIdx ; }                       // after a sure job, we can forget about rules at lower prio
			else             b = ::max(b,Buildable::Maybe) ;
			prev_rule = r ;                                                                            // prevent further matching of same rule
		NextRuleTgt : ;
		}
		n_rules = NoIdx ;                                                                              // we have exhausted all rules
	Done :
		if (+new_jts) {
			//vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
			jts.shorten_by(jts.size()-n_job_tgts) ;
			jts.append(new_jts)                   ;
			//^^^^^^^^^^^^^^^^^
			n_job_tgts += new_jts.size() ;
		}
		//                  vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
		if (n_rules==NoIdx) rule_tgts().clear     (       ) ;
		else                rule_tgts().shorten_by(n_rules) ;
		//                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
		return b ;
	}

	void NodeData::_do_set_buildable( Req req , RejectSet&/*lazy*/ known_rejected , DepDepth lvl ) {
		Trace trace("_do_set_buildable",idx(),req,lvl) ;
		switch (buildable) {                                                                // ensure we do no update sources
			case Buildable::Anti   :
			case Buildable::SrcDir :
			case Buildable::Src    : SWEAR(!rule_tgts(),rule_tgts()) ; goto Return ;
			case Buildable::Decode :
			case Buildable::Encode :
			case Buildable::Loop   :                                   goto Return ;
		DN}
		status(NodeStatus::Unknown) ;
		//
		{	::string name_ = name() ;
			if (name_.size()>g_config->path_max) {                                          // path is ridiculously long, pretend an infinite recursion
				buildable = Buildable::PathTooLong ;
				_set_match_ok() ;
				throw ::pair( Special::InfinitePath , ::vector<Node>{idx()} ) ;
			}
			//
			{	Buildable b = _gather_special_rule_tgts( name_ , known_rejected ) ;
				//                       vvvvvvvvvvvvvvvvvvvvvvvvv
				if (b<=Buildable::No ) { buildable = Buildable::No ; goto Return ; }        // AntiRule's have priority so no warning message
				if (b>=Buildable::Yes) { buildable = b             ; goto Return ; }
				//                       ^^^^^^^^^^^^^^^^^^^^^^^^^
			}
			buildable = Buildable::Loop ;                                                   // during analysis, temporarily set buildable to break loops (will be caught at exec time) ...
			try {                                                                           // ... in case of crash, rescue mode is used and ensures all matches are recomputed
				Buildable db = Buildable::No ;
				if (+dir()) {
					//vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
					dir()->set_buildable( req , lvl , true/*throw_if_infinite*/ ) ;         // dir is necessarily shorter than us, no need to increment lvl, and this is not user-visible level
					//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
					switch ((db=dir()->buildable)) {
						case Buildable::DynAnti   :
						case Buildable::Anti      :
						case Buildable::No        :
						case Buildable::Maybe     :                                    break       ;
						//                          vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
						case Buildable::Yes       : buildable = Buildable::Yes       ; goto Return ;
						case Buildable::DynSrc    :
						case Buildable::Src       :
						case Buildable::SubSrc    : buildable = Buildable::SubSrc    ; goto Return ;
						case Buildable::SrcDir    :
						case Buildable::SubSrcDir : buildable = Buildable::SubSrcDir ; goto Return ;
						//                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
					DF}                                                                     // NO_COV
				}
				//                    vvvvvvvvvvvvvvvvvvvvvvvvv
				if (!is_lcl(name_)) { buildable = Buildable::No ; goto Return ; }
				//                    ^^^^^^^^^^^^^^^^^^^^^^^^^
				//
				Buildable b = _gather_prio_job_tgts( name_ , req , known_rejected , lvl ) ;
				if (db==Buildable::Maybe) b = ::max(b,Buildable::Maybe) ;                   // we are at least as buildable as our dir
				//vvvvvvvvvvv
				buildable = b ;
				//^^^^^^^^^^^
				goto Return ;
			} catch (::pair<Special,::vector<Node>>& e) {
				buildable = Buildable::Unknown ;                                            // restore Unknown as we do not want to appear as having been analyzed
				match_gen = 0                  ;
				e.second.push_back(idx()) ;
				throw ;
			}
		}
	Return :
		_set_match_ok() ;
		trace("done",buildable) ;
		return ;
	}

	bool/*solved*/ NodeData::_make_pre( ReqInfo& ri , bool query ) {
		Trace trace("Nmake_pre",idx(),buildable,ri) ;
		Req              req   = ri.req ;
		::string/*lazy*/ name_ ;
		auto lazy_name = [&]()->::string const& {
			if (!name_) name_ = name() ;
			return name_ ;
		} ;
		// step 1 : handle what can be done without dir
		switch (buildable) {
			case Buildable::PathTooLong :
			case Buildable::Anti        :
			case Buildable::SrcDir      :
			case Buildable::DynAnti     :
			case Buildable::No          : status(NodeStatus::None) ; goto NoSrc ;
			case Buildable::DynSrc      :
			case Buildable::Src         : status(NodeStatus::Src ) ; goto Src   ;
			case Buildable::Decode      :
			case Buildable::Encode      : status(NodeStatus::Src ) ; goto Codec ;
			case Buildable::Unknown     :                            FAIL()     ;                       // NO_COV
		DN}
		if (!dir()) goto NotDone ;
		// step 2 : handle what can be done without making dir
		//vvvvvvvvvvvvvvvvvvvvvvv
		dir()->set_buildable(req) ;
		//^^^^^^^^^^^^^^^^^^^^^^^
		switch (dir()->buildable) {
			case Buildable::DynAnti     :
			case Buildable::Anti        :
			case Buildable::No          :                            goto NotDone ;
			case Buildable::SrcDir      : status(NodeStatus::None) ; goto Src     ;                     // status is overwritten Src if node actually exists
			case Buildable::PathTooLong :                                                               // path too long have been discovered above
			case Buildable::Unknown     :                            FAIL()       ;                     // NO_COV
			default                     :                            break        ;
		}
		//
		if ( ReqInfo& dri = dir()->req_info(req) ; !dir()->done(dri,NodeGoal::Status) ) {               // fast path : no need to call make if dir is done
			if (!dri.waiting()) {
				ReqInfo::WaitInc sav_n_wait{ri} ;                                                       // appear waiting in case of recursion loop (loop will be caught because of no job on going)
				dir()->asking = idx() ;
				//vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
				dir()->make( dri , query?MakeAction::Query:MakeAction::Status , ri.speculate ) ;
				//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
			}
			trace("dir",dir(),STR(dir()->done(dri,NodeGoal::Status)),ri) ;
			//
			if (dri.waiting()) {
				dir()->add_watcher(dri,idx(),ri,ri.pressure) ;
				status(NodeStatus::Uphill) ;                                                            // temporarily, until dir() is built and we know the definitive answer
				goto NotDone ;                                                                          // return value is meaningless when waiting
			}
			if ( query && !dir()->done(dri) ) { trace("query","dir") ; return false ; }
			SWEAR(dir()->done(dri)) ;                                                                   // after having called make, dep must be either waiting or done
		}
		// step 3 : handle what needs dir status
		switch (dir()->buildable) {
			case Buildable::Maybe :
				if (dir()->status()==NodeStatus::None) { status(NodeStatus::Unknown) ; goto NotDone ; } // not Uphill anymore
				[[fallthrough]] ;
			case Buildable::Yes :
				if (buildable==Buildable::Maybe) buildable = Buildable::Yes ;                           // propagate as dir->buildable may have changed from Maybe to Yes when made
				[[fallthrough]] ;
			case Buildable::SubSrc    :
			case Buildable::SubSrcDir :
				switch (dir()->status()) {
					case NodeStatus::Transient :                              goto Transient ;
					case NodeStatus::Uphill    : status(NodeStatus::Uphill) ; goto NoSrc     ;
				DN}
			break ;
		DN}
		// step 4 : handle what needs dir crc
		switch (dir()->buildable) {
			case Buildable::Maybe :
			case Buildable::Yes   :
				if (dir()->crc==Crc::None) { status(NodeStatus::Unknown) ; goto NotDone ; }             // uphill is buildable, but does not actually exist
				goto DirSrc ;
			case Buildable::SubSrcDir :
				if (dir()->crc==Crc::None) { status(NodeStatus::None   ) ; goto Src     ; }             // status is overwritten Src if node actually exists
				goto DirSrc ;
			case Buildable::SubSrc :
			case Buildable::DynSrc :
			case Buildable::Src    :
			DirSrc :
				if (dir()->crc.is_lnk()) goto Transient ;                                               // our dir is a link, we are transient
				status(NodeStatus::Uphill) ;                                                            // a non-existent source stays a source, hence its sub-files are uphill
				goto NoSrc ;
		DF}                                                                                             // NO_COV
		FAIL() ;                                                                                        // NO_COV
	Codec :
		{	SWEAR(crc.valid()) ;
			if (!Codec::refresh(+idx(),+ri.req)) status(NodeStatus::None) ;
			if (log_date()>req->start_ddate    ) ri.overwritten = Access::Reg ;                         // date is only updated when actual content is modified and codec cannot be links
			trace("codec",ri.overwritten) ;
			goto DoneDsk ;
		}
		FAIL() ;                                                                                        // NO_COV
	Src :
		{	bool modified = refresh_src_anti( status()!=NodeStatus::None , {req} , lazy_name() ) ;
			if      (crc            !=Crc::None) status(NodeStatus::Src) ;                              // overwrite status if it was pre-set to None
			else if (status()==NodeStatus::None) goto NoSrc ;                                           // if status was pre-set to None, it means we accept NoSrc
			if      (modified                  ) actual_job() = {} ;
			/**/                                 goto DoneDsk ;                                         // sources are always done on disk, as it is by probing it that we are done
		}
		FAIL() ;                                                                                        // NO_COV
	Transient :
		{	refresh(Crc::Unknown) ;                                                                     // if depending on a transient node, a job must be rerun in all cases
			status(NodeStatus::Transient) ;
			actual_job() = {} ;
			goto DoneDsk ;
		}
		FAIL() ;                                                                                        // NO_COV
	NoSrc :
		{	if (ri.goal>=NodeGoal::Dsk) {
				Manual manual = manual_wash(ri,query,true/*dangling*/) ;                                // always check manual if asking for disk
				trace("no_src",ri.goal,crc,manual,actual_job()) ;
				if (crc!=Crc::None) {
					if (manual==Manual::Ok) {                                                           // if already unlinked, no need to unlink it again
						lazy_name() ;                                                                   // solve
						SWEAR(is_lcl(name_),name_) ;
						if (query) { trace("query","unlnk") ; return false ; }
						unlnk(name_,true/*dir_ok*/) ;                                                   // wash pollution if not manual
						req->audit_job( Color::Warning , "unlink" , Rule::NoRuleName , name_ ) ;
					}
					refresh(Crc::None) ;                                                                // if not physically unlinked, node will be manual
					actual_job() = {} ;
				}
				goto DoneDsk ;
			} else {
				trace("no_src",ri.goal,crc,actual_job()) ;
				if (crc!=Crc::None) {
					refresh(Crc::None) ;                                                                // if not physically unlinked, node will be manual
					if (+actual_job()) {
						polluted        = Polluted::Job ;                                               // disk has been modified, actual_job cannot be the official job
						polluting_job() = actual_job()  ;
					}
					actual_job() = {} ;
				}
				goto Done ;
			}
		}
		FAIL() ;                                                                                        // NO_COV
	Done :
		ri.done_ = ri.goal ;
		goto NotDone ;
		FAIL() ;                                                                                        // NO_COV
	DoneDsk :
		ri.done_ = NodeGoal::Dsk   ;                                                                    // disk is de facto updated
		polluted = Polluted::Clean ;
	NotDone :
		trace("done",idx(),status(),crc,ri) ;
		return true ;
	}

	static bool _may_need_regenerate( NodeData const& nd , NodeReqInfo& ri , NodeMakeAction make_action ) {
		/**/                                if (   make_action==NodeMakeAction::Wakeup            ) return false ;                                // do full analysis
		/**/                                if (   !ri.done(NodeGoal::Status)                     ) return false ;                                // do full analysis
		JobTgt cjt = nd.conform_job_tgt() ; if (!( +cjt && cjt.produces(nd.idx(),true/*actual*/) )) return false ;                                // no hope to regenerate, proceed normally
		/**/                                if (   +nd.polluted || nd.busy                        ) ri.done_ = ::min(ri.done_,NodeGoal::Status) ; // disk cannot be ok if node is polluted or busy
		/**/                                if (   ri.done()                                      ) return false ;                                // node is ok
		Trace trace("_may_need_regenerate",nd.idx(),ri,cjt,nd.polluted,STR(nd.busy),make_action) ;
		ri.prio_idx = nd.conform_idx() ;                                                                                                          // ask to run only conform job
		ri.single   = true             ;                                                                                                          // .
		return true ;
	}
	void NodeData::_do_make( ReqInfo& ri , MakeAction make_action , Bool3 speculate ) {
		RuleIdx            prod_idx       = NoIdx                              ;
		Req                req            = ri.req                             ;
		::array<RuleIdx,2> multi          = {NoIdx,NoIdx}                      ;
		bool               stop_speculate = speculate<ri.speculate && +ri.goal ;
		bool               query          = make_action==MakeAction::Query     ;
		bool               chk_regenerate = false                              ;                                      // anti infinite loop : may only regenerate once
		RejectSet/*lazy*/  known_rejected { self }                             ;
		::string/*lazy*/   name_          ;                                                                           // = name()
		Trace trace("Nmake",idx(),ri,make_action) ;
		ri.speculate &= speculate ;
		//vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
		set_buildable( req , /*lazy*/known_rejected ) ;
		//^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
		if      (make_action==MakeAction::Wakeup) ri.dec_wait() ;
		else                                      ri.goal = ::max( ri.goal , mk_goal(make_action) ) ;
		if      (ri.waiting()                   ) goto Wait ;
		else if (req.zombie()                   ) ri.done_ = ::max( ri.done_ , NodeGoal::Dsk ) ;
		//
		if (ri.prio_idx==NoIdx) {
			if (ri.done()) goto Wakeup ;
			//            vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
			bool solved = _make_pre( ri, make_action==MakeAction::Query ) ;
			//            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
			if (!solved     ) { SWEAR(query) ; goto Wait   ; }
			if (ri.waiting())                  goto Wait   ;
			if (ri.done()   )                  goto Wakeup ;
			ri.prio_idx = 0 ;
		} else {
			if ( _may_need_regenerate(self,ri,make_action) ) goto Make   ;
			if ( ri.done()                                 ) goto Wakeup ;
			// fast path : check jobs we were waiting for, lighter than full analysis
			JobTgtIter it{self,ri} ;
			for(; it ; it++ ) {
				JobTgt jt   = *it                        ;
				bool   done = jt->c_req_info(req).done() ;
				trace("check",jt,jt->c_req_info(req)) ;
				if (!done             ) { prod_idx = NoIdx ; goto Make ;                                            } // we waited for it and it is not done, retry
				if (jt.produces(idx())) { if (prod_idx==NoIdx) prod_idx = it.idx ; else multi = {prod_idx,it.idx} ; } // jobs in error are deemed to produce all their potential targets
			}
			if (prod_idx!=NoIdx) goto DoWakeup ;                                             // we have at least one done job, no need to investigate any further
			if (ri.single) ri.single   = false  ;                                            // if regenerating but job does not generate us, something strange happened, retry this prio
			else           ri.prio_idx = it.idx ;                                            // else go on with next prio
		}
	Make :
		g_kpi.n_node_make++ ;
		SWEAR(prod_idx==NoIdx,prod_idx) ;
		for( chk_regenerate=true ;; chk_regenerate=false ) {                                 // only check regenerate once (e.g. in case of submit_loop, we would try forever)
			for (;;) {
				SWEAR(ri.prio_idx!=NoIdx) ;
				if (!ri.single) {                                                            // fast path : cannot have several jobs not gather new jobs if we consider only a single (existing) job
					if (ri.prio_idx>=n_job_tgts) {                                           // gather new JobTgt's from rule_tgts
						try {
							//!                            vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv fast path : avoid computing name()
							buildable = ::max( buildable , _gather_prio_job_tgts( name_ , req , known_rejected ) ) ;
							//!                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
							if (ri.prio_idx>=n_job_tgts) goto DoWakeup ;                     // fast path
						} catch (::pair<Special,::vector<Node>> const& e) {
							set_infinite(e.first,e.second) ;
							goto DoWakeup ;
						}
					}
					for( JobTgtIter it{self,ri} ; it ; it++ ) {                              // check if we obviously have several jobs, in which case make nothing
						JobTgt jt = *it ;
						if      ( jt.sure()                 )   buildable = Buildable::Yes ; // buildable is data independent & pessimistic (may be Maybe instead of Yes)
						else if (!jt->c_req_info(req).done())   continue ;
						else if (!jt.produces(idx())        )   continue ;
						if      (prod_idx!=NoIdx            ) { multi = {prod_idx,it.idx} ; goto DoWakeup ; }
						prod_idx = it.idx ;
					}
					prod_idx = NoIdx ;
				}
				// make eligible jobs
				JobTgtIter it { self , ri } ;
				{	ReqInfo::WaitInc sav_n_wait{ri} ;                                                              // ensure we appear waiting while making jobs to block loops (caught in Req::chk_end)
					for(; it ; it++ ) {
						JobTgt      jt     = *it               ;
						JobReason   reason ;
						JobReqInfo& jri    = jt->req_info(req) ;
						if (busy) {
								/**/                      reason = {JobReasonTag::BusyTarget    ,+idx()} ;
						} else if (+polluted) {
							if (crc==Crc::None) {
								/**/                      reason = {JobReasonTag::NoTarget      ,+idx()} ;
							} else switch (polluted) {
								case Polluted::Old      : reason = {JobReasonTag::OldTarget     ,+idx()} ; break ;
								case Polluted::PreExist : reason = {JobReasonTag::PrevTarget    ,+idx()} ; break ;
								case Polluted::Job      : reason = {JobReasonTag::PollutedTarget,+idx()} ; break ; // polluting job is already set
							DF}                                                                                    // NO_COV
						} else if (ri.goal!=NodeGoal::Status) {                                                    // dont check disk if asked for Status
							if (jt->running(true/*with_zombies*/))
								/**/                      reason = {JobReasonTag::BusyTarget    ,+idx()} ;
							else switch (manual_wash(ri,false/*query*/,false/*dangling*/)) {
								case Manual::Ok         :                                                  break ;
								case Manual::Unlnked    : reason = {JobReasonTag::NoTarget      ,+idx()} ; break ;
								case Manual::Empty      :
								case Manual::Modif      : reason = {JobReasonTag::ManualTarget  ,+idx()} ; break ;
							DF}                                                                                    // NO_COV
						}
						if (+reason) {
							if ( jri.done() && !jt.produces(idx()) ) reason = {} ;                                 // job cannot do much if we know it does not produce us
						} else {
							if ( !has_actual_job(jt) && jt.produces(idx(),true/*actual*/) ) {                                                     // ensure we dont let go a node with the wrong job
									if (has_actual_job())   { reason = {JobReasonTag::PollutedTarget,+idx()} ; polluting_job() = actual_job() ; }
									else                      reason = {JobReasonTag::NoTarget      ,+idx()} ;
							}
						}
						if (ri.live_out) jri.live_out = ri.live_out ;                                                              // transmit user request to job for last level live output
						jt->asking = idx() ;
						//                vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
						if      (!query ) jt->make( jri , JobMakeAction::Status , reason , ri.speculate ) ;
						else if (!reason) jt->make( jri , JobMakeAction::Query  , reason , ri.speculate ) ;                        // if we have a reason to run job, answer to query is known
						//                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
						trace("job",ri,STR(query),jt,STR(jri.waiting()),STR(jt.produces(idx())),polluted,STR(busy)) ;
						if      (jri.waiting()     )   jt->add_watcher(jri,idx(),ri,ri.pressure) ;
						else if (!jri.done()       ) { SWEAR(query) ; goto Wait ;                                                }
						else if (jt.produces(idx())) { if (prod_idx==NoIdx) prod_idx = it.idx ; else multi = {prod_idx,it.idx} ; } // jobs in error are deemed to produce all their potential targets
					}
				}
				if (ri.waiting()   ) goto Wait     ;
				if (prod_idx!=NoIdx) goto DoWakeup ;
				ri.prio_idx = it.idx ;
			}
		DoWakeup :
			if (prod_idx==NoIdx) {
				if ( ri.goal==NodeGoal::Dsk && !query ) manual_wash(ri,false/*query*/,true/*dangling*/) ;                          // no producing job, check for dangling if asked to do so
				status(NodeStatus::None) ;
				chk_regenerate = false ;                                                                                           // cannot regenerate from nothing
			} else if (multi[0]!=NoIdx) {
				SWEAR(multi[1]!=NoIdx) ;                                                                                           // both must contain a valid index or none of them
				status(NodeStatus::Multi) ;
				trace("multi",ri,multi) ;
				/**/                     req->audit_node(Color::Err ,"multi",idx()                       ) ;
				/**/                     req->audit_info(Color::Note,"at least 2 rules match :"        ,1) ;
				for( RuleIdx i : multi ) req->audit_info(Color::Note,job_tgts()[i]->rule()->user_name(),2) ;
				chk_regenerate = false ;                                                                                           // cannot regenerate from multi
			} else {
				conform_idx(prod_idx) ;
			}
			ri.done_ = ri.goal ;
			if (!( chk_regenerate && _may_need_regenerate(self,ri,make_action) )) break ;
			prod_idx = NoIdx ;
		}
	Wakeup :
		SWEAR(done(ri)) ;
		trace("wakeup",ri,conform_idx(),is_plain()?actual_job():Job()) ;
		ri.wakeup_watchers() ;
	Wait :
		if (stop_speculate) _propag_speculate(ri) ;
		trace("done",ri) ;
	}

	void NodeData::_propag_speculate(ReqInfo const& cri) const {
		switch (status()) {
			case NodeStatus::Uphill    :
			case NodeStatus::Transient : { Node n = dir()             ;         n->propag_speculate( cri.req , cri.speculate ) ; } break ;
			case NodeStatus::Plain     : { Job  j = conform_job_tgt() ;         j->propag_speculate( cri.req , cri.speculate ) ; } break ;
			case NodeStatus::Multi     : { for( Job j : conform_job_tgts(cri) ) j->propag_speculate( cri.req , cri.speculate ) ; } break ;
			case NodeStatus::Unknown   :                                                                                           break ; // node is not built, nowhere to propagate
			default :
				SWEAR(status()<NodeStatus::Uphill,status()) ;                                                                              // ensure we have not forgotten a case
		}
	}

	bool/*ok*/ NodeData::forget( bool targets , bool deps ) {
		Trace trace("Nforget",idx(),STR(targets),STR(deps),STR(waiting()),conform_job_tgts()) ;
		if (waiting()) return false ;
		//
		bool    ok   = true ;
		RuleIdx k    = 0    ;
		RuleIdx prio = 0    ;
		for( Job j : job_tgts().subvec(0,n_job_tgts) ) {
			RuleIdx p = j->rule()->prio ;
			if (p<prio) break ;              // all jobs above or besides conform job(s)
			ok &= j->forget(targets,deps) ;
			if (k==conform_idx()) prio = p ;
			k++ ;
		}
		match_gen = 0 ;
		return ok ;
	}

	void NodeData::mk_old() {
		Trace trace("mk_old",idx()) ;
		busy      = false ;           // possibly old
		match_gen = 0     ;
	}

	void NodeData::mk_no_src() {
		Trace trace("mk_no_src",idx()) ;
		buildable = Buildable::Unknown ;
		match_gen = 0                  ;
		fence() ;
		rule_tgts ().clear() ;
		job_tgts  ().clear() ; n_job_tgts = 0 ;
		actual_job().clear() ;
		refresh() ;
	}

	void NodeData::mk_src(Buildable b) {
		Trace trace("mk_src",idx()) ;
		buildable = b ;
		fence() ;
		rule_tgts ().clear() ;
		job_tgts  ().clear() ; n_job_tgts = 0 ;
		actual_job().clear() ;
		_set_match_ok() ;
	}

	void NodeData::mk_src(FileTag tag) {
		Trace trace("mk_src",idx(),tag) ;
		switch (tag) {
			case FileTag::None  : mk_src(Buildable::Anti  ) ;                      break ;
			case FileTag::Dir   : mk_src(Buildable::SrcDir) ;                      break ;
			case FileTag::Empty : mk_src(Buildable::Src   ) ; tag = FileTag::Reg ; break ; // do not remember file is empty, so it is marked new instead of steady/changed when first seen
			default             : mk_src(Buildable::Src   ) ;                      break ;
		}
		refresh(tag) ;
	}

	bool/*modified*/ NodeData::refresh( Crc crc_ , SigDate const& sd ) {
		bool modified = !crc.match(crc_) ;
		//
		Trace trace( "refresh" , STR(modified) , idx() , reqs() , crc ,"->", crc_ , date() ,"->", sd ) ;
		//
		{	Lock lock { s_crc_date_mutex } ;
			if (modified) crc_date(crc_,sd) ;
			else          date() = sd ;
		}
		for( Req r : reqs() ) {
			ReqInfo& ri = req_info(r) ;
			if (modified) ri.done_  = ::min( ri.done_ , NodeGoal::Status ) ; // target is not conform on disk any more
			if (+sd     ) ri.manual = Manual::Ok                           ; // if we passed a sig, we know the disk state, and we just updated our records
		}
		return modified ;
	}

	static ::pair<Manual,bool/*refreshed*/> _manual_refresh( NodeData& nd , FileSig const& sig ) {
		Manual m = nd.manual(sig) ;
		if (m<Manual::Changed) return {m,false/*refreshed*/} ;      // file was not modified
		if (nd.crc==Crc::None) return {m,false/*refreshed*/} ;      // file appeared, it cannot be steady
		//
		::string ndn = nd.name() ;
		if ( m==Manual::Empty && nd.crc==Crc::Empty ) {             // fast path : no need to open file
			nd.date() = FileSig(ndn) ;
		} else {
			FileSig sig ;
			Crc     crc { ndn , /*out*/sig } ;
			if (!nd.crc.match(crc)) return {m,false/*refreshed*/} ; // real modif
			nd.date() = sig ;
		}
		return {Manual::Ok,true/*refreshed*/} ;                     // file is steady
	}
	Manual NodeData::manual_refresh( Req req , FileSig const& sig ) {
		auto [m,refreshed] = _manual_refresh(self,sig) ;
		if ( refreshed && +req ) req->audit_node(Color::Note,"manual_steady",idx()) ;
		return m ;
	}

	//
	// Target
	//

	::string& operator+=( ::string& os , Target const t ) { // START_OF_NO_COV
		/**/           os << "T("         ;
		if (+t       ) os << +t           ;
		if (+t.tflags) os <<','<<t.tflags ;
		return         os << ')'          ;
	}                                                       // END_OF_NO_COV


	//
	// Dep
	//

	::string& operator+=( ::string& os , Dep const& d ) {         // START_OF_NO_COV
		return os << static_cast<DepDigestBase<Node> const&>(d) ;
	}                                                             // END_OF_NO_COV

	::string& operator+=( ::string& os , GenericDep const& gd ) { // START_OF_NO_COV
		os << "GenericDep(" ;
		if (gd.hdr.sz) {
			os << gd.hdr.chunk_accesses            <<',' ;
			os << ::span((&gd)[1].chunk,gd.hdr.sz) <<',' ;
		}
		os << gd.hdr ;
		return os << ')' ;
	}                                                             // END_OF_NO_COV

	::string Dep::accesses_str() const {
		::string res ; res.reserve(N<Access>) ;
		for( Access a : iota(All<Access>) ) res.push_back( accesses[a] ? AccessChars[+a].second : '-' ) ; // NOLINT(clang-analyzer-core.CallAndMessage) XXX! : for some reason, clang-tidy fires up here
		return res ;
	}

	::string Dep::dflags_str() const {
		::string res ; res.reserve(N<Dflag>) ;
		for( Dflag df : iota(All<Dflag>) ) res.push_back( dflags[df] ? DflagChars[+df].second : '-' ) ;
		return res ;
	}

	//
	// Deps
	//

	::string& operator+=( ::string& os , DepsIter::Digest const& did ) { // START_OF_NO_COV
		return os <<'('<< did.hdr <<','<< did.i_chunk <<')'  ;
	}                                                                    // END_OF_NO_COV

	static void _append_dep( ::vector<GenericDep>& deps , Dep const& dep , size_t& hole ) {
		bool can_compress = dep.is_crc && dep.crc()==Crc::None && dep.dflags==DflagsDfltDyn && !dep.parallel ;
		if (hole==Npos) {
			if (can_compress) {                                                                       // create new open chunk
				/**/ hole                         = deps.size()             ;
				Dep& hdr                          = deps.emplace_back().hdr ;
				/**/ hdr.sz                       = 1                       ;
				/**/ hdr.chunk_accesses           = dep.accesses            ;
				/**/ deps.emplace_back().chunk[0] = dep                     ;
			} else {                                                                                  // create a chunk just for dep
				deps.push_back(dep) ;
				deps.back().hdr.sz             = 0  ;                                                 // dep may have a non-null sz (which is not significant as far as the dep alone is concerned)
				deps.back().hdr.chunk_accesses = {} ;                                                 // useless, just to avoid a random value hanging around
			}
		} else {
			Dep& hdr = deps[hole].hdr ;
			if ( can_compress && dep.accesses==hdr.chunk_accesses && hdr.sz<lsb_msk(Dep::NSzBits) ) { // append dep to open chunk
				uint8_t i = hdr.sz%GenericDep::NodesPerDep ;
				if (i==0) deps.emplace_back() ;
				deps.back().chunk[i] = dep ;
				hdr.sz++ ;
			} else {                                                                                  // close chunk : copy dep to hdr, excetp sz and chunk_accesses fields
				uint8_t  sz                 = hdr.sz             ;
				Accesses chunk_accesses     = hdr.chunk_accesses ;
				/**/     hdr                = dep                ;
				/**/     hdr.sz             = sz                 ;
				/**/     hdr.chunk_accesses = chunk_accesses     ;
				/**/     hole               = Npos               ;
			}
		}
	}

	static void _fill_hole(GenericDep& hdr) {
		SWEAR(hdr.hdr.sz!=0) ;
		uint8_t  sz                     = hdr.hdr.sz-1                                                 ;
		Accesses chunk_accesses         = hdr.hdr.chunk_accesses                                       ;
		/**/     hdr.hdr                = { (&hdr)[1].chunk[sz] , hdr.hdr.chunk_accesses , Crc::None } ;
		/**/     hdr.hdr.sz             = sz                                                           ;
		/**/     hdr.hdr.chunk_accesses = chunk_accesses                                               ;
	}
	static void _fill_hole( ::vector<GenericDep>& deps , size_t hole ) {
		if (hole==Npos) return ;
		GenericDep& d = deps[hole] ;
		_fill_hole(d) ;
		if (d.hdr.sz%GenericDep::NodesPerDep==0) deps.pop_back() ;
	}

	// START_OF_NO_COV for debug only
	void Deps::_chk( ::vector<Node> const& deps , size_t is_tail ) {
		::vector<Node> stored ; for( Dep const& d : self ) stored.push_back(d) ;
		if (is_tail) SWEAR(stored.size()>=deps.size(),stored.size(),deps.size()) ;
		else         SWEAR(stored.size()==deps.size(),stored.size(),deps.size()) ;
		for( size_t i : iota(deps.size())) SWEAR(deps[i]==stored[i+stored.size()-deps.size()],i,deps,stored) ;
	}
	// END_OF_NO_COV

	Deps::Deps( ::vector<Node> const& deps , Accesses accesses , Dflags dflags , bool parallel ) {
		::vector<GenericDep> ds   ;        ds.reserve(deps.size()) ;                               // reserving deps.size() is comfortable and guarantees no reallocaiton
		size_t               hole = Npos ;
		for( auto const& d : deps ) _append_dep( ds , {d,accesses,dflags,parallel} , hole ) ;
		_fill_hole(ds,hole) ;
		self = {ds} ;
	}

	void Deps::assign(::vector<Dep> const& deps) {
		::vector<GenericDep> ds   ;        ds.reserve(deps.size()) ; // reserving deps.size() is comfortable and guarantees no reallocaiton
		size_t               hole = Npos ;
		for( auto const& d : deps ) _append_dep( ds , d , hole ) ;
		_fill_hole(ds,hole) ;
		DepsBase::assign(ds) ;
	}

	void Deps::replace_tail( DepsIter it , ::vector<Dep> const& deps ) {
		SWEAR(it!=end()) ;                                                          // else current chunk is already closed
		// close current chunk
		GenericDep* cur_dep = const_cast<GenericDep*>(it.hdr) ;
		cur_dep->hdr.sz = it.i_chunk ;
		if (it.i_chunk!=0) {
			_fill_hole(*cur_dep) ;
			cur_dep = cur_dep->next() ;
		}
		// create new tail
		::vector<GenericDep> ds   ;
		size_t               hole = Npos ;
		for( auto const& d : deps ) _append_dep( ds , d , hole ) ;
		_fill_hole(ds,hole) ;
		// splice it
		NodeIdx tail_sz = items()+DepsBase::size()-cur_dep ;
		if (ds.size()<=tail_sz) {
			for( GenericDep const& d : ds ) *cur_dep++ = d ;                        // copy all
			shorten_by(tail_sz-ds.size()) ;                                         // and shorten
		} else {
			for( GenericDep const& d : ::span(ds.data(),tail_sz) ) *cur_dep++ = d ; // copy what can be fitted
			append(::span( &ds[tail_sz] , ds.size()-tail_sz ) ) ;                   // and append for the remaining
		}
	}

}
