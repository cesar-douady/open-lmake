\input texinfo

@c This file is part of the open-lmake distribution (git@github.com:cesar-douady/open-lmake.git)
@c Copyright (c) 2023 Doliam
@c This program is free software: you can redistribute/modify under the terms of the GPL-v3 (https://www.gnu.org/licenses/gpl-3.0.html).
@c This program is distributed WITHOUT ANY WARRANTY, without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

@macro XXX{txt}
@end macro

@macro lmake
@code{lmake}
@end macro

@macro adminfile{file}
@file{LMAKE/\file\}
@end macro

@macro Lmakefile
@file{Lmakefile.py}
@end macro

@set TITLE The lmake Manual
@set EDITION @dfn{work in progress}
@c info.texi contains :
@c @set VERSION       <version>
@c @set UPDATED       <date>
@c @set UPDATED-MONTH <date>
@include info.texi

@settitle @value{TITLE}
@setchapternewpage odd
@c Combine the variable and function indices:
@syncodeindex vr fn
@c Combine the program and concept indices:
@syncodeindex pg cp
@c FSF publishers: format makebook.texi instead of using this file directly.
@c %**end of header

@copying
This file documents the @lmake utility, which determines
automatically which pieces of a large workflow need to be remade
and issues the commands to remake them.

This is Edition @value{EDITION}, last updated @value{UPDATED},
of @cite{@value{TITLE}}, for @lmake version @value{VERSION}.

Copyright @copyright{}  2023 Doliam.

@quotation
Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 3 or
any later version published by the Free Software Foundation
@end quotation
@end copying

@summarycontents
@contents

@top @lmake
@insertcopying


@chapter Overview of @lmake

The @lmake utility automatically determines automatically which pieces of a large workflow need to be remade
and issues the commands to remake them.
This manual describes @lmake, which was implemented by Cesar Douady.

Our examples show C/C++ and Python programs, since they are very common, but you can use
@lmake with any programming language to run any phase of your CI/CD as long as these can be scripted.
Indeed, @lmake is not limited to programs.
You can use it to describe any task where some files must be (re)computed automatically
from others whenever recomputing would generate such files differently than what they currently are.
Such situations include dependency modifications, but also command modifications, dependency list modifications,
apparition of an include file that was in the search path before an include file was actually accessed, symbolic link modifications, etc.

Hard links are also supported.
Repositories can be moved (as far as @lmake is concerned, user content may not support moves), archived and restored.

@lmake is designed to be scalable, robust and efficient.

By scalable, we mean that @lmake can manage millions of files and tens of thousands of CPU hours without any difficulty,
so there is never any reason to have any kind of recursive invocation, @lmake can handle the whole project all at once.

By robust, we mean that @lmake guarantees that if a job is not rerun, then rerunning it would lead to the same content (or a content that is equally legal).
This includes automatic capture of so called hidden dependencies (i.e. dependencies that are not explicitly stated in the rules, e.g. include files).

We also mean that @lmake, as any software, it may have bug.
Such bugs can lead to crashes and to pessimistic behavior (a job is rerun while it was not necessary).
But special attention has been devoted in its design to ensure that it is never optimistic (a job not being rerun while it should have been).
In case of any adverse event (lmake crashes or spurious system reboot),
@lmake automatically recovers potentially corrupted states in a safe way to avoid having to remake the whole project because a few files are corrupted.
In extreme cases, there is a @code{lrepair} tool that can recover all safe parts of a damaged repository.

Note that @lmake does not only recorver from its own flees, but also a lot of experience is embedded into it to work around system bugs.
This includes for example NFS peculiar notion of close-to-open consistency (which does not apply to the directory containing the file) or jobs spuriously disappearing.

By efficient, we mean that jobs are run in parallel, optionally using a batcher such as SGE or slurm, managing limited resources as declared in @Lmakefile.
We also mean that @lmake makes a lot of effort to determine if it is necessary to run a job (while always staying pessismistic).
Such effort includes checksum based modification detection rather than date based, so that if a job is rerun and produces an identical content, subsequent jobs are not rerun.
Also, @lmake embed a build cache whereby jobs can record their results in a cache so that if the same run needs to be carried out by another user,
it may barely fetch the result from the cache rather than run the - potentially lengthy - job.

@section Preparing and running @lmake.

To prepare to use @lmake, you must write a file called @Lmakefile that describes the relationships among files in your workflow and provides commands for generating each file.
This is analogous to the @file{makefile} when using @code{make}.

When developping a program, typically, the executable file is built from object files, which in turn are built by compiling source files.
Then unit tests are run from the executable and input files, and the output is compared to some references.
Finally a test suite is a collection of such tests.

Once a suitable @Lmakefile exists, each time you change anything in the workflow (source files, recipes, ...), this simple shell command:

@example
lmake <my_target>
@end example

@noindent
suffices to perform all necessary steps so that @file{<my_target>} is reproduced as if all steps leading to it were carried out although only necessary steps were actually carried out.
The @lmake program maintains an internal state in the @file{LMAKE} directory to decide which of the files need to be regenerated.
For each of those files, it issues the recipes recorded in @Lmakefile.
During the execution of recipes, @lmake instruments them in order to gather which files were read and written in order to determine hidden dependencies and whether such actions were legal.
These information are recorded in the @file{LMAKE} directory.

You can provide command line arguments to @lmake to somewhat control this process.

@section Problems and Bugs

If you have problems with @lmake or think you've found a bug,
please report it to the developers; we cannot promise to do anything but
we might well want to fix it.

Before reporting a bug, make sure you've actually found a real bug.
Carefully reread the documentation and see if it really says you can do
what you're trying to do.
If it's not clear whether you should be able to do something or not, report that too; it's a bug in the documentation!

Before reporting a bug or trying to fix it yourself, try to isolate it
to the smallest possible @Lmakefile that reproduces the problem.
Then send us the @Lmakefile and the exact results @lmake gave you, including any error messages.
Please don't paraphrase these messages: it's best to cut and paste them into your report.
When generating this small @Lmakefile, be sure to not use any non-free
or unusual tools in your recipes: you can almost always emulate what
such a tool would do with simple shell commands.
Finally, be sure to explain what you expected to occur; this will help us decide whether the problem was really in the documentation.

if your problem is non-deterministic, i.e. it shows up once in a while, include the entire content of the @file{LMAKE} directory.
This directory contains extensive execution traces meant to help developers to track down problems.
Make sure, though, to trim it from any sensitive data (with regard to IP).

Once you have a precise problem you can report it in one of two ways.
Either send electronic mail to:

@example
    xxx@@yyy.zzz
@end example

@noindent
or use our Web-based project management tool, at:

@example
    https://xxx.yyy.zzz
@end example

@noindent
In addition to the information above, please be careful to include the version number of @lmake you are using.
You can get this information from the file @file{LMAKE/version}.
Be sure also to include the type of machine and operating system you are using.
One way to obtain this information is by running the command @samp{uname -a}.

@chapter An Introduction to @Lmakefile syntax

You need a file called @Lmakefile to tell @lmake what to do.
Alternatively, this may be a package and the file @file{Lmakefile/__init__.py} must exist.
This is important as in addition to defining the necessary context for @lmake to work, it also serves as a marker to find the root of the repository.
The bare existence of a directory @file{Lmakefile} seemed too light to act as a marker, hence the necessity for the @file{__init__.py} file underneath.

The goal of making a package is to define 3 sub-modules @code{config}, @code{rules} and @code{sources}.
It is recommanded to :
@itemize
@item In simple cases, just define @Lmakefile
@item In more complex cases, splitting in 3 sub-modules may be more performant as each part is individually re-read depending on what has changed.
For example, if you add a source, sources need to be re-read, but rules need not.
If it was a single module, everything would be re-read.
@end itemize

Note that in the case of a package, common code can be placed in @file{Lmakefile/__init__.py} as this is read in all 3 cases.
For example, a @code{Rule} may need to know the available resources defined in @code{config} to adapt iteself.
This part of the config can be defined in @file{Lmakefile/__init__.py}.

Throughout this document, @Lmakefile means either @file{Lmakefile.py} or the package @file{Lmakefile}.

In this chapter, we will discuss a simple @Lmakefile that describes how to compile, link and test a tiny executable @file{hello_world.exe}
which consists of 3 C source files (@file{hello_world.c}, @file{hello.c} and @file{world.c}) and 2 header files (@file{hello.h} and @file{world.h}).
This tiny executable just writes @code{hello world} on its output with no argument or @code{hello you} if passed @code{you} as only argument.

This project is implemented in the @file{examples/cc.dir} directory.

In addition to the source files, there is a file @file{hello_world.olst} listing necessary objects to build the executable @file{hello_world.exe}.
This is done in such a way that @Lmakefile contains no project specific information.

Also, you need test inputs, in our case @file{world.in} (empty) and @file{smith.in}, and reference outputs, @file{hello_world-world.ref} an @file{hello_world-smith.ref},
that contains the expected results of running @file{hello_world.exe} on the 2 inputs respectively.

Finally, a test suite is described by @file{hello_world.tlst} which lists the necessary tests to run to validate @file{hello_world.exe}.

@section Genericity

The key to genericity is that file names describe file contents.
For example, the reference output for running the executable @file{hello_world.exe} on input @file{smith.in} is called @file{hello_world-smith.ref}.

From this latter file name, you can derive :
@itemize
@item the executable : the part before the @code{-}
@item the input      : the part between the @code{-} and the @code{.}
@item what it is     : the suffix after the @code{.}
@end itemize

A regular expression based analysis will easily reveal the components of this file name.
This is the heart of @lmake : you describe the flow by using regular expressions, @lmake executes it.

@section Execution

The first time you execute the flow, you need to execute all steps :
@itemize
@item compile all source files to object files
@item link object files to the executable
@item run all tests
@item compare to references
@end itemize

Once this has been done, what needs to be executed depends on what has been modified :
@multitable @columnfractions 0.2 0.4 0.4
@headitem What has been modified @tab What needs to be re-executed @tab Notes
@item nothing
@tab nothing
@item a @file{.c} source file
@tab compile said source file, link, run all tests, do all comparisons
@tab if the object file happen to be identical to previous one (e.g. changing comments or layout of source file for readability), there is no need to link and test.
@item a @file{.h} include file
@tab compile all source files that include said include file, link, run all tests, do all comparisons
@tab if the object files happen to be identical to previous one (e.g. changing comments or layout of source file for readability), there is no need to link and test.
@item a test input file
@tab run said test, do said comparison
@item a recipe in @Lmakefile
@tab execute all jobs using said recipe, then all further jobs depending on it
@tab if anything happen to be rebuilt identically, then the dependent jobs need not be re-executed
@item the list of objects to link executable
@tab compile new objects, link, run all tests, do all comparisons
@tab old objects (no more listed in object list) need not be recompiled, even if corresponding sources are also modified
@end multitable

@section Description of @Lmakefile

As its name suggests, @Lmakefile is actually a Python file.
@lmake embeds a Python interpreter (version 3.6+) to interpret @Lmakefile.
Because Python is among the most powerful and widely used programming language, this choice allows @lmake users to have access to a very powerful language to express complicated workflows
without the need to learn a new language.
(As a side effect, it also allows @lmake developpers to provide such a powerful means without having to design and implement it.)

Among the features of Python that come handy when describing workflows, one can list : variables, functions, f-strings, conditionals, loops and inheritance.

The goal of @Lmakefile is to describe 3 aspects of your workflow :
@itemize @bullet
@item some global configuration
@item the list of the sources of the workflow
@item the derivation rules
@end itemize

This is done by importing the @lmake module and defining the 2 variables @code{lmake.config}, @code{lmake.manifest} and by defining rules inheriting from the base classes in @code{lmake.rules}.
When reading @Lmakefile, @lmake simply imports this module by issuing @code{import Lmakefile} in a Python 3.6+ interpreter and looks at these variables and sub-classes.
@lmake provides some help for these 3 goals, though.

Once @Lmakefile has been read, @lmake writes in the @file{LMAKE} directory a digest of these definitions in the files @file{LMAKE/config}, @file{LMAKE/sources} and @file{LMAKE/rules}.
These may be consulted in case of doubt about what @lmake has understood of your @Lmakefile file.

@section Configuration

The configuration describes some global aspects of the workflow.
The @lmake module contains a reasonable default value for the @code{lmake.config} variable and in an introduction chapter, there is nothing much to say.
In a simple workflow, ignoring the configuration is a good starting point.

@section Sources

@lmake needs to know the list of the source files.
The mere presence on disk of a file is not sufficient for @lmake to qualify it as a source.
This is because the aim of @lmake is to provide a reproductible workflow.
For example, if you work under @code{git}, as it is very common, once you have been able to build a target, you must be able to commit and push, then a colleague (or yourself in another repository)
must be able to do a pull and build the same target to get the same result.
If a file exists in your original repository, but is not tracked by @code{git} and is used to build your target, your colleague will not be able to reproduce the same target with the same content.
In such a situation, @lmake will consider your file as @dfn{dangling} and accessing it will be an error.

Source files are listed in @code{lmake.manifest} as a @code{list} or a @code{tuple}.
By default, if @code{lmake.manifest} is not set, @lmake will look for a file named @file{Manifest} and use it as a list of files, one per line.
If no @file{Manifest} file is present, it will then issue a @code{git ls-files --recurse-submodules} command to gather the list of sources.
Note that the @code{git} repository can be anywhere on the directory path to the @lmake repository.

@section Rules

Rules are classes that derive from one of the base classes defined in @code{lmake.rules} (Rule, AntiRule, PyRule, ...).

To be recognized as a usable rule, rules must define the following attributes (possibly by inheriting them) :
@itemize @bullet
@item @code{targets}
@item @code{cmd}
@end itemize

If any is not defined, such a @code{class} may still be pertinent to serv as base class for usable rules.

Generally, it will also have the @code{deps} attribute defined and possibly the @code{stems} (unless stems are directly defined in targets or deps) :

@example
@group
from lmake.rules import Rule
class Compile(Rule) :
	targets = @{ 'OBJ' : r'@{File:.*@}.o' @}
	deps    = @{ 'SRC' :  '@{File@}.c'    @}
	cmd     = 'gcc -c -o @{OBJ@} @{SRC@}'
@end group
@end example

Let's look at each element in this rule.

@subsection @code{name}
The first element is the class name @code{Compile}.
This name will be used by @lmake in reporting when it needs to refer to this rule, in error messages or when it reports execution.
Generally speaking, all rules have a @code{name} attribute which defaults to the class name if not explicitly set.
Here, the @code{name} of our rule is @code{'Compile'} but we could have set the attribute @code{name} to @code{'cc compilation'} for example.

@subsection @code{stems}
This attribute provides a vocabulary of (Python) regular expressions that can be further referenced in other attributes.

Usually, stems are most useful when defined in a base classe inherited by several rules as it is generally lighter to define them directly in the @code{targets} or @code{deps} attributes.
So it is not used in the previous example.
But in the following case, it is more comfortable to share the vocabulary in the @code{stems} attribute of a base class :

@example
@group
class Compile(Rule) :
	stems = @{ 'File' : r'.*' @}
class CompileC(Compile) :
	targets = @{ 'OBJ' : '@{File@}.o' @}
	deps    = @{ 'SRC' : '@{File@}.c' @}
	cmd     = 'gcc -c -o @{OBJ@} @{SRC@}'
class CompileCpp(Compile) :
	targets = @{ 'OBJ' : '@{File@}.o'  @}
	deps    = @{ 'SRC' : '@{File@}.cc' @}
	cmd     = 'g++ -c -o @{OBJ@} @{SRC@}'
@end group
@end example

@subsection @code{targets}
Then, there is the @code{targets} attribute.
This attribute defines the files that may be generated by this rule.
Its syntax looks like Python 3.6+ f-strings, except that variable parts (in @code{@{@}}) must be plain variables (not actual expressions)
optionally followed by a @code{:} and the definition of the regular expression.
However, this works the other way around, compared to f-strings. With an f-string, you start from a value of @code{File}, say @code{'foo'}, and from that, you can derive the string
@code{'foo.o'} from the f-string @code{'@{File@}.o'}.
But here, we start from a file @file{foo.o} and we find that this rule applies if we define @code{File} as @code{'foo'}.
More precisely, @lmake matches the file name @code{'foo.o'} against the regular expression @code{r'(.*)\.o'}.
The overall regular expression is computed as the concatenation of the variable parts and the escaped fixed parts.

The reason why the Python 3.6+ f-strings syntax has been leveraged is by symmetry with the @code{deps} attribute described below.

There may be more than a single target (and this is why this attribute is a @code{dict}).
In that case, the rule is supposed to generate all of them when it is executed and any of them will trigger its execution.
But in the case of a single target, the @code{target} can be defined as a @code{str} instead of @code{targets}.
In that case, the stdout of the command is redirected to it.

@subsection @code{deps}
Then, we find the @code{deps} attribute.
This attribute define the explicit dependencies the rule needs before it can be run.
This is a @code{dict} mapping keys to actual Python 3.6+ f-strings (but you must not put the initial f, this is interpreted by @lmake, no Python).
Once @code{File} has been determined by matching a target, it is fed to the f-strings to determine the explicit dependencies.
@lmake will automatically determine actual dependencies by spying the rule execution, so one could think mentioning them explicitly is useless.
To some extent, this is true, with these limitations :

Similarly to targets, the attribute @code{dep} can be defined as a @code{str} instead of @code{deps} and is then fed to the command as its stdin.

@itemize @bullet

@item
Explicit dependencies are not only used to determine if a rule must be run or not, they are also used to determine if a rule apply or not.
For a rule to apply, it must match a given file as a target, but also, the computed explicit dependencies must be sources or recursively buildable.
By contrast, if a hidden dependencies cannot be built (and if it does not actually exist), this is silently ignored (more to come later on this subject).

Imagine for example that you have a rule to compile C files and another rule to compute C++ files. Given @file{foo.o}, @lmake must determine which rule to apply.
With explicit dependencies, @lmake has the necessary information to select the adequate rule : it will look for files @file{foo.c} and @file{foo.cc} and if one is a source or is buildable,
it can then select the corresponding rule.
Note that if both are sources or buildable, the situation will be ambiguous and @lmake will report an error.
On the opposite, if none are sources or buildable, @file{file.o} will be deemed not buildable.

@item
From a performance perspective, this allows @lmake to know up front that a dependency is required before running a job.
If a dependency is not explicitly mentioned, a target may be built by @lmake, spying its accesses.
@lmake then discovers the dependency, and if it is not up to date, build it and rerun the rule with up to date dependencies.
This double run (which occurs only the first time @lmake hit the given target) can be avoided if the dependency is explicit.

@end itemize

Generally speaking, obvious dependencies (such as the source file for a compilation step) should be mentioned explicitly and the other ones (such as include files for a compilation step)
can be left as hidden dependencies.

@subsection @code{cmd}
Finally we see the @code{cmd} attribute.
This attribute specifies the recipe to use to build targets from dependencies.
The @code{cmd} attribute can be either a @code{str} or a function.

If it is a @code{str}, it contains a shell script that will be executed when the rule is triggered
(the shell can be customized and defaults to the default system shell, usually @file{/bin/bash}).
Before execution, it is interpreted as a Python f-string, i.e. everything between @code{@{@}} is interpreted as a Python expression and the corresponding value is substituted.
During this process, the stems, targets and deps have their definition from the current job (as well as any referenced attribute or global variables).

The return code determines the success of the job.

It can also be a function that is called to execute the job, such as :
@example
@group
import re
from lmake.rules import PyRule
class NoComment(PyRule) :
	target = r'@{File:.*@}.nc'
	deps   = @{ 'IN' : '@{File@}' @}
	def cmd() :
		text = open(IN).read()
		filtered = re.sub('(^|\n)\n+',r'\1',re.sub(r'#.*','',text))
		print(filtered,end='')
@end group
@end example

In this case, this function is called in a Python interpreter when the rule is triggered
(the Python used to run this function can be customized and defaults to the Python used to read @Lmakefile).
Before execution, the definitions of stems, targets and dependencies are put in the global @code{dict}
(as well as any referenced global variable or rule attribute, such as @code{re} in this example).

the job will be considered successful if it returns, raising an exception will trigger an error.

This way, functions are easy to write and read.

@section A simple @lmake session

You can copy the directory @file{cc.dir} and execute @code{python run.py}.
This script executes a simple @lmake session and is largely commented to explain what is going on.

@chapter User Commands
User commands are documented in man pages.

@chapter The Python @lmake module

The @lmake module provides support to write @code{cmd} functions executed during job execution.

The @code{lmake.rules} module provides support to write rules themselves.

The @code{lmake.auto_sources} module can be used to help define sources if the default behavior is not satisfactory.

Some variables of this module can be defined in @Lmakefile for some specific purposees.

@section @code{class pdict}
Documented with @code{help(lmake.pdict)}.

This class is a dict in which attribute accesses are mapped to item accesses.
It is very practical to handle configurations.

@section @code{def multi_strip(txt)}
Documented with @code{help(lmake.multi_strip)}.

This function deindent @code{txt} so as to ease printing code.

@section @code{def check_version(major,minor)}

This function is used to check that the expected version is compatible with the actual version.

Upon new releases of @lmake, the major version is a tag of the form YY.MM providing the year and month of publication if it is not backward compatible.
Else the minor version is increased if the interface is modified (i.e. new features are supported).
Hence, the check is that major versions must match equal and the actual minor version must be at least the expected minor version.

This function must be called right after having imported the @lmake module as it may adapt itself to the required version when this function is called.
For example, some default values may be modified and if they are used before this function is called, a wrong (native) value may be provided instead of the correct (adjusted to required version) one.

@section @code{def find_cc_ld_library_path(cc)}
Documented with @code{help(lmake.find_cc_ld_library_path)}.

This function determines an adequate value to put in @code{$LD_LIBRARY_PATH} to use programs compiled with @code{cc}.

@section @code{def run_cc(*cmd_line,marker='...',stdin=None)}
Documented with @code{help(lmake.run_cc)}.

This functions ensures that all directories listed in arguments such as @code{-I} or @code{-L} exist reliably.

@section @code{version}

This variable holds the native version of @lmake.
It is a tuple formed with a @code{str} (the major version) and a @code{int} (the minor version).
See previous section for more information.

@section constants

The following constants are defined :
@table @code
@item repo_root
The root directory of the (sub-)repository.
@item top_repo_root
The root directory of the top-level repository as determined when the @lmake command was run.

@item autodeps
The @code{tuple} of implemented autodep methods. @code{'ld_preload'} is always present.
@item backends
The @code{tuple} of implemented backends. @code{local} is always present.
@item no_crc
The 64-bit @code{int} checksum when it has not been computed (yet).
@item crc_no_file
The 64-bit @code{int} checksum produced when computed on a non-existent file.
@item user_environ
A dict, much like os.environ, that provides the environment in which @lmake was run when it read its configuration.
This allows the user to have access to these environment variables when explicitly required.
@end table

@section Job execution support

The Python @lmake module also provides a Python API to the job supporting command described above.
They are fully documented by running @code{help} on each function.

The correspondance is :
@multitable @columnfractions 0.3 0.1 0.6
@headitem Function @tab equivalent command @tab Comment
@item @code{def check_deps()}
@tab @code{lcheck_deps}
@tab
@item @code{def depend( *files , follow_symlinks=True , verbose=False , read=True , critical=False , essential=False , ignore_error=False , required=True , ignore=False )}
@tab @code{ldepend}
@tab @code{files} may be a single @code{tuple} or a @code{tuple} of @code{str}'s.
For example, you can call @code{depend('file1','file2')} or @code{depend(('file1','file2'))}.
If @code{verbose}, the result is a @code{dict} indexed by files, whose values are 2-tuples formed by :
@itemize @minus
@item a status : @code{True} if the file was up to date and ok, @code{False} if the file was up to date and in error, @code{None} if the file was not up to date.
@item a @code{str} containing the crc as described for @code{ldepend}.
@end itemize
@item @code{def target( *files , write=True , essential=False , incremental=False , phony=False , no_uniquify=False , no_warning=False , ignore=False , source_ok=False , allow=True )}
@tab@code{ltarget}
@tab @code{files} may be a single @code{tuple} or a @code{tuple} of @code{str}'s.
For example, you can call @code{target('file1','file2')} or @code{target(('file1','file2'))}.
@item @code{def decode(file,context,code)}
@tab@code{ldecode}
@tab The return value is the value associated with code.
@item @code{def encode(file,context,value,min_len=1)}
@tab @code{lencode}
@tab The return value is the generated of retrieved code.
@end multitable

@section @code{lmake.get_autodep}
@code{def get_autodep()}

This function returns whether autodep is currently activated (@code{True}) or deactivated (@code{False}).
When activated, the monitoring is performed normally.
When deactivated, no access monitoring is performed, as if the @code{autodep} rule attribute is set to @code{None}.
Note that even in that case, the @code{depend} and @code{target} functions work normally.

Using the @code{Autodep} @code{class}, the context version of this function, is much easier.

@section @code{lmake.set_autodep}
@code{def set_autodep(active)}

This function may be used to activate or deactivate the autodep machinery.
When activated, the monitoring is performed normally.
When deactivated, no access monitoring is performed, as if the @code{autodep} rule attribute is set to @code{None}.
Note that even in that case, the @code{depend} and @code{target} functions work normally.

Using the @code{Autodep} @code{class}, the context version of this function, is much easier.

@section @code{class Autodep}
@code{def __init__(self,enable)}

This @code{class} is initialized with a single @code{bool} as argument.

This class may be used as a context to temporarily enable or disable the autodep machinery and can be nested, as in the following example :

@example
@group
import subprocess
import lmake
class Foo(Rule) :
	targets = @{ 'DST' : 'foo' @}
	def cmd() :
		with lmake.Autodep(False) :
			subprocess.run(('no_autodep_in_script',))
			print(open('no_dep_for_this_file').read(),file=open(DST,'w')) # writing to DST is not seen
			lmake.target(DST)                                            # however this will report writing to DST
			with lmake.Autodep(True) :
				print(open('dep_recorded_for_this_file').read(),file=open(DST,'w')) # writing to DST is seen
@end group
@end example

@section The @code{lmake.rules} module

@subsection @code{class Rule}
This @code{class} is used as a base @code{class} for rules.

@subsection @code{class AntiRule}
This @code{class} is used as a base @code{class} for anti-rules.

Anti-rules specify that target files that are not buildable.
They have no dependencies nor execution.

@subsection @code{class SourceRule}
This @code{class} is used as a base @code{class} for sources defined by a pattern.

Source-rules specify that a matching target is considered a source.
If such a file is required and does not exist, it is an error condition.
They have no dependencies nor execution.

@subsection @code{class Py[23]Rule}

These classes may be used as base @code{class} for Python code doing imports.

It manages @code{.pyc} files so that user is not annoyed by Python generating @code{.pyc} files at esoteric places.

Also, it provides dependencies to module source files although Python may optimize such accesses and miss deps on dynamically generated modules.

@code{Py2Rule} manages Python2.
@code{Py3Rule} manages Python3.
@code{PyRule} is an alias for @code{Py3Rule}.

@subsection @code{class RustRule}
This @code{class} may be used as a base @code{class} to execute executable written in rust.

Rust uses a special link mechanism which defeats the default @code{ld_audit} autodep mechanism.
This base @code{class} merely sets the autodep method to @code{ld_preload} which works around this problem.

@subsection @code{class HomelessRule}
This @code{class} removes @code{$HOME} from the environment, which is then set by default to @code{$TMPDIR}.
This is a way to ensure that various tools behave the same way as if they were run for the first time.
By default @code{$HOME} points to the root of the repository, which permits to put various init code there.

@subsection @code{class TraceRule}
This @code{class} defines a preamble for use by shell rules that set the @code{-x} flag (which traces commands) so that traces are sent to stdout.
This is useful as such traces are activity logging, not errors, which are normally reported to stdout in jobs.

@subsection @code{class DirtyRule}
This @code{class} may be used to ignore all writes that are not an official target.

By itself, it is a dangerous @code{class} and must be used with care.
It is meant to be a practical way to do trials without having to work out all the details, but in a finalized workflow, it is better to avoid the usage of this class.

@section The @code{lmake.sources} module
This module provide support functions to define sources.

@subsection @code{def manifest_sources(manifest='Manifest')}
This function returns the list of sources found in the @code{manifest} file, one per line.
Comments are supported as everything following a @code{#} itself at start of line or preceded by a space.
Leading and trailing white spaces are stripped after comment removal.

@subsection @code{def git_sources( recurse=True , ignore_missing_submodules=False )}
This function lists files under @code{git} control, recursing to sub-modules if @code{recurse} is true and ignore missing such sub-modules if @code{ignore_missing_submodules} is true.
The @code{git} repository itself can be an enclosing directory of the @lmake repository.
In that case, sources are adequately set to track @code{git} updates.

@subsection @code{def auto_sources(**kwds)}
This function tries to find sources by calling @code{manifest_sources} and @code{git_sources} in turn, untill one succeeds. Arguments are passed as pertinent.

@section The @code{lmake.import_machinery} module

@subsection @code{def fix_import()}

The classes @code{PyRule}, @code{Py2Rule} and @code{Py3Rule} call @code{lmake.import_machinery.fix_import()} to manage dependencies during import.
In case you have a rule that calls Python and needs to manage imports similarly, you may call this function.

@subsection @code{module_suffixes}

In case you have to manage non-standard file extensions, you may add them to this variable.
The default value is @code{('.py','.so','/__init__.py')}.

@chapter Directories

By default, all administration data @lmake needs to track the repository state is in the @file{LMAKE} directory at the root of the repository.

But most data are either accessed only by the @lmake server, or by individual jobs, and need not be on a shared disk that is visible from the server and all execution hosts.
Such disk are typically rather slow, compared to local disks.

So there a possibility to store administration data that do not mandate sharing into local disks.

@anchor{dir-local_admin_dir}
@section @code{lmake.config.local_admin_dir}

This variable specifies the directory to use for data that are accessed by the @lmake server only.
It can be set to a directory mounted on a local disk which may be visible only by the @lmake server (i.e. on the host on which you launch the @lmake command).

This directory need not be unique for each repository as @lmake will create a unique sub-directory per repository (identified by its absolute path).

It is of paramount importance to leave this directory intact as this is where @lmake stores most of its bookkeeping data.

@chapter Config

Configuration is either defined directly in @Lmakefile or you can define a callable or a sub-module called @code{config} which is called/imported.

@lmake can be configured to tailor its parameters to the user needs. When reading its configuration, the environment is reset to a standard environment :
@itemize @minus
@item HOME is set to the repository root dir.
@item PATH is set to the default path.
@item UID is set to the user id.
@item USER is set to the user name.
@end itemize
However, the existing environment in which @lmake is launched can be accessed as @code{lmake.user_environ}.
This allows explicit access to this environment while avoiding spurious, unwanted, unreliable and uncontrolled accesses.

Note that @code{lmake.user_environ} is not defined when the @code{lmake} module is imported when not reading the configuration.
During job execution, environment must be passed using the @code{environ}, @code{environ_resources} and @code{environ_ancillary} rule attributes.

Configuration is done by setting attributes (or items) of the @code{pdict} @code{lmake.config}.

After @lmake has been run (at least once), the configuration, as understood by @lmake can be retrieved in the file @adminfile{config}.

The configuration is reloaded (if necessary) each time a @lmake command is run, which may occur while another one is also running.
However, fields may have restrictions :
@itemize @minus
@item Clean   : This field can only set initially when the repository is clean (for example after a @code{git clean -ffdx} command).
@item Static  : This field can only be modified when no other @lmake command is running.
@item Dynamic : This field can freely be modified.
@end itemize

Recognized attributes are :
@multitable @columnfractions 0.1            0.07         0.03        0.8
@headitem                    Attribute @tab Default @tab Update @tab Description

@item @code{disk_date_precision}
@tab @code{0.010}
@tab Static
@tab This attribute instruct @lmake to take some margin (expressed in seconds) when it must rely on file dates to decide about event orders.
It must account for file date granularity (generally a few ms) and date discrepancy between executing hosts and disk servers (generally a few ms when using NTP).
If too low, there are risks that @lmake consider that data read by a job are up to date while they have been modified shortly after.
If too high, there is a small impact on performance as @lmake will consider out of date data that are actually up to date.
The default value should be safe in usual cases and user should hardly need to modify it.

@item @code{heartbeat}
@tab @code{10}
@tab Static
@tab @lmake has a heartbeat mechanism to ensure a job does not suddenly disappear (for example if killed by the user, or if a remote host reboots).
If such an event occurs, the job will be restarted automatically.
This attribute specifies the time between 2 successive checks for a given job (subject to the restrictions of @code{heartbeat_tick} below).
If @code{None}, the heartbeat mechanism is disabled.
The default value should suit the needs of most users.

@item @code{heartbeat_tick}
@tab @code{0.1}
@tab Static
@tab @lmake has a heartbeat mechanism to ensure a job does not suddenly disappear (for example if killed by the user, or if a remote host reboots).
If such an event occurs, the job will be restarted automatically.
This attribute specifies the time between 2 successive checks globally for all jobs (subject to the restrictions of @code{heartbeat} above).
If @code{None}, no restriction apply.
The default value should suit the needs of most users.

@item @code{local_admin_dir}
@tab @file{LMAKE}
@tab Clean
@tab This variable contains a directory to be used for @lmake administration in addition to the @file{LMAKE} directory.
Actually most of the accesses are made in this directory (cf @pxref{dir-local_admin_dir}).

@item @code{link_support}
@tab @code{'Full'}
@tab Clean
@tab @lmake has several levels of symbolic link support (cf @pxref{link-support}).
This attribute specifies the used level.

@item @code{max_dep_depth}
@tab @code{1000}
@tab Static
@tab The rule selection process is a recursive one (cf @pxref{rule-selection}).
Several means are provided to avoid infinite recursion.
The search stops if the depth of the search reaches the value of this attribute, leading to the selection of a special internal rule called @code{'infinite'}.

@item @code{max_error_lines}
@tab @code{100}
@tab Dynamic
@tab When a lot of error lines are generated by @lmake, other than copying the @code{stderr} of a job, only the first @code{max_error_lines} ones are actually output,
followed by a line containing @code{...}.
The purpose is to ease reading.

@item @code{network_delay}
@tab @code{1}
@tab Static
@tab When a job completes, it signals it to @lmake.
But while this informations is travelling, the job is nowhere : it is no more running and @lmake is not aware of it being completed.
If during that time, the heartbeat fires checking for job liveness or a ^C is hit asking for jobs to die, @lmake may think this job is lost.
To prevent that, @lmake waits for some time before declaring such a job as actually lost.
This attribute provides this delay in seconds.

@item @code{path_max}
@tab @code{400}
@tab Static
@tab This is one of the infinite recursion protection in the rule selection process (cf @pxref{rule-selection}).
The search stops if any file with a name longer than the value of this attribute, leading to the selection of a special internal rule called @code{'infinite'}.

@item @code{reliable_dirs}
@tab @code{False} unless only local backend is used
@tab Static
@tab Specify whether directory coherence is enforced when a file is created/modified/unlinked.
@*
It is the case for the following file systems : ceph.
@*
It is not the case for the followin file systems : NFS.
@*
When false, enclosing directories are recursively open before any file is accessed to ensure the right file is open,
and enclosing directory is closed after any file creation, modification or delettion.
This is due to the fact that some file systems, such as NFS.
In other words, on such file systems, the "close to open coherence" must be understood as "the data are there, but it does not mean you are guaranteed access to them".
In order to access the data, you need a reliable directory, which mean you must open the directory before such access, hoping that the directory has been closed by the writer after the last update.
And this applies recursively.
@*
This has a performance cost but no more performant method is known to the autor.
And because of the performance cost, this option has been designed to avoid paying it for file systems that do not require such going through such a headache.

@item @code{sub_repos}
@tab @code{()}
@tab Static
@tab This attribute provide the list of sub-repositories.
Sub repositories are sub-directories of the repository that are themselves repositories, i.e. they have a @Lmakefile.
Inside such sub-repositories, the applied flow is the one described in it, namely :
@itemize
@item Config is the one of the top-level, except for the @code{link_support} attribute which becomes the most conservative (@code{full}>@code{file}>@code{none}).
@item Sources are taken from the local @Lmakefile and sources listed in the global @Lmakefile that happen to be located in the sub-repository are ignored.
@item Rules are taken from the local @Lmakefile, executed within it (by adjusting their @code{cwd} attributes) and rules from the global repository do not apply.
However there are 2 situations in which a global rule may apply in a sub-repo :
@itemize
@item if a target contains an explicit prefix within a sub-repo, then it is considered the user is willing to subrogate this principle.
@item if a rule matches a job with 2 or more targets, with a target outside the sub-repo and another inside it and the target outside the sub-repo is needed,
the job will be executed, generating a target within the sub-repo.@XXX{?flag this case as an error rather than silently accepting it}
@end itemize
@end itemize
However, relative external source dirs (i.e. source dirs located outside the sub-repository) that happen to be located in the global repository are suppressed,
i.e. the global flow applies to files located there, instead as being considered sources.
This way, when the sub-repository is used standalone, it assumes its external environment is adequately prepared, and when used as a sub-repository, the global flow generates them.
Global flow must be understood as the flow defined at the top-level and in any other sub-repositories.

Sub-repositories are recursive, i.e. they can contain sub-sub-repositories and the same applies at each level recursively.

@item @code{console.date_precision}
@tab @code{None}
@tab Dynamic
@tab This attribute specifies the precision (as the number of digit after the second field, for example 3 means we see milli-seconds) with which timestamps are generated on the console output.
If @code{None}, no timestamp is generated.

@item @code{console.has_exec_time}
@tab @code{True}
@tab Dynamic
@tab If this attribute is true, execution time is reported each time a job is completed.

@item @code{console.history_days}
@tab @code{7}
@tab Dynamic
@tab This attribute specifies the number of days the output log history is kept in the @file{LMAKE/outputs} directory.

@item @code{console.host_length}
@tab @code{None}
@tab Dynamic
@tab This attribute specifies the width of the field showing the host that executed or is about to execute the job.
If @code{None}, the host is not shown.
Note that no host is shown for local execution.

@item @code{console.show_eta}
@tab @code{True}
@tab Dynamic
@tab If this attribute is true, the title shows the ETA of the command, in addition to statistics about number of jobs.

@item @code{trace.size}
@tab @code{100_000_000}
@tab Static
@tab While @lmake runs, it generates an execution trace recording a lot of internal events meant for debugging purpose.
The trace is handled as a ring buffer, storing only the last events when the size overflows.
The larger the trace, the more probable the root cause of a potential problem is still recorded, but the more space it takes on disk.
This attributes contains the maximum size this trace can hold (@lmake keeps the 5 last traces in case the root cause lies in a previous run).

@item @code{trace.n_jobs}
@tab @code{1000}
@tab Static
@tab While @lmake runs, it generates execution traces for all jobs.
This attributes contains the overall number of such traces that are kept.

@item @code{trace.channels}
@tab all
@tab Static
@tab The execution trace @lmake generates is split into channels to better control what to trace.
This attributes contains a @code{list} or @code{tuple} of the channels to trace.

@item @code{colors}
@tab raisonably readable
@tab Dynamic
@tab @lmake generate colorized output if it is connected to a terminal (and if it understands the color escape sequences) (cf @pxref{video-mode}).
This attribute is a @code{pdict} with one entry for each symbolic color (cf @pxref{video-mode}).
Each entry is a 2-tuple of 3-tuple's.
The first 3-tuple provides the color in normal video mode (black/white) and the second one the color in reverse video (white/black).
Each color is a triplet RGB of values between 0 and 255.

@item @code{backends}
@tab
@tab Dynamic (with possible restrictions from backend)
@tab This attribute is a @code{pdict} with one entry for each backend
(cf @pxref{backends} for an explanation of what is the purpose of backends, and see the backends section for a description of the attributes).
Each entry is a pdict providing resources. Such resources are backend specific.

@item @code{caches}
@tab
@tab Static
@tab This attribute is a @code{pdict} with one entry for each cache.
Caches are named with an arbitrary @code{str} and are referenced in rules using this name.
The attributes are described in the caches section below.
@end multitable

@section backends

@multitable @columnfractions 0.1            0.07         0.83
@headitem                    Attribute @tab Default @tab Description

@item @code{backends.*.interface}
@tab best guess
@tab
When jobs are launched remotely, they must connect to @lmake when they start and when they complete.
This is done by connecting to a socket @lmake has opened for listening, which requires that we must have a means to determine an IP address to connect to.
The host running @lmake may have several network interfaces, one of them (typically only one) being usable by such remote hosts.
There is no generic way to determine this address, so in general, @lmake cannot determine it automatically.
@*
This value may be empty (loop-back for local backend, @code{hostname} look up for remote backends), given in standard dot notation, as the name of an interface (as shown by @code{ifconfig})
or the name of a host (looked up as for @code{ping}).

@item @code{backends.local.cpu}
@tab number of physical CPU's
@tab This is a normal resource that rules can require (which is the case if resources are defaulted)

@item @code{backends.local.mem}
@tab size of physical memory
@tab This is the pysical memory necessary for jobs.
It can be specified as a number or a string representing a number followed by a standard suffix such as @code{k},  @code{M} or @code{G}.
Internally, the granularity is forced to MBytes before any possible rounding linked with the @code{precisions} attribute.

@item @code{backends.local.tmp}
@tab 0
@tab This is the disk size in the temporary directory necessary for jobs.
It can be specified as a number or a string representing a number followed by a standard suffix such as @code{k},  @code{M} or @code{G}.
Internally, the granularity is forced to MBytes before any possible rounding linked with the @code{precisions} attribute.

@end multitable

@section caches

By default, no cache is configured, but an example can be found in @file{lib/lmake/config.py}, commented out.

@multitable @columnfractions 0.1 0.07 0.83
@headitem Attribute @tab Default @tab Description
@item @code{caches.*.tag}
@tab -
@tab This attribute specifies the method used by @lmake to cache values.
In the current version, only 2 tags may be used :
@itemize @minus
@item @code{'none'} is a cache that caches nothing.
No further configuration is required for such a cache.
@item @code{'dir'} is a cache working without daemon.
The data are stored in a directory.
@end itemize
@item @code{caches.<dir>.repo}
@tab @code{lmake.repo_root}
@tab Valid only when @code{tag} is @code{'dir'}. This attribute specifies a key identifying the repository.
In order to avoid poluting the cache during typical edit-run-debug loops with data that will never be reused, the cache restrict its data to at most one entry for each job in each repo.
This attribute is used to identiy a repository.
If 2 repositories use the same key, then results produced in one will replace those produced in the other one.
Symetrically, if you use 2 different keys for the same repo, then the cache may store several entries for the same repo.
Besides these considerations, a classical LRU algorithm is used.
@item @code{caches.<dir>.dir}
@tab -
@tab Valid only when @code{tag} is @code{'dir'}.
This attribute specifies the directory in which the cache puts its data.
The directory must pre-exist and contain a file @file{LMAKE/size} containing the size the cache may occupy on disk.
The size may be suffixed by a unit suffix (k, M, G, T, P or E). These refer to base 1024.
@item @code{caches.<dir>.reliable_dirs}
@tab @code{False}
Same meaning as @code{config.reliable_dirs} for the directory containing the cache.
@tab Valid only when @code{tag} is @code{'dir'}.
@item @code{caches.<dir>.group}
@tab -
@tab Valid only when @code{tag} is @code{'dir'}.
This attribute specifies the group used when creating entries.
By default, the default group of the user is used.
@end multitable

@section debug

When @code{ldebug} is used, it consults this @code{dict}.
It maps debug keys to modules to import to implement the debug method (cf man ldebug).
Values contain the module name optionnaly followed by a human description (that will appear with @code{ldebug -h}) separated with spaces.

@chapter Sources

Sources are files that are deemed as intrinsic.
They cannot be derived using rules as explained in the following chapter.

Also, if a file cannot be derived and is not a source, it is deemed unbuildable, even if it actually exists.
In this later case, it will be considered dangling and this is an error condition.
The purpose of this restriction is to ensure repeatability : all buildable files can be (possibly indirectly) derived from sources using rules.

There are several ways to provide the list of sources (called the manifest) to @lmake :
@itemize
@item define @code{lmake.manifest}                : This must be a @code{tuple} or @code{list} listing the sources.
@item define a callable named @code{sources}      : The callable is called and, as a side effect, must define @code{lmake.manifest}.
@item implement a sub-module named @code{sources} : The sub-module is imported and, as a side effect, must define @code{lmake.manifest}.
@item do nothing                                  : @lmake calles the @code{lmake.sources.auto_sources()} function described below.
@end itemize

The manifest can contain :
@itemize
@item Files located in the repository.
@item Directories.
In that case, the whole subtree underneath the directory are considered sources.
Directories may be in the repository or outside, but cannot contain or lie within system directories such as @file{/usr}, @file{/proc}, @file{/etc}, etc.
If outside, they can be relative or absolute.
If the repository is moved, the relative/absolute semantic is enforced.
This is true for cache related aspects as well where comparison between job data located in different repositories must be performed.
@end itemize
In both cases, names must be canonical, i.e. contain no empty component nor @file{.}, nor @file{..} except initially for relative names.

The following helper functions can be used to provide sources.

Remember that @Lmakefile and, if needed, @file{Manifest} must be listed as sources.

@section @code{manifest_sources(manifest='Manifest',**kwds)} :

This function sets @code{lmake.manifest} from the content of the file provided in @code{manifest}.

@code{kwds} is ignored.

It raises a @code{FileNotFoundError} exception if @code{manifest} cannot be found.

@section @code{git_sources(recurse=True,ignore_missing_submodules=False,**kwds)} :

This function sets @code{lmake.manifest} by listing files managed by @code{git}.

If @code{recurse}, sub-modules are searched as well.

If @code{ignore_missing_submodules}, missing sub-modules are ignored rather than generating an error.

@code{kwds} is ignored.

It raises a @code{FileNotFoundError} exception if the repository is not controled by @code{git}.

@section @code{auto_sources(**kwds)} :

This function successively tries @code{manifest_sources} and @code{git_sources} by passing its @code{kwds} argument until one succeeds.

It raises a @code{FileNotFoundError} exception if none succeeds.


@chapter Rules

Rules are described as Python @code{class}'es inheriting from @code{lmake.Rule}, @code{lmake.AntiRule} or @code{SourceRule}.

Such classes are either defined directly in @Lmakefile or you can define a callable or a sub-module called @code{rules} that does the same thing when called/imported.
For example you can define :
@example
@group
def rules() :
	class MyRule(lmake.Rule) :
		target = 'my_target'
		cmd    = ''
@end group
@end example
Or the sub-module @code{Lmakefile.rules} containing such class definitions.

Inheriting from @code{lmake.Rule} is used to define production rules that allows deriving targets from dependencies.

Inheriting from @code{lmake.AntiRule} is (rarely) used to define rules that specify that matching targets @strong{cannot} be built.
Anti-rules only require the @code{targets} attribute (or those that translate into it, @code{target}, @code{post_targets} and @code{post_target}) and may usefully have a @code{prio} attribute.
Other ones are useless and ignored.

Inheriting from @code{lmake.SourceRule} may be used to define sources by patterns rather than as a list of files controlled by some sort of source-control (typically @code{git}).

In addition to user rules defined as described hereinafter, there are a certain number of special rules that applies systematically :

@multitable @columnfractions 0.1 0.9
@item Sources
@tab Sources are built in a special way : the disk is checked and if the file has been modified, the rule is triggered, which mostly does nothing except noticing the modification,
which may trigger other jobs.
This is typically the root reason why @lmake run jobs instead of doing nothing at all.
@item Uphill
@tab Any file is deemed as depending on its directory in a special way : if its directory is buildable, then the file is deemed not buildable.
This is logical : if file @file{foo} is buildable (i.e. produced as a regular file or a symbolic link), there is not way file @file{foo/bar} can be built.
If @file{foo} is produced as a regular file, this is the end of the story.
If it is produced as a symbolic link (say with @file{foo_real} as target), the dependent job will be rerun and it will then depend on @file{foo} and @file{foo_real/bar} when it opens @file{foo/bar}.
Note that if the directory applies as the star-target of a rule, then the corresponding job must be run to determine if said directory is, indeed, produced.
@item Infinite
@tab if walking the dependencies leads to infinite recursion, when the depth reaches @code{lmake.config.max_dep_depth}, this special rule is triggered which generates an error.
Also, if a file whose name is longer that @code{lmake.config.path_max} considered, it is deemed to be generated by this rule and it is in error.
This happens typically if you have a rule that, for example builds @code{@{File@}} from @code{@{File@}.x}.
If you try to build @file{foo}, @lmake will try to build @file{foo.x}, which needs @file{foo.x.x}, which needs @file{foo.x.x.x} etc.
@end multitable

Rules are described by a series of attribute as follows.

@section Dynamic values

Most attributes can either be data of the described type or a function taking no argument returning the desired value.
This allows the value to be dynamically selected depending on the job.

Such functions are evaluated in an environment in which the stems (as well as the @code{stems} variable which is a @code{dict} containing the stems
and the targets (as well as the @code{targets} variable) are defined and usable to derive the return value.
Also, depending on the attribute, the deps (as well as the @code{deps} variable) and the resources (as well as the @code{resources} variable) may also be defined.
Whether or not these are available depend on when a given attribute is needed.
For example, when defining the @code{deps}, the deps are obviously not available.

Generally, these functions are not supposed to do local disk accesses (i.e. from within the repository) as at the time they are called, such accessed files may not be up to date.
However, when @code{deps} are in the function environment, the listed files are up to date and can be accessed.
In the current release, these restrictions are not enforced by @lmake, but they will be in a future release.

For composite values (dictionaries or sequences), the entire value may be function or each value can individually be a function (but not the keys).
For dictionaries, if the value function returns @code{None}, there will be no corresponding entry in the resulting dictionary.

Note that regarding resources available in the function environment, the values are the ones instantiated by the backend.

@section @code{combine}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{set}
@item Default
@tab The list of attributes hereinafter described as having combined inheritance
@item Dynamic
@tab No.
@item Example
@tab @code{@{'my_dict_attribute'@}}
@end multitable

This attribute specify a set of attribute names to be processed with combined inheritance (cf @pxref{rule-inheritance}).

Combined attributes may only be @code{dict}, @code{set} and @code{list}.
@code{dict}'s and @code{set}'s are @code{update}d, @code{list}'s are @code{append}ed.
@code{dict}'s and @code{list}'s are ordered in MRO, base classes being after derived classes.

Note that this attribute is itself combined, and thus can easily be extended.

@section @code{paths}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{ 'environ.PATH':':' , 'environ.PYTHONPATH':':' , 'environ.LD_LIBRARY_PATH':':' @}}
@item Dynamic
@tab No.
@item Example
@tab @code{@{'environ_resources.LM_LICENSE_FILE':':'@}}
@end multitable

This attribute specify a set of entries in @code{dict} combined attributes (i.e. listed in the @code{combine} attribute) that must be handled by joining values with a separator.
When such an entry appear in a rule, its value is searched for occurrences of the special marker @code{...} surrounded by separators (the start and end of the strings are deemed to be separators)
And each such occurrence is replaced by the inherited value.

This makes it particularly useful to manage paths as it allows any intermediate base @code{class} to add its own entries, before or after the original ones.

For example, to add the directory @file{/mypath} after the inherited path, one would define the attribute @code{environ_md} as @code{@{'PATH':'...:/mypath'@}}.
To add it before, one would use @code{@{'PATH':'/mypath:...'@}}.

It is a @code{dict} whose keys are of the form <attribute>.<key> and values are the separator to use.

@section @code{name}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab None
@item Type
@tab @code{str}
@item Default
@tab @code{cls.__name__}
@item Dynamic
@tab No.
@item Example
@tab @code{'compile and link'}
@end multitable

This attribute specify a name for the rule.
This name is used each time @lmake needs to mention the rule in a message.

All rules must have a unique name.
Usually, the default value is fine, but if your rule is defined in a for loop for example,
then you have several definitions with the same @code{__name__} and you must distinguish them from each other with this attribute (usually an f-string with the loop index in it).

@section @code{virtual}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab None
@item Type
@tab @code{bool}
@item Default
@tab @code{True} if @code{cls} lacks the essential attributes to make it a rule (@code{targets} and, if not anti, @code{deps} and @code{cmd}).
@item Dynamic
@tab No.
@item Example
@tab @code{True}
@end multitable

When this attribute exists and has a @code{True} value, this @code{class} is not a rule and is only used as a base @code{class} to define concrete rules.

@section @code{prio}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{float}
@item Default
@tab @code{0} if inheriting from @code{lmake.Rule}, @code{float('+inf')} if deriving from @code{lmake.AntiRule}.
@item Dynamic
@tab No.
@item Example
@tab @code{1}
@end multitable

This attribute is used to order matching priority.
Rules with higher priorities are tried first and if none of them are applicable, rules with lower priorities are then tried (cf @pxref{rule-selection}).
However, @code{AntiRule}'s and @code{SourceRule}'s are always tried before plain rules.

@section @code{stems}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab No.
@item Example
@tab @code{@{'File':r'.*'@}}
@end multitable

Stems are regular expressions that represent the variable parts of targets which rules match.

Each entry <key>:<value> define a stem named <key> whose associated regular expression is <value>.

@section @code{job_name}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Dynamic
@tab No.
@item Default
@tab The first matching target of the most derived @code{class} in the inheritance hierarchy (i.e. the MRO) having a matching target.
@end multitable

This attribute may exceptionally be used for cosmetic purpose.
Its syntax is the same as target name (i.e. a target with no option).

When @lmake needs to include a job in a report, it will use this attribute.
If it contains star stems, they will be replaced by @code{*}'s in the report.

If defined, this attribute must have the same set of static stems (i.e. stems that do not contain *) as any matching target.

@section @code{targets}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab No.
@item Example
@tab @code{@{ 'OBJ' : '@{File@}.o' @}}
@end multitable

This attribute is used to define the regular expression which targets must match to select this rule (cf @pxref{rule-selection}).

Keys must be Python identifiers.
Values are @code{list}'s or @code{tuple}'s whose first item defines the target regular expression and following items define flags.
They may also be a simple @code{str} in which case it is as if there were no associated flags.

The regular expression looks like Python f-strings.
The fixed parts (outside @{@}) must match exactly.
The variable parts, called stems, are composed of :
@itemize @bullet
@item An optional name.
If it exists, it is used to ensure coherence with other targets and the @code{job_name} attribute, else coherence is ensured by position.
This name is used to find its definition in the stems @code{dict} and may also be used in the @code{cmd} attribute to refer to the actual content of the corresponding part in the target.
@item An optional *.
If it exists, this target is a star target, meaning that a single job will generate all or some of the targets matching this regular expression.
if not named, such stem must be defined.
@item An optional @code{:} followed by a definition (a regular expression).
This is an alternative to refering to an entry in the @code{stems} @code{dict}.
Overall, all stems must be defined somewhere (in the @code{stems} @code{dict}, in a target or in @code{job_name}) and if defined several times, definitions must be identical.
Also, when defined in a target, a definition must contain balanced @code{@{@}}'s, i.e. there must be as many @code{@{} as @code{@}}.
If a regular expression requires unbalanced @code{@{@}}, it must be put in a @code{stems} entry.
@end itemize

Regular expressions are used with the @code{DOTALL} flag, i.e. a @code{.} matches any character, including @code{\n}.

The flags may be any combination of the following flags, optionally preceded by - to turn it off.

@multitable @columnfractions 0.1 0.1 0.05 0.75
@headitem CamelCase @tab snake_case  @tab Default @tab Description
@item Essential     @tab essential   @tab Yes     @tab This target will be shown in a future graphic tool to show the workflow, it has no algorithmic effect.
@item Incremental   @tab incremental @tab No      @tab Previous content may be used to produce these targets.
In that case, these are not unlinked before execution.
However, if the link count is more than 1, they are uniquified, i.e. they are copied in place to ensure modification to the link does not alter other links.
@item Optional      @tab optional    @tab No      @tab If this target is not generated, it is not deemed to be produced by the job.
@lmake will try to find an alternative rule.
This is equivalent to being a star target, except that there is no star stem.
@item Phony         @tab phony       @tab No      @tab Accept that this target is not generated, this target is deemed generated even not physically on disk.
If a star target, do not search for an alternative rule to produce the file.
@item SourceOk      @tab source_ok   @tab No      @tab Do not generate an error if target is actually a source
@item NoUniquify    @tab no_uniquify @tab No      @tab If such a target has several hard links pointing to it, it is not uniquified (i.e. copied in place) before job execution.
@item NoWarning     @tab no_warning  @tab No      @tab Warning is not reported if a target is either uniquified or unlinked before job execution while generated by another job.
@item Top           @tab top         @tab No      @tab target pattern is interpreted relative to the root directory of the repository, else it is relative to the @code{cwd} of the rule.
@end multitable

All matching targets must have the same set of static stems (i.e. stems with no * in its name).

Matching is done by first trying to match static targets (i.e. which are not star) then star targets.
The first match will provide the associated stem definitions and flags.

Unless the @code{top} flag is set, the pattern is rooted to the sub-repo if the rule is defined in such a sub-repo.
If the @code{top} flag is set, the pattern is always rooted at the top-level repo.

@section @code{target}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str} or @code{list} or @code{tuple}
@item Default
@tab -
@item Dynamic
@tab No.
@end multitable

This attribute defines an unnamed target.
Its syntax is the same as any target entry except that it may not be @code{incremental}. Also, such a target may not be a @code{star} target.

During execution, @code{cmd} stdout will be redirected to this (necessarily unique since it cannot be a @code{star}) target.

The @code{top} flag cannot be used and the pattern is always rooted to the sub-repo if the rule is defined in such a sub-repo.

@section @code{side_targets}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab No.
@end multitable

This attribute is identical to @code{targets} except that :
@itemize @minus
@item the @code{ReadIsDep} or @code{read_is_dep} flag is available that transform files accessed read-only into deps rather than targets.
@item targets listed here do not trigger job execution, i.e. they do not participate to the rule selection process (cf @pxref{rule-selection}).
@item it not compulsery to use all static stems as this constraint is only necessary to fully define a job when selected by the rule selection process.
@end itemize

@section @code{deps}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab Yes. Environment includes stems and targets.
@item Example
@tab @code{@{ 'SRC' : '@{File@}.c' @}}
@end multitable

This attribute defines the static dependencies.
It is a @code{dict} which associates Python identifiers to files computed from the available environment.

They are f-strings, i.e. their value follow the Python f-string syntax and semantic
but they are interpreted when @lmake tries to match the rule (the rule only matches if static dependencies are buildable, cf @pxref{rule-selection}).
Hence they lack the initial @code{f} in front of the string.

Accessible variables when evaluating the f-string include the @code{stems}, the @code{targets}, attributes and the module dictionary.

Alternatively, values can also be @code{list} or @code{tuple} whose first item is as described above, followed by flags.

The flags may be any combination of the following flags, optionally preceded by - to turn it off when it is present by default.
Flags may be arbitrarily nested into sub-@code{list}'s or sub-@code{tuple}'s.

@multitable @columnfractions 0.1 0.1 0.05 0.75
@headitem CamelCase Flag @tab snake_case Flag @tab Default @tab Description
@item Essential          @tab essential       @tab Yes     @tab This dep will be shown in a future graphic tool to show the workflow, it has no algorithmic effect.
@item Critical           @tab critical        @tab No      @tab This dep is critial (cf @pxref{critical-deps}).
@item IgnoreError        @tab ignore_error    @tab No      @tab This dep may be in error, job will be launched anyway.
@item Required           @tab required        @tab No      @tab This dep is deemed to be read, even if not actually read by the job.
@item Top                @tab top             @tab No      @tab dep pattern is interpreted relative to the root directory of the repository, else it is relative to the @code{cwd} of the rule.
@end multitable

Flag order and dependency order are not significative.

Unless the @code{top} flag is set, the @code{cwd} attribute is prepended to the dep pattern in order to support hierarchical repository (cf @pxref{hierarchical-repositories}).

@section @code{dep}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Default
@tab -
@item Dynamic
@tab Yes. Environment includes stems and targets.
@end multitable

This attribute defines an unnamed static dependency.

During execution, @code{cmd} stdin will be redirected to this dependency, else it is @file{/dev/null}.

@section @code{side_deps}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab No.
@end multitable

This attribute is used to define flags to deps when they are acquired during job execution.
It does not declare a dep by itself.
Syntactically, it follows the @code{side_targets} attribute except that :
@itemize @minus
@item specified flags are dep flags rather than target flags.
@item an additional flag @code{Ignore} or @code{ignore} is available to mean that files matching this pattern must not be deps if accessed as read.
@end itemize

@section @code{order}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{list}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab No.
@end multitable

By default @code{target}, @code{side_targets} and @code{side_deps} are handled in this order (cf @pxref{targets-deps}).
If this order is inadequate, this attribute may be used to specify the order.
The order may be partial : other keys are put after the mentioned keys, keeping their relative order.

@section @code{chroot_dir}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Default
@tab @code{None}
@item Dynamic
@tab Yes. Environment includes stems, targets and deps.
@end multitable

This attribute defines a directory in which jobs will @code{chroot} into before execution begins.
It must be an absoluted path (e.g. @code{'/ubuntu22.04'}).

Note that unless the @code{repo_view} is set, the repository must be visible under its original name in this chroot environment.

If @code{None}, @code{''}, @code{'/'}, no @code{chroot} is performed unless required to manage the @code{tmp_view} and @code{repo_view} attributes (in which case it is transparent).
However, if @code{'/'}, namespaces are used nonetheless (cf @pxref{namespaces}).

@section @code{repo_view}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Default
@tab @code{None}
@item Dynamic
@tab Yes. Environment includes stems, targets and deps.
@end multitable

This attribute defines a directory in which jobs will see the top-level directory of the repo (the root directory).
This is done by using @code{mount -rbind} (cf @pxref {namespaces}).

It must be an absolute path not lying in the temporary directory (e.g. @code{'/repo'}).

If @code{None} or @code{''}, no bind mount is performed.

If performed, @code{$TOP_REPO_ROOT} will reflect this value.

As of now, this attribute must be a top level directory, i.e. @file{'/a'} is ok, but @file{'/a/b'} is not.

@section @code{tmp_view}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Default
@tab @code{None}
@item Dynamic
@tab Yes. Environment includes stems, targets and deps.
@end multitable

This attribute defines the name which the temporary directory available for job execution is mounted on (cf @pxref {namespaces}).

If @code{None}, @code{''} or not specified, this directory is not mounted.
Else, it must be an absolute path.

As of now, this attribute must be a top level directory, i.e. @file{'/a'} is ok, but @file{'/a/b'} is not.

The physical directory is :
@itemize
@item If @lmake is supposed to keep this directory after job execution, it is a directory under @file{LMAKE/tmp}, determined by @lmake (its precise value is reported by @code{lshow -i}).
@item Else if @code{$TMPDIR} is specified in the environment of the job, it is used. Note that it need not be unique as @lmake will create a unique sub-directory within it.
@item Else, a directory determined by @lmake lying in the @file{LMAKE} directory.
@end itemize

Unless @lmake is instructed to keep this directory, it is erased at the end of the job execution.

Note that in all cases, @code{$TMPDIR} is set so that the job can use it to access the tmp directory.

@section @code{views}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab Yes. Environment includes stems, targets and deps.
@end multitable

This attribute defines a mapping from logical views to physical directories.
Accesses to logical views are mapped to their corresponding physical location. Views and physical locations may be dirs or files depending on whether they end with a @code{/} or not.
Files must be mapped to files and directories to directories.
Both logical views and physical locations may be inside or outside the repository, but it is not possible to map an external view to a local location.
Physical description may be :
@itemize @minus
@item a @code{str} in which case a bind mount is performed.
@item a @code{dict} with keys @code{upper} (a @code{str}) and @code{lower} (a single @code{str} or a list of @code{str}) in which case an overlay mount is performed.
Key @code{copy_up} (a single @code{str} or a list of @code{str}) may also be used to provide a list of directories to create in upper or files to copy from lower to upper.
Directories are recognized when they end with @code{/}.
Such @code{copy_up} items are provided relative to the root of the view.
@end itemize
The mapping is done through bind mounts (cf @pxref {namespaces}).

@section @code{environ}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab See description
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@item Example
@tab @code{@{ 'MY_TOOL_ROOT' : '/install/my_tool' @}}
@end multitable

This attribute defines environment variables set during job execution.

The content of this attribute is managed as part of the job command, meaning that jobs are rerun upon modification.
This is the normal behavior, other means to define environment are there to manage special situations.

The environment in which the @lmake command is run is ignored so as to favor reproducibility, unless explicitly transported by using value from @code{os.environ}.

If resulting value is @code{...} (the Python ellipsis), the value from the execution environment is used.
This is typically used to access some environment variables set by @code{slurm}.

If a value contains the strings @code{$LMAKE_ROOT}, @code{$REPO_ROOT}, @code{$TOP_REPO_ROOT} or @code{$TMPDIR}, these parts are substituted by their respective definitions.
They must be isolated words or surrounded by braces (e.g. @code{$@{LMAKE_ROOT@}}).

By default the following environment variables are defined :
@table @code
@item HOME in Rule
The root directory of the repository, so as to prevent tools from accessing startup files that may vary from user to user.
Necessary startup files can be put inside the repository, administered with your prefered versioning tool as any other source.
In @code{HomelessRule}, it is defined as the temporary directory.
@item PATH in Rule
The standard path with @lmake bin directory in front.
The standard path is the one you get with the standard shell in absence of any startup file.
@item PYTHONPATH in PyRule
The @lmake lib directory.
@end table

Note that the current environment is accessible when @Lmakefile is read, so that it is quite simple to copy some variables from the user environment
although this practice is discouraged and should be used with much care.

@section @code{environ_resources}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@item Example
@tab @code{@{ 'MY_TOOL_LICENCE' : '12345' @}}
@end multitable

This attribute defines environment variables set during job execution.

The content of this attribute is managed as resources, meaning that jobs in error are rerun upon modification, but not jobs that were successfully built.

The values undertake the same substitutions as for the @code{environ} attribute described above.

The environment in which the @lmake command is run is ignored so as to favor reproducibility.

Note that the current environment is accessible when @Lmakefile is read, so that it is quite simple to copy some variables from the user environment
although this practice is discouraged and should be used with much care.

If resulting value is @code{...} (the Python ellipsis), the value from the execution environment is used.
This is typically used to access some environment variables set by @code{slurm}.

@section @code{environ_ancillary}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab See description
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@item Example
@tab @code{@{ 'DISPLAY' : ':10' @}}
@end multitable

This attribute defines environment variables set during job execution.

The content of this attribute is not managed, meaning that jobs are not rerun upon modification.

The values undertake the same substitutions as for the @code{environ} attribute described above.

The environment in which the @lmake command is run is ignored so as to favor reproducibility.

By default the following environment variables are defined :
@table @code
@item UID
The user id.
@item USER
The user login name.
@end table

Note that the current environment is accessible when @Lmakefile is read, so that it is quite simple to copy some variables from the user environment
although this practice is discouraged and should be used with much care.

If resulting value is @code{...} (the Python ellipsis), the value from the execution environment is used.
This is typically used to access some environment variables set by @code{slurm}.

@section @code{python}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{list} or @code{tuple}
@item Default
@tab system Python
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute defines the interpreter used to run the @code{cmd} if it is a @code{function}.
At the end of the supplied executable and arguments, @code{'-c'} and the actual script is appended, unless the @code{use_script} attribut is set.
In the later case, a file that contains the script is created and its name is passed as the last argument without a preceding @code{-c}.

@lmake uses Python 3.6+ to read @file{Lmakefile.py}, but that being done, any interpreter can be used to execute @code{cmd}.
In particular, Python2.7 and all revisions of Python3 are fully supported.

@section @code{shell}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{list} or @code{tuple}
@item Default
@tab @code{/bin/bash}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute defines the interpreter used to run the @code{cmd} if it is a @code{str}.
At the end of the supplied executable and arguments, @code{'-c'} and the actual script is appended.

@section @code{cmd}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{function} or @code{str}
@item Default
@tab -
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources. See description, though, if it is defined as a function.
@item Example1
@tab @code{'gcc -c -o @{OBJ@} @{SRC@}'}
@item Example2
@tab @code{def cmd() : subprocess.run(('gcc','-c','-o',OBJ,SRC,check=True))}
@end multitable

Whether @code{cmd} is a @code{str} or a @code{function}, the following environment variable are automatically set, if not explicitly set by the @code{environ} attribute :
@itemize @minus
@item @code{$LD_AUDIT}          : A variable necessary for autodep if the @code{autodep} attribute is set to @code{'ld_audit'} (cf @pxref{autodep}).
@item @code{$LD_PRELOAD}        : A variable necessary for autodep if the @code{autodep} attribute is set to @code{'ld_preload'} or @code{'ld_preload_jemalloc'} (cf @pxref{autodep}).
@item @code{$LMAKE_AUTODEP_ENV} : A variable necessary for the autodep mechanism of @lmake, it must stay present and untouched (cf @pxref{autodep}).
@item @code{$REPO_ROOT}         : The root of the (sub-)repository.
@item @code{$TOP_REPO_ROOT}     : The root of the top-level repository.
@item @code{$SEQUENCE_ID}       : A value which is unique for each run.
It is @code{1} initially and is incremented each time a job is run.
@item @code{$SMALL_ID}          : A value which is unique among running job at any given time.
It is always at least @code{1} and efforts are made to maintain it as small as possible.
@item @code{$TMPDIR}            : The name of a directory which is empty at the start of the job.
If the temporary directory is not kept through the use of the @code{keep_tmp} attribute or the @code{-t} option, this directory is cleaned up at the end of the job execution.
@item @code{$HOME}              : This variable is set to the value of the TMPDIR variable if not set.
However it is set by default to the root of the repository by the @code{Rule} base class.
@end itemize

@subsection if it is a @code{function}

In that case, this attribute is called to run the job.
Combined inheritance is a special case for @code{cmd}.

If several definitions exist along the MRO, They must all be @code{function}'s and they are called successively in reverse MRO.
The first (i.e. the most basic) one must have no non-defaulted arguments and will be called with no argument.
The other ones may have arguments, all but the first having default values.
In that case, such @code{function}'s are called with the result of the previous one as unique argument.
Else, if a @code{function} has no argument, the result of the previous function is dropped.

During evaluation, when the job runs, its global @code{dict} is populated to contain values referenced in these @code{function}'s.
Values may come from (by order of preference) :
@itemize @minus
@item The @code{stems}, @code{targets}, @code{deps}, @code{resources} as named in their respective @code{dict}.
@item @code{stems}, @code{targets}, @code{deps}, @code{resources} that contain their respective whole @code{dict}.
@item Any attribute defined in the class, or a base class (as for normal Python attribute access).
@item Any value in the module @code{dict}.
@item Any builtin value
@item undefined variables are not defined, which is ok as long as they are not accessed.
@end itemize

Because jobs are executed remotely using the interpreter mentioned in the @code{python} attribute
and to avoid depending on the whole @Lmakefile (which would force to rerun all jobs as soon as any rule is modified),
these @code{function}'s and their context are serialized to be transported.
The serialization process may improve over time but as of today, the following applies :
@itemize @minus
@item Basic objects are transported as is : @code{None}, @code{...}, @code{bool}, @code{int}, @code{float}, @code{complex}, @code{str}, @code{bytes}.
@item @code{list}, @code{tuple}, @code{set} and @code{dict} are transported by transporting their content. Note that reconvergences (and a fortiori loops) are not handled.
@item @code{function}'s are transported as their source accompanied with their context : global accessed variables and default values for arguments.
@item Imported objects (@code{function}'s and @code{class}'es and generally all objects with a @code{__qualname__} attribute) are transported as an @code{import} statement.
@item Builtin objects are transported spontaneously, without requiring any generated code.
@end itemize

Values are captured according to the normal Python semantic, i.e. once the @code{Lmakefile} module is fully imported.
Care must be taken for variables whose values change during the @code{import} process.
This typically concerns loop indices.
To capture these at definition time and not at the end, such values must be saved somewhere.
There are mostly 2 practical possibilities :
@itemize @minus
@item Declare an argument with a default value. Such default value is saved when the function is defined.
@item Define a class attribute. Class attributes are saved when its definition ends, which is before a loop index.
@end itemize

The job is deemed to be successful if the last function returns a false value.

@subsection if it is a @code{str}

In that case, this attribute is executed as a shell command to run the job.
Combined inheritance is a special case for @code{cmd}.
While walking the MRO, if for a base class @code{cmd} is defined as a @code{function} and it has a @code{shell} attribute, the value of this attribute is used instead.
The purpose is that it is impossible to combine @code{str}'s and @code{function}'s because they use different paradigms.
As a consequence, a base class may want to have 2 implementations, one for subclasses that use Python @code{cmd} and another for subclasses that use shell @code{cmd}.
For such a base class, the solution is to define @code{cmd} as a @code{function} and set its @code{shell} attribute to the @code{str} version.

If several definitions exist along the MRO, They must all be @code{str}'s and they are run successively in reverse MRO in the same process.
So, it is possible for a first definition to define an environment variable that is used in a subsequent one.

As for other attributes that may be dynamic, @code{cmd} is interpreted as an f-string.

The job is deemed to be successful if the return code of the overall process is @code{0}.

@section @code{cache}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Constraint
@tab One of the caches listed in config.
@item Default
@tab <not cached>
@item Dynamic
@tab Yes. Environment includes stems, targets.
@end multitable

This attribute specifies the cache to use for jobs executed by this rule.
When a job is executed, its results are stored in the cache.
If space is needed (all caches are constrained in size), any other entry can be replaced.
The cache policy (described in its own section, in the config chapter) tries to identify entries that are likely to be useless in the future.

@section @code{compression}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{int}
@item Constraint
@tab between @code{0} and @code{9}
@item Default
@tab 0
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute specifies the compression level used when caching.
It is passed to the zlib library used to compress job targets.
@code{0} means no compression.
@code{9} means maximum compression.

@section @code{backend}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Constraint
@tab One of the supported backends.
@item Default
@tab @code{'local'}
@item Dynamic
@tab Yes. Environment includes stems, targets and deps.
@end multitable

This attribute specifies the backend to use to launch jobs (cf @pxref{backends}).

@section @code{autodep}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Constraint
@tab One of @code{'none'}, @code{'ld_audit'}, @code{'ld_preload'}, @code{'ld_preload_jemalloc'} or @code{'ptrace'}
@item Default
@tab @code{'ld_audit'} if supported else @code{'ld_preload'}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute specifies the method used by autodep (cf @pxref{autodep}) to discover hidden dependencies.

@section @code{resources}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab Yes. Environment includes stems, targets and deps.
@item Example
@tab @code{@{ 'MY_RESOURCE' : '1' @}}
@end multitable

This attribute specifies the resources required by a job to run successfully.
These may be cpu availability, memory, commercial tool licenses, access to dedicated hardware, ...

The syntax is the same as for @code{deps}, except that in addition to other variables, deps can be referenced.

After interpretation, the @code{dict} is passed to the @code{backend} to be used in its scheduling (cf @pxref{local-backend} for the local backend).

@section @code{max_stderr_len}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{int}
@item Default
@tab @code{100}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps.
@end multitable

This attribute defines the maximum number of lines of stderr that will be displayed in the output of @lmake.
The whole content of stderr stays accessible with the @code{lshow -e} command.

@section @code{allow_stderr}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute has a false value, the simple fact that a job generates a non-empty stderr is an error.
If it is @code{True}, writing to stderr is allowed and does not produce an error. The @lmake output will exhibit a warning, though.

@section @code{auto_mkdir}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute has a @code{True} value, executing a @code{chdir} syscall (e.g. executing @code{cd} in bash) will create the target directory if it does not exist.

This is useful for scripts in situations such as :
@itemize @minus
@item The script does @code{chdir a}.
@item Then try to read file @file{b} from there.
@item What is expected is to have a dependency on @file{a/b} which may not exist initially but will be created by some other job.
@item However, if directory @file{a} does not exist, the @code{chdir} call fails and the file which is open for reading is @file{b} instead of @file{a/b}.
@item As a consequence, no dependency is set for @file{a/b} and the problem will not be resolved by a further re-execution.
@item Setting this attribute to @code{True} creates directory @file{a} on the fly when @code{chdir} is called so that it succeeds and the correct dependency is set.
@end itemize

@section @code{keep_tmp}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute is set to a true value, the temporary directory is kept after job execution.
It can be retreived with @code{lshow -i}.
Sucessive executions of the same job overwrite the temporary directory, though, so only the content corresponding to the last execution is available.
When this attribute has a @code{False} value, the temporary directory is washed at the end of the job execution.

@section @code{force}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab No.
@end multitable

When this attribute is set to a @code{True} value, jobs are always considered out-of-date and are systematically rerun if a target is needed.
It is rarely necessary.

@section @code{max_submits}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{int}
@item Default
@tab @code{10}
@item Dynamic
@tab No.
@end multitable

This attribute specifies the maximum number of times a job can be submitted for a single @lmake command.
The goal is to protect agains potential infinite loop cases.
The default value should be both comfortable (avoid hitting it in normal situations) and practical (avoid too many submissions before stopping).

@section @code{timeout}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{float}
@item Constraint
@tab >=0
@item Default
@tab no timeout
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute has a non-zero value, job is killed and a failure is reported if it is not done before that many seconds.

@section @code{start_delay}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{float}
@item Default
@tab @code{3}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute is set to a non-zero value, start lines are only output for jobs that last longer than that many seconds.
The consequence is only cosmetic, it has no other impact.

@section @code{kill_sigs}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{list} or @code{tuple}
@item Default
@tab @code{(signal.SIGKILL,)}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute provides a list of signals to send the job when @lmake decides to kill it.
A job is killed when :
@itemize @minus
@item @kbd{^C} is hit if it is not necessary for another running @lmake command that has not received a @kbd{^C}.
@item When timeout is reached.
@item When @code{check_deps} is called and some dependencies are not up to date.
@end itemize

The signals listed in this list are sent in turn, once every second.
Longer interval can be obtained by inserting @code{0}'s. @code{0} signals are not sent and anyway, these would have no impact if they were.

If the list is exhausted and the job is still alive, a more agressive method is used.
The process group of the job, as well as the process group of any process connected to a stream we are waiting for, are sent @code{SIGKILL} signals instead of just the process group of the job.
The streams we are waiting for are @code{stderr}, and @code{stdout} unless the @code{target} attribute is used (as opposed to the @code{targets} attribute)
in which case @code{stdout} is redirected to the the target and is not waited for.

Note: some backends, such as slurm, may have other means to manage timeouts. Both mechanisms will be usable.

@section @code{max_retries_on_lost}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{int}
@item Default
@tab @code{1}
@item Dynamic
@tab No.
@end multitable

This attribute provides the number of allowed retries before giving up when a job is lost.
For example, a job may be lost because of a remote host being misconfigured, or because the job management process (called @code{job_exec}) was manually killed.

In that case, the job is retried, but a maximum number of retry attemps are allowed, after which the job is considered in error.

@section @code{use_script}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute commands an implementation detail.
If false, jobs are run by launching the interpreter followed by @code{-c} and the command text.
If true, jobs are run by creating a temporary file containing the command text, then by launching the interpreter followed by said file name.
If the size of the command text is too large to fit in the command line, this attribute is silently forced true.

@chapter The @file{LMAKE} directory

This directory contains numerous information that may be handy for the user.

It also contains a @file{lmake} directory containing data for @lmake's own private usage.

@section @file{LMAKE/config}

This file contains a description of the @code{lmake.config} @code{dict} as it has been understood by @lmake after having processed @Lmakefile.

@section @file{LMAKE/rules}

This file contains a description of the rules as it has been understood by @lmake after having processed @Lmakefile.

@section @file{LMAKE/manifest}

This file contains a description of the sources as it has been understood by @lmake after having processed @Lmakefile.

@section @file{LMAKE/config_deps}

This file contains a list of files that @lmake has read to process @Lmakefile.
Each line contains a file, preceded by a @code{+} if file exists or a @code{!} if it does not.

@section @file{LMAKE/rules_deps}

If a callable or a sub-module has been set to define rules, this file contains a list of files that @lmake has read to process it.
Each line contains a file, preceded by a @code{+} if file exists or a @code{!} if it does not.

@section @file{LMAKE/sources_deps}

If a callable or a sub-module has been set or if using the default behavior to list sources, this file contains a list of files that @lmake has read to process it.
Each line contains a file, preceded by a @code{+} if file exists or a @code{!} if it does not.

@section @file{LMAKE/outputs/<date>/<time>}

This file contains a transcript of the @lmake command that has been run at @file{<time>} on @file{<day>}.
Such logs are kept for a number of days given in @code{lmake.config.console.history_days}.

@section @file{LMAKE/last_output}

This file is a symbolic link to the last transcript.

@section @file{LMAKE/targets}

This file contains the targets that have been required by @lmake commands in chronological order (with duplicates removed).

@section @file{LMAKE/quarantine}

This directory contains all files that have been quarantined.
A file is quantantined when @lmake decides it must be unlinked and it contains manual modifications, i.e. modifications made outside the control of @lmake.
In that case, in order to be sure that no user work is lost, the file is quarantined in this directory rather than unlinked.

@chapter Some considerations

This chapter contains some considerations that appear in several places of this documentation.
It is meant to be the target of cross-references.

@anchor{rule-inheritance}
@section Rule inheritance

Rules are Python @code{class}'es that inherit from @code{lmake.Rule} (or @code{lmake.AntiRule} or @code{lmake.SourceRule}).

However, Python's native inheritance mechanism is not ideal to describe a rule as one would like to prepare a base @code{class} such as :
@itemize @minus
@item provide environment variables
@item provide some default actions for some files with given pattern
@item provide some automatic dependencies
@item ...
@end itemize

As these are described with @code{dict}, you would like to inherit @code{dict} entries from the base @code{class} and not only the @code{dict} as a whole.
A possibility would have been to use the @code{__prepare__} method of a meta-class to pre-define inherited values of such attributes,
but that would defeat the practical possibility to use multiple inheritance by suppressing the diamond rule.

The chosen method has been designed to walk through the MRO at class creation time and :
@itemize @minus
@item Define a set of attributes to be handled through combination. This set is defined by the attribute @code{combine}, itself being handled by combination.
@item Combined attribute are handled by updating/appending rather than replacing when walking through MRO in reverse order.
@item Entries with a value None are suppressed as update never suppress a given entry.
Similarly, values inserted in a set prefixed with a @code{'-'} remove the corresponding value from the @code{set}.
@end itemize

Because this mechanism walks through the MRO, the diamond rule is enforced.

@code{dict}'s and @code{list}'s are ordered so that the most specific information appear first, as if classes are searched in MRO.

@anchor{regexpr}
@section Regular expressions
Internally, @lmake uses a regular expression library, that may change with versions, but which are always very close to the Python @code{re} module.

As of today, the standard @code{std::regex} package is used with the @code{ECMASript} grammar.
The following differences with Python @code{re} are known :
@itemize @bullet
@item named groups are not supported.
There are hardly any reason to use named groups in stems.
This would allow back references as number based back references cannot be used as one cannot know what number to use.
However, the same stem can be used several time and all but the first one will be back references to the first one.

For example if you want to match files such as @file{image/image_small.jpg} and @file{image/image_big.jpg}, you can use @code{'@{Image:\w+@}/@{Image@}_@{Size:\w+@}.jpg'}.
A file such as @file{image1/image2_big.jpg} will not match.
@item braces (@code{@{@}}) are sometimes recognized as literal braces by Python, even when not escaped with @code{\}.
This is not the case with @code{std::regex}, they always must be escaped.
@end itemize

@anchor{targets-deps}
@section Handling an access
At first glance, recognizing a target from a dep when a job runs seems pretty easy when the accesses to the disk can be traced : reading a file is a dep, writing to it is a target.
And this is what is done informally, but there are a lot of corner cases.

The specification devised hereinafter has been carefully thought to allow @lmake to run adequate jobs to reach a stable state from any starting point.
More specifically, think of the following sequence :
@itemize @minus
@item @code{git clean -ffdx}
@item @code{lmake foo}
@item @code{git pull}
@item @code{lmake foo}
@end itemize

The second @code{lmake foo} command is supposed to do the minimum work to reach the same content of @file{foo} as would be obtained with the sequence :
@itemize @minus
@item @code{git pull}
@item @code{git clean -ffdx}
@item @code{lmake foo}
@end itemize

This what stable state means : the content of @file{foo} is independent of the history and only depends on the rules and the content of sources, both being managed through @code{git} in this example.

In this specification, directories are ignored (i.e. the presence or content of a directory has no impact) and symbolic links are similar to regular files whose content is the link itself.

@subsection Reading and writing files
The first point is to precisely know what reading and writing mean.

Writing to file @file{foo} means :
@itemize
@item A system call that writes or initiate writing to @file{foo}, e.g. @code{open("foo",O_WRONLY|O_TRUNC)} or @code{symlink(...,"foo")},
assuming the @code{autodep} rule attribute is not set to @code{'none'}.
@item Unlinking @file{foo}, e.g. @code{unlink("foo")}, is also deemed to be writing to it.
@item A call to @code{lmake.target('foo',write=True)}. Note that @code{True} is the default value for the @code{write} argument.
@item The execution of @code{ltarget foo} in which the @code{-W} option is not passed.
@item Under the condition that these actions are not preceded by a call to @code{lmake.target('foo',ignore=True)} or the execution of @code{ltarget -I foo}.
@item Also under the condition that @file{foo} does not match a @code{targets} or @code{side_targets} entry with the @code{Ignore} flag set.
@item Also under the condition that @file{foo} lies in the repository (i.e. under the directory containing @file{Lmakefile.py} but not in its @file{LMAKE} sub-directory).
@end itemize

Reading file @file{foo} means :
@itemize
@item A system call that reads or initiate reading @file{foo}, e.g. @code{open("foo",O_RDONLY)}, @code{readlink("foo",...)} or @code{stat("foo",...)},
assuming the @code{autodep} rule attribute is not set to @code{'none'}.
@item Unless the @code{config.link_support} attribute is set to @code{'none'},
any access (reading or writing) to @file{foo} which follows symlinks is an implicit @code{readlink}.
@item Unless the @code{config.link_support} attribute is set to @code{'file'} or @code{'none'},
any access (reading or writing) to @file{foo}, whether it follows symlinks or not, is an implicit @code{readlink} of all directories leading to it.
@item Note that some system calls can be both a read and a write, e.g. @code{open("foo", O_RDWR)} but also @code{rename("foo",...)}.
In that case, the read occurs before the write.
@item A call to @code{lmake.depend('foo',read=True)}. Note that @code{True} is the default value for the @code{read} argument.
@item The execution of @code{ldepend foo} in which the @code{-R} option is not passed.
@item Under the condition that these actions are not preceded by a call to @code{lmake.depend('foo',ignore=True)} or the execution of @code{ldepend -I foo}.
@item Also under the condition that @file{foo} is not listed in @code{deps} or matches a @code{side_deps} entry, with the @code{Ignore} flag set.
@item Also under the condition that @file{foo} lies in the repository (i.e. under the directory containing @file{Lmakefile.py} but not in its @file{LMAKE} sub-directory) or in a source directory.
@end itemize

@subsection Being a target
A file may be a target from the begining of the job execution, or it may become a target during job execution.
In the latter case, it is not a target until the point where it becomes one.
A file cannot stop being a target : once it has become a target, this is until the end of the job execution.

A file is a target from the begining of the job execution if it matches a @code{targets} or @code{side_targets} entry.

A file becomes a target when it is written to (with the meaning mentioned above) or when @code{lmake.target} or @code{ltarget} is called.

@subsection Being a dep
A file may be a dep from the begining of the job execution, or it may become a dep during job execution.

A file cannot stop being a dep : once it has become a dep, this is until the end of the job execution.

A file is a dep from the begining of the job execution if it listed as a @code{deps} in the rule.

A file becomes a dep when it is read (with the meaning mentioned above) while not a target at that time.

@subsection Errors
Some cases lead to errors, independently of the user script.

The first case is when there is clash between static declarations.
@code{targets}, @code{side_targets}, @code{side_deps} entries may or may not contain star stems.
In the latter case, and including the static deps listed in @code{deps}, they are static entries.
It is an error if the same file is listed several times as a static entry.

The second case is when a file is both a dep and a target.
You may have noticed that the definition above does not preclude this case, mostly because a file may start its life as a dep and become a target.
This is an error unless the file is finally unlinked (or was never created).

The third case is when a target was not declared as such.
@file{foo} can be declared as target by :
@itemize
@item matching a @code{targets} or @code{side_targets} entry.
@item calling @code{lmake.target('foo',allow=True} (which is the default value for the @code{allow}).
@item executing @code{ltarget foo} in which the @code{-a} option is not passed.
@end itemize
A target that is not declared is an error.

@subsection Processing a target
Targets are normally erased before the start of the job execution, unless they are sources or flagged as @code{incremental}.
In case a target is also a dep, it is automatically flagged as @code{incremental}, whether it is an error or not.

If a job is run when a not @code{incremental} and not source target exists, it is deemed unreliable and is rerun.

@subsection Best effort

@lmake tries to minimize the execution of jobs, but may sometimes miss a point and execute a job superfluously.
This may include erasing a file that has no associated production rule.
Unless a file is a dep of no job, @lmake may rebuild it at any time, even when not strictly necessary.

In the case @lmake determines that a file may have actually been written manually outside its control, it fears to overwrite a user-generated content.
In that case, @lmake quarantines the file under the @file{LMAKE/quarantine} directory with its original name.
This quarantine mechanism, which is not necessary for @lmake processing but is a facility for the user, is best effort.
There are cases where @lmake cannot anticipate such an overwrite.

@anchor{namespaces}
@section Namespaces

Namespaces are used to isolate jobs.
This is used to provide the semantic for the @code{chroot_dir}, @code{repo_view}, @code{tmp_view} and @code{views} attributes.

In that case, pid's are also isolated which allow reliable job end : when the top-level process exits, the namespaces are destroyed and no other process can survive.
This guarantees that no daemon is left behind, uncontrolled.

Note that this is true even when @code{chroot_dir} is @code{'/'}, which otherwise provides no other effect by itself.

Namespaces can be used in the following situations :
@itemize @bullet
@item @lmake provides a cache mechanism allowing to prevent executing a job which was already executed in the same or another repository.
However, some jobs may use and record absolute paths.
In that case, the cache will be inefficient as the result in a repository is not identical to the one in another repository.
This is current practice, in particular in the EDA tools community (which may be rather heavy and where caching is mostly desirable).
Using the @code{repo_view} attribute is a good way to work around this obstacle.
@item @lmake tracks all dependencies inside the reposity and listed source directories. But it does not track external dependencies, typically the system (e.g.the @file{/usr} directory).
However, the @code{chroot_dir} attribute is part of the command definition and a job will be considered out of date if its value is modified.
Hence, this can be used as a marker representing the whole system to ensure jobs are rerun upon system updates.
@item some softwares (e.g. EDA tools) are designed to operate on a directory rather than dealing with input files/directories and output files/directories.
This goes against reentrancy and thus reliability, repeatability, parallelism etc.
This problem can be solved with symbolic links if they are allowed.
In all cases, it can be solved by using the @code{tmp_view} and copying data back and forth between the repository and the tmp directory.
Or, more efficient, it can be solved by adequately mapping a logical steady file or directory to a per job physical file or directory (respectively).
@end itemize

@anchor{backends}
@section Backends

Backends are in charge of actually launching jobs when the @lmake engine has identified that it had to be run.
It is also in charge of :
@itemize @minus
@item Killing jobs when the @lmake engine has identified it had to be so.
@item Scheduling jobs so as to optimize the runtime, based on some indications provided by the @lmake engine.
@item Rescheduling jobs when new scheduling indications becomes available.
@end itemize

A backend has to take decisions of 2 kinds :
@itemize @minus
@item Is a job eligible for running ?
From a dependency perspective, the @lmake engine guarantees it is so.
But the job needs some resources to run and these resources may already be busy because of some other jobs already running.
@item If several jobs are eligible, which one(s) to actually launch.
@end itemize

Each backend is autonomous in its decisions and has its own algorithm to take them.
However, generally speaking, they more or less work by following the following principles :
@itemize @minus
@item For the first question, the backend maintain a pool of available resources and a job is eligible if its required resources can fit in the pool.
When launched, the required resources are subtracted from the pool and when terminated, they are returned to it.
@item For the second question, each job has an associated pressure provided by the @lmake engine and the backend actually launches the eligible job with the highest pressure.
@end itemize

The required resources are provided by the @lmake engine to the backend as a @code{dict} which is the one of the job's rule after f-string interpretation.

The pressure is provided in the form of @code{float} computed as the accumulated ETE along the critical path to the final targets asked on the @lmake command line.
To do that, future job ETE have to be estimated.
For jobs that have already run, last successful execution time is used.
When this information is not available, i.e. when the job has never run successfully, a moving average of the execution times of the jobs sharing the same rule is used as a best guess.

The @lmake backend also provides the current ETA (cf @pxref{eta-estimation}) of the final targets to allow the backends from different repository to take the best collective decision.

In addition to dedicated resources, all backends manage the following 3 resources :
@itemize @minus
@item @code{cpu} : The number of threads the job is expected to run in parallel. The backend is expected to reserve enough resources for such a number of threads to run smoothly.
@item @code{mem} : The memory size the job is expected to need to run smoothly.
The backend is expected to ensure that such memory is available for the job.
Unit must be coherent with the one used in the configuration. It is MB by default.
@item @code{tmp} : The size of necessary temporary disk space.
By default temporary disk space is not managed, i.e. @code{$TMPDIR} is set (to a freshly created empty empty dir which is cleaned up after execution)
with no size limit (other than the physical disk size) but no reservation is made in the backend.
@end itemize

@anchor{local-backend}
@section Local backend

The local backend launches jobs locally, on the host running the @lmake command.
There is no cooperation between backends from different repositories and the user has to ensure there is no global resource conflict.

This backend is configured by providing entries in the @code{lmake.config.backends.local} @code{dict}.
The key identifies the resource and the value is a @code{int} that identifies a quantity.

The local backend is used when either :
@itemize @minus
@item The @code{backend} attribute is @code{'local'} (which is the default value).
@item @code{lmake} is launched with the the @code{--local} option.
@item The required backend is not supported or not available.
@end itemize
In the two later cases, required resources are translated into local resources (best effort)
and if not possible (e.g. because a resource is not available locally or because special constraints cannot be translated), then only one such job can run at any given time.

Each rule whose @code{backend} attribute is @code{'local'} provides a @code{resources} attribute such that :
@itemize @minus
@item The key identifies a resource (which must match a resource in the configuration).
@item The value (possibly tailored by job through the use of the f-string syntax) is a @code{int} or a @code{str} that can be interpreted as @code{int}.
@end itemize
The variable available to the job as global variables (python case) or environment variables (shell case) contains the actual quantity of resources allocated to this job.

The local backend ensures that the sum of all the resources of the running jobs never overshoots the configured available quantity.

By default, the configuration contains the 2 generic resources : @code{cpu} and @code{mem} configured respectively as the overall number of available cpus and the overall available memory (in MB).
@itemize @minus
@item @code{cpu} : The number of cpu as returned by @code{os.wched_getaffinity(0)}.
@item @code{mem} : The physical memory size as returned by @code{s.sysconf('SC_PHYS_PAGES')*os.sysconf('SC_PAGE_SIZE')} in MB.
@end itemize
Each rule has a default @code{resources} attribute requiring one CPU.

@section SGE backend

The SGE backend connects to a SGE daemon to schedule jobs, which allows :
@itemize @minus
@item a global scheduling policy (while the local backend only sees jobs in its own repository).
@item the capability to run jobs on remote hosts (while the local backend only run jobs on the local host).
@end itemize

The configuration is composed of :
@itemize @bullet
@item @code{bin}  : The directory in which to find SGE executables such as @code{qsub}. This entry must be specified.
@item @code{cell} : The cell used by the SGE daemon. This is translated into @code{$SGE_CELL} when SGE commands are called.
By default, this is automatically determined by the SGE daemon.
@item @code{cluster} : The cluster used by the SGE daemon. This is translated into @code{$SGE_CLUSTER} when SGE commands are called.
By default, this is automatically determined by the SGE daemon.
@item @code{default_prio} : the priority used to submit jobs to the SGE daemon if none is specified on the @code{lmake} command line.
@item @code{n_max_queued_jobs} : @lmake scatters jobs according to the required resources and only submit a few jobs to slurm for each set of asked resources.
This is done to decrease the load of the SGE daemon as @lmake might have millions of jobs to run and the typical case is that they tend require only a small set of different resources
(helped in this by the limited precision on CPU, memory and temporary disk space requirements).
for each given set of resources, only the jobs with highest priorities are submitted to slurm, the other ones are retained by @lmake so as to limit the number of waiting jobs in slurm queues
(the number of running job is not limited, though).
This attribute specifies the number of waiting jobs for each set of resources that @lmake may submit to slurm.
If too low, the schedule rate may decrease because by the time taken, when a job finishes, for @lmake to submit a new job, slurm might have exhausted its waiting queue.
If too high, the schedule rate may decrase because of the slurm daemon being overloaded.
A reasonable value probably lies in the 20-100 range.
@item @code{repo_key} : This is a string which is add in front of @lmake job names to make SGE job names.
This key is meant to be a short identifier of the repository.
By default it is the base name of the repository followed by @code{:}.
Note that SGE precludes some characters and these are replaced by close looking characters (e.g. @code{;} instead of @code{:}).
@item @code{root}         : The root directory of the SGE daemon. This is translated into @code{$SGE_ROOT} when SGE commands are called. This entry must be specified.
@item @code{cpu_resource} : This is the name of a resource used to require cpu's.
For example if specified as @code{cpu_r} and the rule of a job contains @code{resources=@{'cpu':2@}}, this is translated into @code{-l cpu_r=2} on the @code{qsub} command line.
@item @code{mem_resource} : This is the name of a resource used to require memory in MB.
For example if specified as @code{mem_r} and the rule of a job contains @code{resources=@{'mem':'10M'@}}, this is translated into @code{-l mem_r=10} on the @code{qsub} command line.
@item @code{tmp_resource} : This is the name of a resource used to require memory temporary disk space in MB.
For example if specified as @code{tmp_r} and the rule of a job contains @code{resources=@{'tmp':'100M'@}}, this is translated into @code{-l tmp_r=10}0 on the @code{qsub} command line.
@end itemize

The @code{resources} rule attributes is composed of :
@itemize @minus
@item standard resources @code{cpu}, @code{mem} and @code{tmp}.
@item @code{hard} : @code{qsub} options to be used after a @code{-hard} option.
@item @code{soft} : @code{qsub} options to be used after a @code{-soft} option.
@item any other resource passed to the SGE daemon through the @code{-l} @code{qsub} option.
@end itemize

@section slurm backend

The slurm backend connects to a slurm daemon to schedule jobs, which allows :
@itemize @minus
@item a global scheduling policy (while the local backend only sees jobs in its own repository).
@item the capability to run jobs on remote hosts (while the local backend only run jobs on the local host).
@end itemize

The configuration is composed of :
@itemize @bullet
@item @code{config} : The slurm configuration file to use to contact the slurm controller. By default, the slurm library auto detects its configuration.
@item @code{n_max_queued_jobs} : @lmake scatters jobs according to the required resources and only submit a few jobs to slurm for each set of asked resources.
This is done to decrease the load of the slurm daemon as @lmake might have millions of jobs to run and the typical case is that they tend require only a small set of different resources
(helped in this by the limited precision on CPU, memory and temporary disk space requirements).
for each given set of resources, only the jobs with highest priorities are submitted to slurm, the other ones are retained by @lmake so as to limit the number of waiting jobs in slurm queues
(the number of running job is not limited, though).
This attribute specifies the number of waiting jobs for each set of resources that @lmake may submit to slurm.
If too low, the schedule rate may decrease because by the time taken, when a job finishes, for @lmake to submit a new job, slurm might have exhausted its waiting queue.
If too high, the schedule rate may decrase because of the slurm daemon being overloaded.
A reasonable value probably lies in the 20-100 range.
@item @code{repo_key} : This is a string which is add in front of @lmake job names to make slurm job names.
This key is meant to be a short identifier of the repository.
By default it is the base name of the repository followed by @code{:}.
@item @code{use_nice} : @lmake has and advantage over slurm in terms of knowledge : it knows the dependencies, the overall jobs necessary to reach the asked target and the history of the time
taken by each job.
This allows it to anticipate the needs and know, even globally when numerous @lmake commands run, in the same repository or on several ones, which jobs should be given which priority.
Note that @lmake cannot leverage the dependency capability of slurm as dependencies are dynamic by nature : new dependencies can appear during job execution, adding newedges to the dependency graph,
jobs can have to rerun, so a dependent job may not be able to start when its dependency is done, and a job can be steady, so a dependent job may not have to run at all.

The way it works is th following :
@itemize @minus
@item First @lmake computes and ETA for each @lmake command (cf @pxref{eta-estimation}. This ETA is a date, it is absolute, and can be compared between commands running in different repositories
@item Then it computes a pressure for each job. The pressure is the time necessary to reach the asked target of the @lmake command given the run time for all intermediate jobs
(including the considered job).
@item The subtraction of the pressure from the ETA gives a reasonable and global estimate of when it is desirable to schedule a job, and hence can be used as a priority.
@end itemize

The way to communicate this information is to set for each job a nice value that represents this priority.
Because this may interfere with other jobs submitted by other means, this mechanism is made optional,
although it is much better than other scheduling policies based on blind guesses of the futur (such as fair-share, qos, etc.).

@end itemize

There are 2 additional parameters that you can set in the @code{PriorityParams} entry of the slurm configuration in the form of param=value, separated by @code{,} :
@itemize @minus
@item @code{time_origin} : as the communicated priority is a date, we need a reference point.
This reference point should be in the past, not too far, to be sure that generated nice values are in the range @code{0} - @code{1<<31}.
@lmake make sometimes generates dates in the past when it wrongly estimates a very short ETA with a high pressure.
Taking a little bit of margin of a few days is more than necessary in all practical cases.
Default value is 2023-01-01 00:00:00.
Date is given in the format YYYY-MM-DD HH:MM optionally followed by +/-HH:MM to adjust for time zone.
This is mostly ISO8601 except the T between date and time replaced by a space, which is more readable and corresponds to mainstream usage.
@item @code{nice_factor} : this is the value that the nice value increases each second. It is a floating point value.
If too high, the the nice value may wrap too often. If too low, job scheduling precision may suffer.
The default value is @code{1} which seems to be a good compromise.
@end itemize
Overall, you can ignore these parameters for @lmake internal needs, the default values work fine.
They have been implemented to have means to control interactions with jobs submitted to slurm from outside @lmake.

The @code{resources} rule attributes is composed of :
@itemize @minus
@item standard resources @code{cpu}, @code{mem} and @code{tmp}.
@item @code{excludes} @code{features}, @code{gres}, @code{licence}, @code{nodes}, @code{part}, @code{qos}, @code{reserv} : these are passed as is to the slurm daemon.
For heterogeneous jobs, these attribute names may be followed by an index identifying the task (for example @code{gres0}, @code{gres1}).
The absence of index is equivalent to index 0.
@item any other resource passed to the slurm daemon as @code{licenses} if such licenses are declared in the slurm configuration, else as @code{gres}.
@end itemize

@anchor{autodep}
@section Autodep

Autodep is a mechanism through which jobs are spied to automatically detect which disk accesses are done.
From this information @lmake can determine if accesses were within the constraints provided by the rule and can list the hidden dependencies.

Several methods are available to spy jobs.
Not all methods are supported on all systems, though.

In all cases, @code{$LMAKE_AUTO_DEP_ENV} must remain in the environment untouched for the autodep mechanism to work correctly.

@subsection @code{'None'} or @code{'none'}

This method is strongly discouraged and should be reserved for usages such as tests, comparisons or benchmarks.

The job is not instrumented.
The only intrusion is the presence of @code{$LMAKE_AUTODEP_ENV}.

The only way to report activity is through the use of @code{ldepend} / @code{ltarget} or similar functions available in the @code{lmake} module.

The main advantage is that this method is not invasive (or marginally).
The main inconvenient is that no automatic hidden dependencies are recorded, one has to explicitly call @code{ldepend} and experience shows it is very difficult not to forget some.

@subsection @code{'LdPreload'} or @code{'ld_preload'}

The job is run with a library loaded using @code{$LD_PRELOAD} that catches some calls to the @file{libc.so} (such as @code{open}) to track activity.
This environment variable may be modified as long as the librairy introduced by @lmake stays present.

This requires @file{libc.so} to be dynamically linked.

This method is very performant.

The main advantage is that this method is available even on rather old versions of Linux.
The main inconvenient is that it is somewhat invasive and there are cases of incompatibilities (e.g. sometimes the use of the @code{jemalloc} package depending on its configuration).
Also, it will not run correctly if some commands have the @file{libc} statically linked and this will go undetected.

This method is recommended on systems that lack the rtld-audit capability when jobs do not use @code{jemalloc}.

@subsection @code{'LdPreloadJemalloc'} or @code{'ld_preload_jemalloc'}

This method is very similar to the previous method except it fully support @code{'jemalloc'}.
The drawback, though, is that it may miss a few dependencies, in some rare occasions, in case accesses are made before @code{main()} is called.

This method is recommended on systems that lack the rtld-audit capability when jobs use @code{jemalloc}.

@subsection @code{'LdAudit'} or @code{'ld_audit'}

This method is similar to @code{ld_preload} except that the rtld-audit (through @code{$LD_AUDIT}) mechanism is used instead of @code{$LD_PRELOAD},
which is less invasive (cases where it is not transparent are very awkward).
This environment variable may be modified as long as the librairy introduced by @lmake stays present.

This also requires @file{libc.so} to be dynamically linked but failure to do so can be detected and an error is generated, mandating the use of another method (except @code{ld_preload}).

The main advantage is that is is both performant, very little invasive and static linkage of @code{libc} is exceptional (and can be detected).
The main inconvenient is that it requires a rather recent version of Linux and there are cases of incompatibilites
(e.g. code written in @code{rust}, including the rust compilers @code{cargo} and @code{rustc}).

This method is recommended on systems that support it.

@subsection @code{'Ptrace'} or @code{'ptrace'}

The job is run @code{ptrace}'ed. The seccomp mechanism is used (if available) to reduce the performance hit to the minimum possible but still, it may be unacceptable.
There is no requirement that @file{libc.so} be dynamically linked.
It is almost not invasive.

Th main adavantage is that it works with a statically linked @code{libc}.
The main inconvenients are that the performance hit can be severe and that 32 bits executables are not supported yet.

Performance varies significantly depending on the number of syscalls made by the job.
As examples, a typical compilation will suffer a 10% hit while an extreme code doing only syscalls will see a 3x slow down.

This method is recommended as a fall back when the previous (@code{ld_preload} and @code{ld_audit}) methods cannot be used.

@anchor{link-support}
@section Link support
@lmake has several levels of symbolic link support :
@itemize @minus
@item If @code{'None'} or @code{'none'}, Symbolic links are not supported, no effort is done to resolve them.
@item If @code{'File'} or @code{'file'}, Symbolic links are supported only when they point to files (much like hard links), so intermediate directories are not checked for symbolic links.
@item If @code{'Full'} or @code{'full'}, All symbolic links are supported. This is the most secure but also the most heavy in terms of performance as all intermediate directories have to be checked.
@end itemize

@anchor{rule-selection}
@section Rule selection

When @lmake needs to ensure that a file is up to date, the first action is to identify which rule, if any, must be used to generate it.
This rule selection process works in several steps described below.

A file is deemed buildable if the rule selection process leads to a job that generates the file.

@subsection Name length
First, the length of the target name is checked agains @code{lmake.config.path_max}.
If the target name is longer, then the process stops here and the file is not buildable.

@subsection Sources
The second step is to check target agains sources and source directories.

If the target is listed as a source it is deemed buildable.
No execution is associated, though, the file modifications made by the user are tracked instead.

If the target is within a directory listed as a source directory (i.e. appears ending with a @code{/} in the manifest), it is deemed buildable if it exists.
If it does not exist, it is not buildable.
In both cases, the process stops here.

@subsection Up-hill directory
The third step is to see if a up-hill directory (i.e. one of the directory along the directory path leading to the file) is (recursively) buildable.

If it is the case, the rule selection process stops here and the file is not buildable.

@subsection @code{AntiRule} and @code{SourceRule}
The following step is to match the target against @code{AntiRule}'s and @code{SourceRule}'s (ordered by their @code{prio} attribute, high values are considered first).
If one is found, the target is buildable if it matches a @code{SourceRule} and is not if it matches an @code{AntiRule}.

If it matches a @code{SourceRule} and it does not exist, it is still buildable, but has an error condition.

In all cases, as soon as such a match is found, the process stops here.

@subsection Plain rules

The rules are split into groups. Each group contains all of the rules that share a given @code{prio}.
Groups are ordered with higher @code{prio} first.

The following steps is executed for each group in order, until a rule is found. If none is found, the file declared not buildable.

@subsection Match a target
For a given rule, the file is matched against each target in turn (cf @pxref{regexpr}).
Static targets are tried first in user order, then star targets in user order, and matching stops at the first match.
Target order is made of @code{targets} and @code{target} entries in reversed MRO order (i.e. higher classes in the Python class hierarchy are considered first),
then @code{post_targets} and @code{post_target} entries in MRO order (i.e. lower classes in the Python class hierarchy are considered first.

If a target matches, the matching defines the value of the static stems (i.e. the stems that appear without a @code{*}).
Else, the rule does not apply.

@subsection Check static dependencies

The definition of the static stems allow to compute :
@itemize @minus
@item The other targets of the rule. Static targets become the associated file, star targets becomes regular expressions in which static stems are expanded.
@item Static dependencies by interpreting them as f-strings in which static stems and targets are defined.
@end itemize

Static dependencies are then analyzed to see if the are (recursively) buildable, and if any is not buildable, the rule does not apply.

@subsection Group recap
After these 2 previous steps have been done for the rules of a group, the applicable rules are analyzed the following way :
@itemize
@item If no rule apply, next group is analyzed.
@item If the file matches several rules as a sure target (i.e. a static target and all static deps are sure),
the file is deemed buildable, but if required to run, no job will be executed and the file will be in error.
@item If the file matches some rules as a non-sure target (i.e. a star target or a dep is not sure), the corresponding jobs are run.
If no such jobs generate the file, next group is analyzed.
If several of them generate the file, the file is buildable and in error.
@end itemize

@anchor{critical-deps}
@section Critical deps

The question of critical deps is a performance only question. Semantically, whether a dep is critical or not has no impact on the content of the files built by @lmake.

During dependency analysis, when a dep (call it @file{dep1}) has been used and turns out to be out-of-date, @lmake must choose between 2 strategies regarding the deps that follow :
@itemize @bullet
@item
One possibility is to anticipate that the modification of @file{dep1} has no impact on the list of following deps.
With such an anticipation, @lmake will keep the following deps, i.e. when ensuring that deps are up-to-date before launching a job, @lmake will launch all necessary jobs to rebuild
all dependencies in parallel, even if the deps have been explicitly declared parallel.
@item
Another possivility is to anticipate that such a modification of @file{dep1} will drastically change the list of following deps.
With such an anticipation, as soone as @lmake sees a modified dep, it will stop its analysis as the following deps, acquired with an out-of-date content of @file{dep1} is meaningless.
@end itemize

The first strategy is speculative : launch everything you hear about, and we will see later what is useful.
The second strategy is conservative : build only what is certain to be required.

Generally speaking, a speculative approach is much better, but there are exceptions.

Typical use of critical deps is when you have a report that is built from the results of tests provided by a list of tests (a test suite).

For example, let's say you have :
@itemize @minus
@item 2 tests whose reports are built in @file{test1.rpt} and @file{test2.rpt} by some rather heavy means
@item a test suite @file{test_suite.lst} listing these reports
@item a rule that builds @file{test_suite.rpts} by collating reports listed in @file{test_suite.lst}
@end itemize

In such a situation, the rule building @file{test_suite.rpts} typically has @file{test_suite.lst} as a static dependency but the actual reports @file{test1.rpt} and @file{test2.rpt} are
hidden dependencies, i.e. automatically discovered when building @file{test_suite.rpts}.

Suppose now that you make a modification that makes @file{test2.rpt} very heavy to generate. Knowing that, you change your test_suite so list a lighter @file{test3.rpt} instead.
The succession of jobs would then be the following :
@itemize @minus
@item @file{test1.rpt} and @file{test2.rpt} are rebuilt as they are out-of-date after your modification.
@item @file{test_suite.rpts} is rebuilt to collate theses reports.
@item @lmake then sees that @file{test3.rpt} is needed instead of @file{test2.rpt}.
@item Hence, @file{test3.rpt} is (re)built.
@item @file{test_suite.rpts} is finally built from @file{test1.rpt} and @file{test3.rpt}.
@end itemize

There are 2 losses of performance here :
@itemize @minus
@item @file{test2.rpt} is unnecessarily rebuilt.
@item @file{test1.rpt} and @file{test3.rpt} are rebuilt sequentially.
@end itemize

The problem lies in the fact that @file{test1.rpt} and @file{test2.rpt} are rebuilt before @lmake had a chance to re-analyze the test suite showing that the new tests are test1 and test3.
Generally speaking, this is a good strategy : such modifications of the dependency graph happens rather rarely and speculating that it is pretty stable by building known dependencies before
launching a job is the right option.
But here, because collating is very light (something like just executing @code{cat} on the reports), it is better to check @file{tests_suilte.lst} first,
and if it changed, rerun the collation before ensuring (old) tests have run.

This is the purpose of the @code{critical} flag.
Such a flag can either be passed when declaring static deps in a rule, or dynamically using @code{lmake.depend} or @code{ldepend}.

The collating rule would look like :
@itemize @minus
@item Set the @code{critial} flag on @file{test_suite.lst} (before or after actually reading it, this has no impact).
@item Read @file{test_suite.lst}.
@item Call @code{ldepend} on the reports listed in @file{test_suite.lst}.
This is optional, just to generate parallel dependencies instead of automatic sequential dependencies (but if done, it must be before actually reading the reports).
@item Collate reports listed in @file{test_suite.lst}.
@end itemize

And the succession of job would be :
@itemize @minus
@item @file{test_suite.rpts} is rebuilt before analyzing @file{test1.rpt} and @file{test2.rpt} because @file{test_suite.lst} has changed.
@item @lmake sees that @file{test3.rpt} is needed instead of @file{test2.rpt}.
@item Hence, @file{test1.rpt} and @file{test3.rpt} are (re)built in parallel.
@item @file{test_suite.rpts} is finally built from @file{test1.rpt} and @file{test3.rpt}.
@end itemize

@anchor{hierarchical-repositories}
@section Hierarchical repositories

Hierarchical repositories are repositories that contain repositories, i.e. some @Lmakefile are present in sub-directories.

In that situation, it is reasonable to assume that the @Lmakefile are made to handle building files underneath it.

To support this situation, @lmake allow you to simply mention such s
@itemize
@item Targets only match within the sub-repo (and escape is possibly by setting the @code{top} flag to the target to provide global rules).
@item The same applies to deps.
@item @code{cmd} is run from this sub-repository, i.e. its cwd is set accordingly.
@item The priority of deeper rules are matched first, so that builds in a sub-repo is not pertubated by rules of englobing repo.
@end itemize

@anchor{eta-estimation}
@section ETA estimation

An ETA estimation is made possible because the execution time for each job is recorded in @lmake book-keeping after all successful runs
(if a job ends in error, it may very well have been much faster and the previous execution time is probably a better estimate than this one).
When a job has never run successfully, an ETE is used instead of its actual execution time by taking a moving average of all the jobs of the same rule.

This being given, a precise ETA would require a fake execution of the jobs yet to be run which can take all dependencies and resources into account.
But this is way too expensive, so a faster process must be done, even at the expense of precision.

In all cases, the ETA assumes that no new hidden dependencies are discovered and that no file is steady so that all jobs currently remaining will actually be executed.

2 approaches can be considered to estimate the time necessary to carry out remaining jobs :
@itemize
@item Resources limited : dependencies are ignored, only resources are considered.
Roughly, the time is the division of the quantity of resources necessary by the quantity of resources available.
For example, if you need 10 minutes of processing and you have 2 cpus, this will last 10/2=5 minutes.
@item Dependencies limited : resources are ignored and only dependencies are considered. This means you only look at the critical path.
For example if you need to run a 2 minutes job followed by a 3 minutes job, and in parallel you must run a 4 minutes job, this will last 2+3=5 minutes.
@end itemize

@lmake uses the first approach.
For that it measures the parallelism of each job while running and the ETA is computed after the sum of the costs of all waiting and running jobs,
the cost being the execution time divided by the observed parallelism.
Jobs running for the first time inherit a moving average of the last 100 run jobs of the same rule.

@anchor{video-mode}
@section Video mode and colors

If lmake is connected to a terminal, then the terminal foreground and background colors are probed and if the brightness of the background color is less than that of the foreground color,
video mode is set to normal, else it is set to reverse.

In that case, lmake output is colored and the (configurable) color set is chosen depending on video mode.

@anchor{resource-buckets}
@section Resource buckets

It may be wise to quantify resources with relatively large steps for resources @code{mem} and @code{tmp}, especially if these may be computed with a formula.

The reason is linked to the way the backends select jobs.
When a backend (actually the local, SGE and slurm backends essentially work the same way) search for the next job to launch, it walk through the available jobs to
find the eligible one with the highest priority.
When doing that, only jobs with different resources need to be compared as for a given set of resources, they can be pre-ordered by priority.
As a consequence, the running time is proportional to the number of different resources.
If the @code{mem} and @code{tmp} needed space is computed from some metrics, it may be very well possible that each job has a different number, leading to a selection process
whose time is proportional to the number of waiting jobs, which can be very high (maybe millions).
To help reduce this overhead, one may want to put jobs into buckets with defined values for these resources.
This can be done with a sound formula to compute the values.
But as this is potentially important for @lmake itself, @lmake provides an easy means to achieve this goal by defining a given precision.
After all, you probably do not care if the reserved memory is 990MB or 1024MB.

The @code{config.backends.precisions} field allows you to easily define the adequate granularity. The larger this number, the finer the granularity.
A fine granularity allows a better use of the available resources.
A coarser graniularity allows a more efficient job selection process.
So the right answer is a sound balance between these two aspects.
A value of 4 or 8 is probably a reasonable value.

In presence of jobs with a high degree of parallelism requiring a lot of cpus, the same may be applied for the required number of cpus.

@anchor{tmp}
@section Mapping the temporary directory

Mapping the temporary directory feature is an answer to some situations which are apparently against the @lmake execution model.

@lmake sees jobs as having some inputs and generating some outputs.
But some tools operate on data (typically a directory) without making a distinction between input and output.

Imagine, for example you have 2 closely related tools :
@itemize
@item Let's call these 2 tools phase1 and phase2.
@item phase1 is used to prepare a directory, for example it generates some source files and put the result in the directory.
@item phase2 operates on this directory, for example it compiles the source files prepared by phase1 and puts the compiled files next to the sources, in the same directory.
@item Suppose, in addition, that phase2 takes and argument, for example it may have several optimization levels for the compilation process.
@end itemize

Then, you want to organize your flow to have a first job using phase1, then several dependent jobs using phase2, potentially running in parallel.
One way to do that is to set up your flow the following way :
@itemize
@item Name the output of phase1 @file{phase1.out}
@item name the output of phases @file{phase2.arg.out} where @file{arg} may have several values.
@item In the rule to run phase1, simply drive it to generate its data in @file{phase1.out}.
@item In the rule to run phase 2, first copy @file{phase1.out} to @file{phase2.arg.out}, then use phase2 to operate on @file{phase2.arg.out}.
The copy process can be further optimized by linking in some situations, but his is not the purpose of this discussion.
@end itemize

This is fine, as long as copying the data is allowed.
Some tools store absolute paths in their own data, so that the copy of @file{phase1.out} to @file{phase2.arg.out} invalidates the data and makes them unusable.
In that case, a modified flow may be :
@itemize
@item In the rule to run phase1, drive it to generate its data in $TMPDIR, then copy $TMPDIR to @file{phase1.out}.
@item In the rule to run phase2, first copy @file{phase1.out} to $TMPDIR, then use phase2 to operate on $TMPDIR, then copy $TMPDIR to @file{phase2.arg.out}.
@end itemize

The problem is that the $TMPDIR used by phase1 may (and typically is) different from the $TMPDIR used for phase2.
This is not a bad @lmake design or a lack of luck, this is unavoidable if you want to run several instances of phase2 in parallel : they cannot all have the same $TMPDIR.

To face this situation, you can ask @lmake to arrange so that each of these jobs see $TMPDIR as a fixed name, for example /tmp, although the true underlying files are in different directories.
This way, the flow shown above works as expected.

This seems like an awkward situation, but is common practice in the CAD tools domain.

@anchor{codec}
@section Encoding and decoding

In some situations with heavily parameterized generated files, file names can become very long.
Think of the mere compilation of a C++ file @file{foo.c}. You may want to specify :
@itemize
@item the optimization level through a -@code{-O} argument
@item Whether debug checks are enable through the definition of @code{NDEBUG}
@item a trace level through the definition of a macro such as @code{TRACE_LEVEL}
@item whether and how to instrument with @code{-fsanitize}
@item whether some internal data are 32 or 64 bits
@item whether to use a reference algorithm or an agressively optimized one used in production.
@item ...
@end itemize
You may want to be able to generate any combination so as, for example, compare the output of any 2 of them for validation purpose.
You easily end up with an object file with a name such as @file{foo.O3.NDEBUG.TRACE_LEVEL=1.sanitize=address.32.o}.
Already 50 characters or so.
In a real projects, file names can easily be 200, 300, 400 characters long.

As long as the file name, with adequate shorthands such as using @code{TL} instead of @code{TRACE_LEVEL} fits within a few hundreds of characters, the situation is heavy but manageable.
But if you need, say 3000 characters to specify a file, then it becomes completely impractical.

When the configuration can be devised in advance, in a stable way, an efficient alternative is to create a file to contain it, which becomes a configuration name,
and just specify the configuration name in the generated file.

In the example above, you may have a file @file{test.opts} that contains options for testing and @file{prod.opts} that contains options for production.
then, your object file is simply named @file{foo.test.o} or @file{foo.prod.o}.

When it is not, the situation is more complex and you need to automatically generate these configuration files with reasonably short names.
A practical and stable way to generate short names is to compute a checksum on the parameters.
You then need a way to retrieve the original parameters from the checksum to generate the generated file (the @file{.o} file in our example).
In doing so, you must account for :
@itemize @minus
@item robustness    : because such checksums are subject to the birthday paradox, you need either to deal with collisions are provide enough margin (roughly doubling the size) to avoid them.
@item repeatability : your system must not prevent you from being able to repeat a scenario that was generated some days, weeks, months earlier.
@item merging       : when you invent a name, think that some colleagues working on the same project may also invent names, and they may collide.
Tools such as @code{git} are there to help you in this process, but your scheme must be git friendly.
@item performance   : you must have a scheme that support as many code/value associations as necessary for your case, without spending most of its time searching for value when given a code.
@item communication : ideally, you may want to signal a bug to a colleague by just telling him "build that target, and you see the bug".
If the target refers to a code, he may need some further steps to create the code/value association, which goes against communication.
@end itemize

One way to deal with this case is to create a central database, with the following pros and cons :
@itemize @minus
@item robustness    : collisions can easily be dealt with.
@item repeatability : this is a probleme. When dealing with collisions, some codes change, which change old repository because the database is not itself versioned. This is a serious problem.
@item merging       : no merging.
@item perfomance    : accessing the data in a performant way is easy. Detecting modifications so that @lmake can take sound decisions may be more challenging.
@item communication : excellent, the database is shared
@item installation  : you need a server, configure clients to connect to it, etc. it is some work
@item maintainance  : as any central services, you may inadvertently enter wrong data, you need a way to administer it as it has the potential to block the whole team.
@end itemize

The @code{lencode}/@code{ldecode} commands (or the @code{lmake.encode}/@code{lmake.decode} fonctions) are there to address this question.

The principle of opeartion is the following :
@itemize @minus
@item There are a certain number of files storing code/value associations. These are sources seen from @lmake, i.e. they are normally managed by @code{git}.
@item To keep the number of such files to a reasonably low level (say low compared to the overal number of sources), there are contexts, mostly used as a subdivision of files
@item So, a file provides a certain number of tables (the contexts), each table associating some codes with some values
@item These tables are stored in files as lines containing triplet : context, code, value
@item When reading, @code{lencode}/@code{ldecode} are very flexible. The files may contain garbage lines, duplicates, collisions, they are all ignored.
When 2 values are associated with the same code by 2 different lines, a new code is generated by lenghtening one of them with further digites of the checksum computed on the value.
When 2 codes are associated with the same value by 2 different lines, only one code is retained, the shorter of the 2 (or any if of equal length).
@item When writing, @code{lencode}/@code{ldecode} are very rigid. File is generated sorted, with no garbage lines, nor duplicates, or collisions.
@item When @lmake starts and read a file, it write it back in its canonical form.
@item When @lmake runs, that @code{lencode} is used and generate new codes on the fly, additional lines are merely appended to the file.
@end itemize

This has the following properties :
@itemize @minus
@item Information is under git. No further server, central database, management, configuration etc.
@item repeatability is excellent. As long as you do not merge, your are insensitive to external activities.
When merging, the probability of collision depends on the length of the used codes, which is under user control.
Moreover, the length increasing automatically with collisions maintain the number of such collision to a reasonably low level, even in fully automatic mode.
@item Merging is very easy : actually one need not even merge. The simple collision file generated by @code{git} can be used as is. This makes this tool very @code{git} friendly.
@item Robustness is perfect : collisions are detected and dealt with.
@item Coherence is perfect : seen from @lmake, each association is managed as a source.
If anything changes (i.e. a new value is associated with an old code or a new code is associated with an old value), the adequate jobs are rerun.
@item Performance is very good as the content of the file is cached in a performance friendly format by @lmake. And update to the file is done by a simple append.
However, the file is sorted at every @lmake command, making the content more rigid and the merge process easier.
@item Associations files can be editing by hand, so that human friendly codes may be associated to some heavily used values.
@code{lencode} will only generate codes from checksums, but will handle any code generated externally (manually or otherwise).
In case of collision and when @lmake must suppress one of 2 codes, externally generated codes are given preference as they believed to be more readable.
If 2 externally generated codes collide, a numerical suffix is appended or incremented to solve the collision.
@end itemize

@chapter FAQ

@section @code{gcc} does not generate dependencies on some generated @file{.h} files, how to handle this ?
When @code{gcc} starts, it looks at all its include directories listed through options such as @code{-I} (@code{-iquote}, @code{-isystem} and @code{-idirafter}).
If a directory does not exist, it is removed from its internal list and when a file is included with @code{#include}, such directories are not tried.
As a consequence, no dep to files within these directories are generated.
To circumvent this adverse optimization done by @code{gcc}, all directories that lie in the repository must exist before @code{gcc} is started.
An easy way to ensure that by creating a dependency to a marker file within each such directory and to create a very simple rule that generates such marker file.

An exemple is shown here :

@example
@group
class Mrkr(lmake.Rule) :
	prio   = float('inf')      # in case of clash with another rule the other rule is perfect, as long as mrkr is not a directory
	target = '@{__dir__@}mrkr'
	cmd    = ''                # target is open as stdout, this is enough, we have nothing to put in the target
class Gcc(lmake.Rule) :
	targets = @{ 'OBJ' : '@{File:.+@}.o' @}
	deps    = @{ 'SRC' : '@{File:.+@}.c' @}
	cmd     = 'ldepend a/mrkr b/mrkr c/mrkr ; gcc -Ia -Ib -Ic -c -o @{OBJ@} @{SRC@}'
@end group
@end example

@chapter Glossary

@table @asis
@item Birthday paradox
This is a wellknown counter intuitive problem linked to checksum collision. It is extensively described there : https://en.wikipedia.org/wiki/Birthday_problem
@item CAD
Computer Aided Design.
A domain used to produce various objects, in partiulcar integrated ciruits, characterized by heavy processing and complex flows.
@item diamond rule
A feature of Python that allows the following behavior :
@itemize
@item A class @code{D} inherits from @code{B} and @code{C} in that order.
@item Both @code{B} and @code{C} inherit from a class @code{A}.
@item A method @code{m} is defined on @code{A} and @code{C} but not on @code{B}.
@item Then if @code{m} is called from an instance of @code{D}, @code{C.m} will be called and not @code{B.m} (which turns out to be @code{A.m}).
@end itemize
This feature is a central point that makes Python multiple inheritance easy to use and enables the class hierarchy shopping list style.
@item ETA
Estimated Time of Arrival. This is the date at which a given event (such as a job being completed) is estimated to occur.
@item ETE
Estimated Time En route. This is the remaining time necessary to complete a task.
@item IP
Intellectual Property.
@item LRU
Least Recently Used. A classical cache replacement policy where the entry that was least recently used is discarded when a new one is allocated.
@item MRO
Method Research Order, the inheritance chain from the current class to its most basic base, usually @code{object}.
Python computes the MRO in such a way as to enforce the diamond rule.
@end table

@bye
