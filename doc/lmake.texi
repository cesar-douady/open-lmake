\input texinfo

@c This file is part of the open-lmake distribution (git@github.com:cesar-douady/open-lmake.git)
@c Copyright (c) 2023 Doliam
@c This program is free software: you can redistribute/modify under the terms of the GPL-v3 (https://www.gnu.org/licenses/gpl-3.0.html).
@c This program is distributed WITHOUT ANY WARRANTY, without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

@macro XXX{txt}
@end macro

@XXX{document which config fields are clean/static/dynamic}

@macro lmake
@code{lmake}
@end macro

@macro adminfile{file}
@file{LMAKE/\file\}
@end macro

@macro Lmakefile
@file{Lmakefile.py}
@end macro

@set TITLE The lmake Manual
@set UPDATED 22 April 2024
@set UPDATED-MONTH April 2024
@set EDITION @dfn{work in progress}
@set VERSION 0.1

@settitle @value{TITLE}
@setchapternewpage odd
@c Combine the variable and function indices:
@syncodeindex vr fn
@c Combine the program and concept indices:
@syncodeindex pg cp
@c FSF publishers: format makebook.texi instead of using this file directly.
@c %**end of header

@copying
This file documents the @lmake utility, which determines
automatically which pieces of a large workflow need to be remade
and issues the commands to remake them.

This is Edition @value{EDITION}, last updated @value{UPDATED},
of @cite{@value{TITLE}}, for @lmake version @value{VERSION}.

Copyright @copyright{}  2023 Doliam.

@quotation
Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 3 or
any later version published by the Free Software Foundation
@end quotation
@end copying

@summarycontents
@contents

@top @lmake
@insertcopying


@chapter Overview of @lmake

The @lmake utility automatically determines automatically which pieces of a large workflow need to be remade
and issues the commands to remake them.
This manual describes @lmake, which was implemented by Cesar Douady.

Our examples show C/C++ and Python programs, since they are most common, but you can use
@lmake with any programming language to run any phase of your CI/CD as long as these can be scripted.
Indeed, @lmake is not limited to programs.
You can use it to describe any task where some files must be (re)computed automatically
from others whenever recomputing would generate such files differently than what they currently are.
Such situations include dependency modifications, but also command modifications, dependency list modifications,
apparition of an include file that was in the search path before an include file was actually accessed, symbolic link modifications, etc.

Hard links are also fully supported.
Repositories can be moved (as far as @lmake is concerned, user content may not support moves), archived and restored.

@lmake is designed to be scalable, robust and efficient.

By scalable, we mean that @lmake can manage millions of files and tens of thousands of CPU hours without any difficulty,
so there is never any reason to have any kind of recursive invocation, @lmake can handle the whole project all at once.

By robust, we mean that @lmake guarantees that if a job is not rerun, then rerunning it would lead to the same content (or a content that is equally legal).
This includes automatic capture of so called hidden dependencies (i.e. dependencies that are not explicitely stated in the rules, e.g. include files).

We also mean that @lmake, as any software, it may have bug.
Such bugs can lead to crashes and to pessimistic behavior (a job is rerun while it was not necessary).
But special attention has been devoted in its design to ensure that it is never optimistic (a job not being rerun while it should have been).
In case of any adverse event (lmake crashes or spurious system reboot),
@lmake automatically recovers potentially corrupted states in a safe way to avoid having to remake the whole project because a few files are corrupted.

Note that @lmake does not only recorver from its own flees, but also a lot of experience is embedded into it to work around system bugs.
This includes for example violations by NFS of its close-to-open synchronization guarantee (which happens, under heavy system load, maybe once in 10.000 accesses)
or SGE/SLURM spuriously disappearing.

By efficient, we mean that jobs are run in parallel, optionally using a batcher such as Slurm, managing limited resources as declared in @Lmakefile.
We also mean that @lmake makes a lot of effort to determine if it is necessary to run a job (while always staying pessismistic).
Such effort includes checksum based modification detection rather than date based, so that if a job is rerun and produces an identical content, subsequent jobs are not rerun.
Also, @lmake embed a build cache whereby jobs can record their results in a cache so that if the same run needs to be carried out by another user,
it may barely fetch the result from the cache rather than run the - potentially lengthy - job.


@section Preparing and running @lmake.

To prepare to use @lmake, you must write a file called
the @Lmakefile that describes the relationships among files
in your workflow and provides commands for generating each file.
In a program, typically, the executable file is updated from object
files, which are in turn made by compiling source files.
Then unit tests are run from the executable and input files, and the output is compared to some references.

Once a suitable @Lmakefile exists, each time you change anything in the workflow (source files, recipes, ...)
this simple shell command:

@example
lmake <my_target>
@end example

@noindent
suffices to perform all necessary steps so that @file{<my_target>} is reproduced as if all steps leading it were carried out while actually carrying out only necessary steps.
The @lmake program maintains an internal state in the @file{LMAKE} directory
to decide which of the files need to be regenerated.
For each of those files, it issues the recipes recorded in @Lmakefile.
During the execution of recipes, @lmake instruments them in order to gather which files were read and written in order to determine hidden dependencies and whether such actions were legal.
These information are recorded in the @file{LMAKE} directory.

You can provide command line arguments to @lmake to somewhat control this process.

@section Problems and Bugs

If you have problems with @lmake or think you've found a bug,
please report it to the developers; we cannot promise to do anything but
we might well want to fix it.

Before reporting a bug, make sure you've actually found a real bug.
Carefully reread the documentation and see if it really says you can do
what you're trying to do.
If it's not clear whether you should be able to do something or not, report that too; it's a bug in the documentation!

Before reporting a bug or trying to fix it yourself, try to isolate it
to the smallest possible @Lmakefile that reproduces the problem.
Then send us the @Lmakefile and the exact results @lmake gave you, including any error messages.
Please don't paraphrase these messages: it's best to cut and paste them into your report.
When generating this small @Lmakefile, be sure to not use any non-free
or unusual tools in your recipes: you can almost always emulate what
such a tool would do with simple shell commands.
Finally, be sure to explain what you expected to occur; this will help us decide whether the problem was really in the documentation.

if your problem is non-deterministic, i.e. it shows up once in a while, include the entire content of the @file{LMAKE} directory.
This directory contains extensive execution traces meant to help developers to track down problems.
Make sure, though, to trim it from any sensitive data.

Once you have a precise problem you can report it in one of two ways.
Either send electronic mail to:

@example
    xxx@@yyy.zzz
@end example

@noindent
or use our Web-based project management tool, at:

@example
    https://xxx.yyy.zzz
@end example

@noindent
In addition to the information above, please be careful to include the
version number of @lmake you are using.
You can get this information from the file @file{LMAKE/version}.
Be sure also to include the type of machine and operating system you are using.
One way to obtain this information is by running the command @samp{uname -a}.


@chapter An Introduction to @Lmakefile syntax

You need a file called a @Lmakefile to tell @lmake what to do.

In this chapter, we will discuss a simple @Lmakefile that describes how to
compile, link and test a tiny executable @file{hello_world} which consists of 3 C++ source files (@file{hello_world.cc}, @file{hello.cc} and @file{world.cc})
and 2 header files (@file{hello.hh} and @file{world.hh}).
This tiny executable just writes @code{hello world} on its output.
There is a reference output (@file{hello_world.ref}) that @lmake uses to check if the execution is correct.

So, the entire project contains the following files :
@itemize
@item @file{hello.hh}
@item @file{hello.cc} (includes @file{hello.hh})
@item @file{world.hh}
@item @file{world.cc} (includes @file{world.hh})
@item @file{hello_world.cc} (includes @file{hello.hh} and @file{world.hh})
@item @file{hello_world.ref}
@end itemize

When @lmake recompiles this tiny executable, each changed C++ source file must be recompiled.
If a header file has changed, each C++ source file that includes the header file must be recompiled.
Each compilation produces an object file corresponding to the source file.
Then, if any source file has changed, all the object files, whether newly made or saved from previous compilations, must be linked together to produce the new tiny executable.
Finally, if the tiny executable changed, its unit test must be rerun and if the resulting output changes (or if the reference is modified), the actual output must be recompared against the reference.

As its name suggests, @Lmakefile is actually a Python file.
@lmake embeds a Python interpreter (version 3.6+) to interpret @Lmakefile.
Because Python is among the most powerful and widely used programming language, this choice allows @lmake users to have access to a very powerful language to express complicated workflows
without the need to learn a new language.
As a side effect, it also allows the developpers to provide such a powerful means without having to design and implement it.
Among the features of Python that come handy when describing workflows, one can list variables, functions, f-strings, conditionals, loops and inheritance.

The goal of @Lmakefile is to describe 3 aspects of your workflow :
@itemize @bullet
@item some global configuration
@item the list of the sources of the workflow
@item the derivation rules
@end itemize

This is done by importing the @lmake module and defining the 2 variables @code{lmake.config}, @code{lmake.manifest} and by defining rules inheriting from the base classes in @code{lmake.rules}.
When reading @Lmakefile, @lmake simply imports this module by issuing @code{import Lmakefile} in a Python 3.6+ interpreter and looks at these variables and sub-classes.
@lmake provides some help for these 3 goals, though.

Once @Lmakefile has been read, @lmake writes in the @file{LMAKE} directory a digest of these definitions in the files @file{LMAKE/config}, @file{LMAKE/sources} and @file{LMAKE/rules}.
These may be consulted in case of doubt about what @lmake has understood of your @Lmakefile file.

@section Configuration

The configuration describes some global aspects of the workflow.
The @lmake module contains a reasonable default value for the @code{lmake.config} variable and in an introduction chapter, there is nothing much to say.
In a simple workflow, ignoring the configuration step is a good starting point.

@section Sources

@lmake needs to know the list of the source files.
The mere presence on disk of a file is not sufficient for @lmake to qualify it as a source.
This is because the aim of @lmake is to provide a reproductible workflow.
For example, if you work under @code{git}, as it is very common, once you have been able to build a target, you must be able to commit and push, then a colleague (or yourself in another repository)
must be able to do a pull and build the same target to get the same result.
If a file exists in your original repository, but is not tracked by @code{git} and is used to build your target, your colleague will not be able to reproduce the same target with the same content.
In such a situation, @lmake will consider your file as @dfn{dangling} and accessing it will be an error.

Source files are listed in @code{lmake.manifest} as a @code{list} or a @code{tuple}.
By default, if @code{lmake.manifest} is not set, @lmake will look for a file named @file{Manifest} and use it as a list of files, one per line.
If no @file{Manifest} file is present, it will then issue a @code{git ls-files --recurse-submodules} command to gather the list of sources.
Note that the @code{git} repository can be anywhere on the directory path to the @lmake repository.

@section Rules

Rules are classes that derive from one of the base classes defined in @code{lmake.rules} (Rule, AntiRule, PyRule, ...).

To be recognized as a usable rule, rules must define the following attributes (possibly by inheriting them) :
@itemize @bullet
@item @code{targets}
@item @code{cmd}
@end itemize

If any is not defined, such a @code{class} may still be pertinent to serv as base class for usable rules.

Generally, it will also have the @code{deps} attribute defined and possibly the @code{stems} (unless stems are directly defined in targets or deps) :

@example
@group
from lmake.rules import Rule
class Compile(Rule) :
	stems   = @{ 'File' : r'.*'         @}
	targets = @{ 'OBJ'  : '@{File@}.o'  @}
	deps    = @{ 'SRC'  : '@{File@}.cc' @}
	cmd     = 'gcc -c -o @{OBJ@} @{SRC@}'
@end group
@end example

Let's look at each element in this rule.

@subsection @code{name}
The first element is the class name @code{Compile}.
This name will be used by @lmake in reporting when it needs to refer to this rule, in error messages or when it reports execution.
Generally speaking, all rules have a @code{name} attribute which defaults to the class name if not explicitly set.
Here, the @code{name} of our rule is @code{'Compile'} but we could have set the attribute @code{name} to @code{'cc compilation'} for example.

@subsection @code{stems}
Then comes the @code{stems} attribute.
This attribute provides a vocabulary of (Python) regular expressions that can be further referenced in other attributes.

@subsection @code{targets}
Then, there is the @code{targets} attribute.
This attribute defines the files that may be generated by this rule.
Its syntax looks like Python 3.6+ f-strings, except that variable parts (in @code{@{@}}) must be plain variables (not actual expressions).
However, this works the other way around, compared to f-strings. With an f-string, you start from a value of @code{File}, say @code{'foo'}, and from that, you can derive the string
@code{'foo.o'} from the f-string @code{'@{File@}.o'}.
But here, we start from a file @file{foo.o} and we find that this rule applies if we define @code{File} as @code{'foo'}.
More precisely, @lmake matches the file name @code{'foo.o'} against the regular expression @code{r'(?P<File>.*)\.o'} and Python provides the group @code{'File'} as @code{'foo'}.

The reason why the Python 3.6+ f-strings syntax has been leveraged is by symmetry with the @code{deps} attribute described below.

There may be more than a single target (and this is why this attribute is a @code{dict}).
In that case, the rule is supposed to generate all of them when it is executed and any of them will trigger its execution.

@subsection @code{deps}
Then, we find the @code{deps} attribute.
This attribute define the explicit dependencies the rule need before it can be run.
This is a @code{dict} mapping keys to actual Python 3.6+ f-strings.
Once @code{File} has been determined by matching a target, it is fed to the f-strings to determine the explicit dependencies.
@lmake will automatically determine actual dependencies by spying the rule execution, so one could think mentioning them explicitly is useless.
To some extent, this is true, with these limitations :

@itemize @bullet

@item
Explicit dependencies are not only used to determine if a rule must be run or not, they are also used to determine if a rule apply or not.
For a rule to apply, it must match a given file as a target, but also, the computed explicit dependencies must be sources or recursively buildable.
By contrast, if a hidden dependencies cannot be built (and if it does not actually exist), this is silently ignored (more to come later on this subject).

Imagine for example that you have a rule to compile C++ files and another rule to compute C files. Given @file{foo.o}, @lmake must determine which rule to apply.
With explicit dependencies, @lmake has the necessary information to select the adequate rule : it will look for files @file{foo.cc} and @file{foo.c} and if one is a source or is buildable,
it can then select the corresponding rule.
Note that if both are sources or buildable, the situation will be ambiguous and @lmake will report an error.
On the opposite, if none are sources or buildable, @file{file.o} will be deemed not buildable.

@item
From a performance perspective, this allows @lmake to know up front that a dependency is required before running a job.
If a dependency is not explicitly mentioned, a target may be built by @lmake, spying its accesses.
@lmake then discovers the dependency, and if it is not up to date, build it and rerun the rule with up to date dependencies.
This double run (which occurs only the first time @lmake hit the given target) can be avoided if the dependency is explicit.

@end itemize

Generally speaking, obvious dependencies (such as the source file for a compilation step) should be mentioned explicitly and the other ones (such as include files for a compilation step)
can be left as hidden dependencies.

@subsection @code{cmd}
Finally we see the @code{cmd} attribute.
This attribute specifies the recipe to use to build targets from dependencies.
The @code{cmd} attribute can be either a @code{str} or a function.

If it is a @code{str}, it contains a shell script that will be executed when the rule is triggered
(the shell can be customized and defaults to the default system shell, usually @file{/bin/bash}).
Before execution, it is interpreted as a Python f-string, i.e. everything between @code{@{@}} is interpreted as a Pyhton expression and the corresponding value is substituted.
During this process, the stems, targets and deps have their definition from the current job.
This way, scripts are easy to write and read.

It can also be a function and our example rule could have been written as :
@example
@group
import subprocess as sp
from lmake.rules import Rule
class Compile(Rule) :
	stems   = @{ 'File' : r'.*'       @}
	targets = @{ 'OBJ'  : '@{File@}.o'  @}
	deps    = @{ 'SRC'  : '@{File@}.cc' @}
	def cmd() :
		sp.run( ('gcc','-c','-o',OBJ,SRC) , check=True )
@end group
@end example

In that case, this function is executed in a Python interpreter when the rule is triggered
(the Python used to run this function can be customized and defaults to the Python used to read @Lmakefile).
Before execution, the definitions of stems, targets and dependencies are put in the global @code{dict} (and a few others that will be described later).

Static targets are defined as their associated file name.
Star targets are defined as functions taking the star stems as arguments and returning the corresponding file.
The @code{regexpr} attribute of this function is defined as the regular expression that matches the star targets.

For example if target @code{STAR} is @code{'@{Dir:.*@}.tardir/@{File*:.*@}}, @code{STAR} will be defined as a function
and @code{STAR('foo')} will return @code{'my_dir.tardir/foo'} if executed from a job with @code{Dir} defined as @code{my_dir},
and @code{STAR.regexpr} will be @code{r'my_dir\.tardir/(.*)'}.

This way, functions are easy to write and read.

@section A simple @Lmakefile

Here is a simple @Lmakefile that sustains our hello_world example :

@example
@group
import lmake
from lmake.rules import Rule

# use default config

# automatic sources

class Base(Rule) :
	stems = @{ 'File' : r'.*' @}

class Compile(Base) :
	targets = @{ 'OBJ' : '@{File@}.o'  @}
	deps    = @{ 'SRC' : '@{File@}.cc' @}
	cmd     = 'gcc -c -o @{OBJ@} @{SRC@}'

class LinkHelloWorld(Rule) :
	targets = @{ 'EXE' : 'hello_world' @}
	deps    = @{
		'HELLO_WORLD' : 'hello_world.o'
	,	'HELLO'       : 'hello.o'
	,	'WORLD'       : 'world.o'
	@}
	cmd = 'gcc -o @{EXE@} @{HELLO_WORLD@} @{HELLO@} @{WORLD@}'

class Run(Base) :
	target = '@{File@}.out'
	deps   = @{ 'EXE' : '@{File@}' @}
	cmd    = '@{EXE@}'

class Check(Base) :
	target = '@{File@}.ok'
	deps = @{
		'OUT' : '@{File@}.out'
	,	'REF' : '@{File@}.ref'
	@}
	def cmd() :
		assert open(OUT).read()==open(REF).read()
@end group
@end example

Note a certain number of elements we have not introduced yet :
@itemize @bullet
@item
We use a base class to define the stem @code{File}, so we do not need to repeat its definition in each rule.
@item
In rule @code{Run}, we have defined the attribute @code{target} as a @code{str} rather than attribute @code{targets} as a @code{dict}.@*
This this handy in simple situations and has the following meaning :
@itemize @bullet
@item There is a single target
@item Its content is generated from the stdout of @code{cmd} execution
@end itemize
@item
If @code{cmd} is a @code{str}, the status of the job is determined from the status of the script.
If @code{cmd} is a function, raising an exception or returning convertible to @code{True} will trigger an error status for the rule execution
@end itemize

To run our example, we need to execute @code{lmake hello_world.ok} and this will do all necessary steps that ensure proper generation of the @code{hello_world} executable,
including compilation, link, execution and check.

Note that we do not have to ever mention hidden dependencies (@file{hello.h} and @file{world.h}), these are handled automatically.

A few reactions of @lmake to user actions when you execute @code{lmake hello_world.ok} :
@itemize @bullet

@item If you modify @file{hello.cc}, @lmake will recompile to @file{hello.o}, then relink to @file{hello_world},
then re-generate to @file{hello_world.out} and finally re-check to @file{hello_world.ok} if @file{hello_world.out} changed or stop there if it did not.

@item If you modify @file{hello.hh}, @lmake will recompile to @file{hello.o} and to @file{hello_world.o} in parallel (if resources permit), then proceed with the rest of the flow as above.

@item If you merely modify a comment in @file{hello.cc}, @lmake will recompile to @file{hello.o} (which will be identical to its previous content) and stop there.

@item If you modify the compilation script (e.g. to add the @code{'-O'} option), all compilations are rerun and most probably the rest as well.

@item If you @code{rm} @file{hello.o}, nothing happens.
@item If you @code{rm} @file{hello.o} and modify @file{world.cc}, @lmake will recompile to @file{world.o}, then understands that it needs to @file{hello.o} for the link phase and
will recompile to it, then proceed with the rest of the workflow.

@item If you modify @file{hello.cc} and @file{hello.o}, @lmake will refuse to regenerate @file{hello.o} over your modifications as it fears to destroy an information which is important for you.
For example, you may have saved an important work in this wrong file and you may not have a copy elsewhere.

@end itemize


@chapter User Commands

All commands may be launched from anywhere in a repository.
A repository is a directory containing @Lmakefile.
This means that before being executed, all commands walk up the directory tree until it finds a file named @Lmakefile, which is then considered to be the repository.

Argument and reports are systematically localized to the current working directory.
For example, if you launch @code{lmake b} from directory @file{a} in your repository,
@lmake will execute jobs from the repository root, and during this execution, it will refer to file @file{a/b} as @file{b} and file @file{c} as @file{../c}.

If launched from a terminal, output is colored.
Colors are different depending on whether terminal if dark/light or light/dark.
These colors can be configured.
The colors bears a semantic :
@itemize @bullet
@item Green means success.
@item Red means error.
@item Magenta means warning.
@item Blue means notes generated by the tool.
@item Gray means information of secondary importance.
@item Uncolored means output from user code. This output can be colored by user code (e.g. gcc generates colored error messages, which is very helpful).
@end itemize

@section Global options
In addition to options described for each user command, the following options are supported by all of them.
@itemize @bullet
@item @code{-J}|@code{--job}   : passed arguments are interpreted as job names rather than as file names.
Job names are the names that appear, for example, on start and done lines when @lmake executes a job.
@item @code{-R}|@code{--rule}  : when the previous option is used, this options allows the specification of a rule, given by its name.
This is necessary when the job name is ambiguous as several rules may lead to the same job name.
@item @code{-q}|@code{--quiet} : Do not generate user oriented messages.Strictly generate what is asked.
This is practical if output is meant for automatic processing such as executing the output of @code{lshow -s}.
@item @code{-S}|@code{--sync}  : Ensure server is launched and wait for its termination.
@item @code{-V}|@code{--video} : Explicitly ask for a video mode instead of interrogating connected terminal.
If argument start with @code{n} or @code{N}, output is assumed to be normal video (black on white).
If it starts with @code{r} or @code{R}, reverse video is assumed.
Else output is not colorized.
@end itemize

If the @code{LMAKE_VIDEO} environment variable is defined, it is processed as if provided to the @code{--video} option.

@section @lmake

Usage : @code{lmake [-a|--archive] [-e|--forget-old-errors] [[-j|--jobs] max_jobs] [-m|--manual-ok] [-o|--live-out] [-l|--local] [-v|--versbose-backend] targets...}

@lmake launches all necessary jobs to ensure that targets are generated following rules specified in @Lmakefile.

@lmake generates an output line for each significant event :
@itemize @bullet
@item When a job starts if it is long (duration that qualifies a job as long is configurable). This start line is deemed of secondary importance.
@item When a job terminates.  Such lines are followed by the content of stderr if any and status is known.
@item When the job status is finally known, if it was not known when it terminated.
Such lines are followed by the content of stderr if any.
Typically the job status is not known at the end of execution when a new dep was discovered that turned out to be out-of-date.
In that case, the dependency is rebuilt, and if the new content is identical to the old one, @lmake can then decide that the job was run with up-to-date deps.
@end itemize

During execution, if launched from a terminal, @lmake also generates a progression status in the title bar.
This progression status line contains :
@itemize @bullet
@item the number of executed jobs (split between useful, rerun and hit)
@item the number of queued jobs, i.e. jobs that are waiting for resources to be run
@item the number of waiting jobs, i.e. jbos that are waiting for dependencies to be run
@end itemize

At the end of the execution, if the asked targets are not successfully generated, a summary is generated reminding the errors (with a configurable max, 20 by default)
and the stderr of the first error. Intermediate targets are deemed of secondary importance.

When run @lmake launches a server and direct its request to it.
This server can then serve other @lmake requests, so that several @lmake process can run simultaneously in the same repository.

During a @lmake process, all jobs are launched according to the state of the repository at the time the @lmake command was launched.
This way, edition in the repository can go on while the @lmake process runs.
If it turns out that a file is needed that has been modified since @lmake was launched, it will be deemed in error for that process.
This way, if you want a reliable run, then you must not modify the repository while @lmake is running.
But if you are running @lmake in an interactive mode, it is very comfortable to be able to go on with your edition session while some regression testing is running.
At worst, you will have an error mentionning a file has been overwritten, but you will not have an incoherent result based on some old files and some newer files.

Before processing arguments, @lmake prepends the content of the @code{LMAKE_ARGS} environment variable, separated by spaces.
This eases the management of user preferences.
For example, a user may like to systematically pass the @code{-a} and @code{-t} options, in which case it can set @code{LMAKE_ARGS='-a -t'}.

Options :
@itemize @bullet
@item @code{-a}|@code{--archive} : ensure all intermediate files are up to date, in addition to the asked targets.
This is useful for example if you want to archive a fully built repository.
@item @code{-b}|@code{--backend} : pass value to backend.
This is used for example to pass a partition or specificities to the slurm backend for a particular command.
Note that backend only impacts resources and scheduling, not the content of the targets, so specifying such an option does not hurt repeatability.
@item @code{-e}|@code{--forget-old-errors} : assume encountered errors are transicent.
Contrarily to the @code{lforget -e} command, this only concerns this execution, not subsequent ones.
@item @code{-j}|@code{--jobs} max_jobs : When this option is used, @lmake will limit the overall number of simultaneous jobs to max_jobs per backend.
If several @lmake commands run simultaneously, a job cannot be launched on behalf of a given command if the number of running jobs is not less than its associated max_jobs.
@item @code{-m}|@code{--manual-ok} : normally, @lmake refuses to launch a job that may overwrite a modification done by the user (unless the file is empty)
as @lmake fears to jettison important information from the user.
With this option, the user instructs @lmake that this fear is not pertinent.
@item @code{-o}|@code{--live-out} : normally, @lmake does not output the stdout of jobs (such stdout is accessible with the @code{lshow} command).
However, sometimes it is practical to have the output while jobs are running.
Generating such output for all jobs would produce an intermixed flow of characters of all jobs running in parallel making such an output unreadable.
When this option is used, only the jobs directly producing the asked targets have their output generated on the output of @lmake.
Because most of the time there is a single target, this ensures that there is a single job generating its output, avoiding the intermixing problem.
@item @code{-l}|@code{--local} : with this option, jobs are launched locally (i.e. using the @code{local} backend) instead of the backend mentioned in the rule.
Note that if 2 @lmake commands with different values for this option are running simultaneously, in case a job is necessary for both, it may be launched locally or remotely.
The originally targetted backend is in charge of mapping required resources mentioned in the rule to local resources understandable by the local backend.
@item @code{-s}|@code{--source-ok} : normally, @lmake refuses to launch a job that may overwrite a source.
With this option, the user instructs @lmake that this is allowed.
@item @code{-t}|@code{--keep-tmp} : normally, @lmake washes the temporary directory allocated to a job at the end of job execution.
With this option, the user instructs @lmake to keep the temporary directories, as if the @code{keep_tmp} attribute was set for all rules.
The kept temporary directory can be retreived with @code{lshow -i}.
@item @code{-v}|@code{--verbose} : enable the generation of some execution information from backend.
This is not systematic as this may incur a performance hit.
These information is available by using @code{lshow -i}.
@end itemize

@subsection output

While @lmake runs, it outputs a log.
This log is also recorded in @file{LMAKE/outputs/<start date>} with the following differences :
@itemize @minus
@item It is not colored.
@item Files are relative to the root of the repository, not to the current working directory where the @lmake command has been launched.
@end itemize

The log contains a line, possibly followed by attached information when the following events occur :
@itemize @minus
@item A job is started, if the job duration is longer than the @code{start_delay} attribute of the rule.
@item A job is completed.
@item A job status is known, while it was not known when it completed.
@item A source file has been seen as modified.
@item A frozen file or a target of a frozen job is needed.
@end itemize

Once the build process is complete, a summary is generated with :
@itemize @minus
@item The frozen files and jobs that we necessary to carry out the build.
@item The jobs in error (the first of them is accompanied with its stderr).
@end itemize

@section @code{lshow}

Usage : @code{lshow -short_cmd|--long_cmd [ -short_option|--long_option option_arg ]* files or job}

@code{lshow} provides various information about jobs.
The jobs are those officially generating the targets (i.e. the jobs that would be selected by @lmake if needing to generate it) if any,
else it may be the jobs that actually generated the target.

There must be a single command while there may be 0 or more options.

Arguments can be files or a single job as described in generic arguments description.

Commands :
@itemize @bullet
@item @code{-b}|@code{--bom} : Output the list of all source files necessary to build the arguments.
If verbose (option @code{-v} or @code{--verbose}), some intermediate files are shown in gray, enough to justify why all listed source files.
@item @code{-c}|@code{--cmd} : Output the @code{cmd} used to execute the job. If dynamic, it shows the specialized @code{cmd} for this job.
@item @code{-d}|@code{--deps} : Output the list of all the deps of the jobs.
Unless the verbose flag is specified, only existing deps are shown.
Each line is composed of 6 fields  separated by spaces :
@itemize @minus
@item Flags : each flag is either a letter if set, or a @code{-} if not :
	@itemize .
	@item @code{E} : dep is essential, i.e. dep is show in a future graphical tool.
	@item @code{c} : dep is critical (cf @pxref{critical-deps}).
	@item @code{e} : ignore errors on dep, i.e. job can be run even if this dep is built in error.
	@item @code{r} : dep is required, i.e. job is in error if dep is not buildable. For static deps, job is not even tried if dep is not buildable (and another rule is used if possible).
	@item @code{S} : dep is static.
	@end itemize
@item Accesses : each kind of accesses is either a letter if done, or a @code{-} if not :
	@itemize .
	@item @code{L} : dep has been accessed as a symbolic link.
	@item @code{R} : dep has been accessed as a regular file.
	@item @code{T} : dep has been accessed with a stat-like system call (i.e. its inode has been accessed).
	@end itemize
@item Key : the key if the dep is static, else blank.
@item Ascii art showing parallel deps (deps coming from a single call to @code{ldepend} or @code{lmake.depend} are considered parallel).
@item Name of the dep.
@end itemize
If a dep does not exist, it is deemed secondary information and is shown in gray.
@item @code{-D}|@code{--inv-deps} : Show jobs that depend on targets.
@item @code{-E}|@code{--env}      : Show the environment used to run the script
@item @code{-i}|@code{--info}     : Show various self-reading info about jobs, such as reason to be launched, why it was needed, execution time, host that executed it, ...
If porcelaine mode (using the @code{--porcelaine} or @code{-p} option), the same information is reported as as an easy to parse Python @code{dict}.
@item @code{-r}|@code{--running}  : Show the list of jobs currently running to build the arguments.
If verbose (option @code{-v} or @code{--verbose}), some waiting jobs are shown in gray, enough to justify why all running jobs are running.
Queued jobs are shown in blue, actively running jobs are uncolored.
@item @code{-e}|@code{--stderr}   : Show the stderr of the jobs.
@item @code{-o}|@code{--stdout}   : Show the stdout of the jobs.
@item @code{-t}|@code{--targets}  : Show the targets of the jobs.
Unless the verbose flag is specified, only existing targets are shown.
Each line is composed of 3 fields  separated by spaces :
@itemize @minus
@item Info : composed of 1 characters : @code{W} if target was written, @code{U} if target was unlinked, else @code{-}.
@item Flags : each flag is either a letter if set, or a @code{-} if not :
	@itemize .
	@item @code{E} : target is essential, i.e. target is show in a future graphical tool.
	@item @code{i} : target is incremental, i.e. it is not unlinked before job execution and read accesses are ignored
	@item @code{p} : target is phony, i.e. being non existing a considered as a particular value for that file
	@item @code{u} : target is not uniquified if several links point to it before job execution (only meaningful for incremental targets).
	@item @code{w} : no warning is emitted if target is either uniquified or unlinked while produced by another job.
	@item @code{S} : target is static.
	@item @code{T} : target is official, i.e. job can be triggered when another one depend on this target.
	@end itemize
@item The name of the target.
@end itemize
If a target does not exist, it is deemed secondary information and is shown in gray.
@item @code{-T}|@code{--inv-targets} : Show jobs that produce targets either officially (listed in @code{targets} attribute) or not (listed in @code{side_targets} attribute or not)
@end itemize

@section @code{ldebug}

Usage : @code{ldebug [-k|--key <key>] [-n] target}

@code{ldebug} runs a job in a debug environment.

The job must have been run with @lmake before (but may not have finished, it just need to have started).
The precise way the job is launched is controled by the @code{lmake.config.debug[<key>]} which provides the name of a module to import.
This module must contain a @code{gen_script} function taking a description of the job provided as keyword arguments and returning the script to execute.

When @code{ldebug} is run, the debug script is generated in a file withing the @file{LMAKE} directory and, unless the @code{-n} or @code{--no-exec} option is given, it is executed.

To write a module for use with @code{ldebug}, the best way is to start from the closest standard module in @file{lib/lmake_debug} and modify it to fit your specific needs.

Unless overridden, the following standard debug methods are provided :
@multitable @columnfractions 0.05 0.15 0.4 0.4
@headitem Key @tab Module @tab Python job @tab Shell job
@item
@tab @file{lmake_debug.default}
@tab Job is run under pdb control.
@tab Job is run with the @code{-x} flag (so that commands are traced) and an interactive shell (as provided by the @code{$SHELL} environment variable) is open in the job environment.
@item g
@tab @file{lmake_debug.pudb}
@tab Job is run under pudb control.
@tab Not supported
@item e
@tab @file{lmake_debug.enter}
@tab Job is not run, just an interactive shell (as provided by the @code{$SHELL} environment variable) is open in the job environment.
@tab Job is not run, just an interactive shell (as provided by the @code{$SHELL} environment variable) is open in the job environment.
@item n
@tab @file{lmake_debug.none}
@tab Job is run normally with no debug support.
@tab Job is run normally with no debug support.
@end multitable

In addition to running the job, these standard modules provide the following environment variables to the job :
@itemize @minus
@item @code{LMAKE_DEBUG_KEY}    : the key provided by the @code{-k} or @code{--key} option.
@item @code{LMAKE_DEBUG_STDIN}  : the file connected as stdin to @code{ldebug} when it was launched (usually a tty)
if the job has its stdin redirected (in case the @code{dep} rule attribute is defined).
@item @code{LMAKE_DEBUG_STDOUT} : the file connected as stdout to @code{ldebug} when it was launched (usually a tty)
if the job has its stdout redirected (in case the @code{target} rule attribute is defined).
@end itemize

When an interactive session is started, the @code{HOME} and @code{SHLVL} are preserved to provide a smooth user environment.
In particular @code{$SHLVL} can be used to provide a differentiated prompt if adequately defined in the start up file (usually @file{~/.bashrc}).

Providing a working @code{pudb} with redirected stdin/stdout necessitated to patch it. This patch is dynamically applied as part of the job start up procedure.

@section @code{lmark}

Usage : @code{lmark [ [-a|--add] | [-d|--delete] ] [-f|--freeze] [-t|--no-trigger] [-F|--force] targets...}
or      @code{lmark [-l|--list] | [-c|--clear] [-f|--freeze] [-t|--no-trigger]}

@code{lmark} is used to mark jobs and files with specific attributes.

@itemize @bullet
@item freeze : This mark prevents jobs from being run.
Instead its targets (as built during the last run for star targets) behave as sources.
If no job generated a file provided in arguments, this file behave as a source.
@item no trigger : This mark prevents @lmake to trigger builds of dependent jobs after modifications of provided files.
However, this applies only if job was last run with success.
@end itemize

Jobs and files marked with freeze or no-trigger and that have been used are repeated in the summary.
This precaution is taken because such presence goes against repeatability and should be suppressed before commiting the repository.

Frozen jobs are useful to run a flow from A to B. To do that you type @code{lmark -f -a A} followed by @code{lmake B}.

No trigger files are useful when working on a foundation file (called @file{utils.h} hereinafter).
It is common to work on @file{utils.h} to add new features.
During such developments, it is practical to run a test suite that checks the new feature.
But to run this test suite, you probably need a lot a derived files that depend on @file{utils.h} without using the new feature.
It is then a waste of time and resources to rebuild these derived files at each tiny modification.
An easy way is :
@itemize @minus
@item mark @file{utils.h}) with @code{no-trigger}
@item write the new test that uses this new feature.
@item modify @file{utils.h} to implement the new feature.
@item run your test.
Files not using the new feature will likely be successfully built and will not be uselessly rebuilt.
File using the new feature will likely fail and will be usefully rebuilt.
If no error is generated, it is easy to run @code{rm} or @code{lforget} to force rebuild.
@item loop on modify/test until feature is ok.
@item when you are satisfied with the new feature, suppress the no-trigger mark and rerun your test suite to ensure repeatability.
@end itemize

Options :
@itemize @bullet
@item @code{-a}|@code{--add}    : mark mentioned jobs or files.
@item @code{-d}|@code{--delete} : remove mark from mentioned jobs or files.
@item @code{-l}|@code{--list}   : list marked files.
@item @code{-c}|@code{--clear}  : delete all marks.
@end itemize

@section @code{lforget}

Usage : @code{lforget [-d] [-t] targets...} or @code{lforget [-e|-r]}

@code{lforget} is used to ask lmake to forget about some of its history.
In its first form, subsequent @lmake commands will forget about the build history of the mentioned targets.
As a consequence, these targets will appear out of date.

This is exceptionally useful in situations where @lmake's hypotheses are broken :
@itemize @minus
@item A file outside the repository is modified. Because @lmake does not track modifications outside the repository, it canot rerun jobs that must be rerun, this must be done manually.
@item An error is transient. Another option is to launch @code{lmake -e} which asks to consider jobs in error as out-of-date.
@end itemize

Options are :
@itemize @minus
@item @code{-d}|@code{--deps}    : In addition, @lmake will forget about hidden deps.
@item @code{-t}|@code{--targets} : In addition, @lmake will forget about star targets.
Caveat : upon next run, these targets will not be unlinked, with a possible rerun as a consequence if non-incremental targets are read before being written.
@end itemize

In its second form, subsequent @lmake commands will :
@itemize @minus
@item @code{-e}|@code{--error} : consider errors seen so far as transient errors and will rerun corresponding jobs.
@item @code{-r}|@code{--resources} : not trust builds with old resources and rerun targets that have been successfully built with old resources.
@end itemize

The @code{-e} option is useful when you have actully seen transient errors.
Just rerunning jobs in error will wash these.
If you need finer control, then you must use the first form of @code{lforget} to control what must be forgotten on a job by job basis.

The @code{-r} option is useful in the following scenario :
@itemize @minus
@item You have run jobs J1 and J2. J1 completed successfully but J2 lacked some memory and ended in error.
@item Then you have modified  the allocated memory, increasing J2's memory and decreasing J1's memory because you think it is better balanced this way.
@item Then you remade both jobs. J2 reran because it was in error and now completes successfully. J1 did not rerun because it was ok and modifying some resources would not change the result.
@item However, it could be that now J1 does not have enough memory any more. It is not a problem in itself because its content is correct, but it may not be reproducible.
@item You want to make sure your repository is fully reproducible.
@item In that case, you run @code{lforget -r}. J1 will rerun because it was not run with the new resources, as if its command was modified. J2 will not because it has already run since then.
@end itemize

@section @code{autodep}

Usage : @code{autodep [ -short_option|--long_option option_arg ]* executable args...}

@code{autodep} is a small tool that may be useful when designing a flow.
It is also used by @code{ldebug} to launch jobs in an adequate environment.
It allows to see what information (dependencies and targets) are recorded by code instrumentation @lmake injects in jobs to track activity without actually run a job under its control.

The trace generated by @code{autodep} is halfly digested in the sens that :
@itemize @minus
@item Only a summary of pertinent accesses are provided, unlike @code{strace} can generate a line for each access.
There is a line for each accessed file, which may be a read or nothing, possibly followed by a write or an unlink.
@item Accesses are tracked as for @lmake, i.e. files outside the repository are not tracked, except read accesses in a source directory.
@item When symbolic links are supported, they are resolved according to the required support level and additional dependencies may be generated when needed for @lmake to work properly.
@item It is not fully digested as dep/target flags that are provided in rules are not taken into account.
A full digestion to mimic @lmake would require a whole lot of information that would make the user interface significantly heavier, defeating the usefulness of this tool.
@end itemize

Accesses are split into 2 categories :
@itemize @minus
@item Targets : a prefix mention the type of target, unlink versus write, preceded by a read or not.
@item Deps : a kind of ascii art render parallel accesses.
@end itemize

For option descriptions, refer to the corresponding rule attribute.

Options :
@multitable @columnfractions 0.05 0.1 0.15 0.7
@headitem short option @tab long options @tab rule attribute @tab Description
@item @code{-m}
@tab  @code{--autodep-method}
@tab  @code{autodep}
@tab
@item @code{-a}
@tab  @code{--auto-mkdir}
@tab  @code{auto_mkdir}
@tab No argument, the presence of this option is equivalent of a @code{True} value for the rule attribute.
@item @code{-c}
@tab  @code{--chroot-dir}
@tab  @code{chroot_dir}
@tab
@item @code{-d}
@tab  @code{--cwd}
@tab  @code{cwd}
@tab
@item @code{-e}
@tab  @code{--env}
@tab  @code{environ_*}
@tab The mapping must be provided as a python @code{dict}  mapping variable names to their corresponding value (beware of quoting with regard to shell).
@item @code{-i}
@tab  @code{--ignore-stat}
@tab  @code{ignore_stat}
@tab No argument, the presence of this option is equivalent of a @code{True} value for the rule attribute.
@item @code{-k}
@tab  @code{--keep-env}
@tab  @code{environ_*}
@tab The mapping must be provided as a python @code{tuple} or @code{list} listing the variables to keep in the environment (beware of quoting with regard to shell).
@item @code{-l}
@tab  @code{--link-support}
@tab  @code{link_support}
@tab This attribute is in @code{lmake.config}, not on the rule.
@item @code{-o}
@tab  @code{--out}
@tab
@tab The file in which to write access info (deps and targets).
@item @code{-r}
@tab  @code{--root-view}
@tab  @code{root_view}
@tab
@item @code{-s}
@tab  @code{--source-vdirs}
@tab  @code{source_dirs}
@tab The list must be provided as a python @code{tuple} or @code{list} (beware of quoting with regard to shell).
@item @code{-t}
@tab  @code{--tmp-view}
@tab  @code{tmp_view}
@tab
@item @code{-v}
@tab  @code{--views}
@tab  @code{views}
@tab The mapping must be provided as a python @code{dict}  mapping views to their corresponding list of origin (beware of quoting with regard to shell).
@item @code{-w}
@tab  @code{--work-dir}
@tab
@tab The name of a directory.
Its content is unpredictable after execution.
This is necessary as soon as one of the views has more than one origin (in that case, overlayfs is used, which requires aorking directory).
@end multitable

@section @code{xxhsum}

Usage : @code{xxhsum file}

XXH is a very high performance, high quality checksum generation algorithm internally used by @lmake to find out whether file was actually modified or not when its date is changed.
XXH is high quality but @strong{not} crypto-robust.
This means that you can defeat it if you write a code specially aimed at this purpose, but not otherwise, by chance.
The version used in @lmake is 56/64 bits : Checksums are computed on 64 bits but when comparing 2 checksums, if they match on 56 (lsb) bits but not on the full 64 bits,
@lmake will consider we enter into a @emph{danger zone} and will stop.
Theoretical computation gives that you can generate thousands of files per second for thousands of year before entering the @emph{danger zone}.
However this theoretical computation assumes that XXH is nearly perfect, which seems to be the case with regards to experiments, but of course it is impossible to do such experiments with
a particular data set that may be far from random and from the actual data set used to evaluate XXH.
In the very improbable case where your data set would be particularly unfriendly with XXH, @lmake will crash with an error rather than silently forgetting to rerun a job.

@code{xxhsum} allow you to generate the checksum of a file, as distingued by @lmake.

Because @lmake handles symbolic links as themselves and not as the file they point to (i.e. @lmake works in the physical world), @code{xxhsum} does not follow symbolic links.
The checksum generated for a symbolic link is computed after the link (not the content of the file it refers to)
and such checksums do not clash with regular files with the same content (a different salt is used).

Also, the execute permission bit is also used to compute the checksum of regular files.
@lmake does not handle security bits (read and write permissions), but the execute bit is a semantic bit (possibly in addition to security) and thus is managed by @lmake.

Directories and other awkward files (i.e. neither a regular file or a symbolic link) are handled as if they did not exist.

The following special cases produce dedicated outputs :
@itemize
@item file does not exist : output is @code{'none'}
@item file is empty       : output is @code{'empty'}
@end itemize

@section @code{lrepair}

Usage : @code{lrepair}

@code{lrepair} is meant to repair internal @lmake book-keeping in case of catastrophic crash, either because of system failure or a bug in @lmake.
Most of the time, @lmake does not need resort to heavy reparation as its internal book-keeping is fairly robust, but in some rare cases, this may be necessary.
In such a case, @lmake will suggest the use of @code{lrepair}.
In case of incoherent behavior, the user may decide to run @code{lrepair}.
This process is pretty long, the goal being to avoid having to restart from a fresh repository, which may incur a severe cost in terms of compute power.

@chapter Job Commands

The commands listed hereafter are meant to be executed from within a job, not as standalone commands.

@section @code{ldepend}

Usage : @code{ldepend [-<short-option>|--<long-option>]... files ...}

@code{ldepend} may be used to inform @lmake that some files must be deemed as read as if you called the @code{open} system call on each of them.
To this extent, it is not that much different from @code{cat} (except performance wise, depend is of course much faster since @code{files} are not really accessed).

Also, generated dependencies are parallel, i.e. a modification on a dependency will not mask an error on another one.
For example, if you do @code{cat a b}, @lmake sees 2 @code{open} system calls, to @file{a} then to @file{b},
exactly the same sequence that if you did @code{cat $(cat a)} where @file{a} contains @code{b} as its only content.

Suppose now that @file{b} is an error. This is a reason for your job to be in error.
But if you modify @file{a}, in the former case, this @strong{cannot} solve your error while in the later case, it may, if the new content of a points to file that may be successfully built.
Because @lmake cannot distinguish between the 2 cases, upon a modification of @file{a}, the job will be rerun in the hope that the error is solved.
Parallel dependencies wil prevent this to happen.

If you do @code{ldepend a b} and @file{a} is modified and @file{b} is in error, the job is not rerun and stays in error.

Also, if for some reasons you run with autodep method @code{none}, this is the way to report dependencies.

In addition to signaling an access, @code{ldepend} is used to set flag on the files passed as arguments. Flags accumulate and will apply if the file is independently accessed.

The following options are supported :
@itemize @bullet
@item @code{-L}|@code{--follow-symlinks} : follow the last level symbolic link, default is not to follow.
@item @code{-v}|@code{--verbose}         : write lines composed of the crc and the name separated by a space for each required dependency.
@item @code{-R}|@code{--no-read}         : does not report an actual read, only dep flags. Default is to report a read and alter flags.
@item @code{-c}|@code{--critical}        : create critical deps (cf @pxref{critical-deps}).
@item @code{-E}|@code{--essential}       : passed dependencies will appear in the flow shown with a graphical tool.
@item @code{-e}|@code{--ignore-error}    : ignore the error status of the passed dependencies.
@item @code{-r}|@code{--no-required}     : accept that dpes may not be buildable, as for a normal read access (in that case, the read may fail, but @lmake is ok).
@item @code{-I}|@code{--ignore}          : dep is ignored altogether.
@item @code{-d}|@code{--stat-read-data}  : if dep is accessed with a stat-like access, ensure @lmake will consider full content has been accessed.
Default is to optimize dependency check as much as possible.
@end itemize

@section @code{lcheck_deps}

Usage : @code{lcheck_deps}

@code{lcheck_deps} ensures that all dependencies accessed so far are up-to-date.
If this not the case, the job is killed, generating a @code{rerun} report, the dependencies are rebuilt and the job is rerun.

This is useful before starting a heavy computation. Typically, dependencies are computed and accessed before the heavy sequence and calling @code{check_deps} allows to avoid
running a heavy computation with bad inputs. It is not a semantic problem as @lmake will realize the situation, rebuild the dependencies are rerun the job, but it may be performance problem.

Imagine for exemple that you have to compile @file{heavy.c} that includes a file @file{generated.h} generated by the command @file{generator}.
Imagine then that you type @code{lmake generated.h}, you look at it, find that the file is syntactically correct but contains a bug.
You then modify @file{generator} and because you are confident in your modification, you type @code{lmake heavy.o}.

@lmake will run the compilation of @file{heavy.o}, which lasts 10 minutes and discover that you need @file{generated.h}, which is out-of-date.
It will then rebuild @file{generated.h} and rerun the compilation to @file{heavy.o}, another 10 minutes.

Suppose now that your compilation script separate the preprocessor (say 10 secondes) phase from the compilation (10 minutes) phase and call @code{lcheck_deps} inbetween.
In that case, the first run will stop after preprocessing as @code{lcheck_deps} will kill the job at that moment and the overall time will be 10 minutes 10 secondes instead of 20 minutes.

Note the following points :
@itemize @minus
@item This is a (performance) problem only during the first run of @file{heavy.o}.
On subsequent runs, in particular during a typical edit-compile-debug loop, @lmake will know the dependencies and will launch jobs in the proper order.
But during the first run, it has no knowledge that @file{heavy.c} actually includes @file{generated.h}.
@item Most often, when @file{generated.h} is out-of-date, it is syntactically incorrect (for example it does not exist),
so the first run fails quite early (without spending its heavy optimization time).
@item In the case where @file{generated.h} is rebuilt identically to its previous content, there will be no second run without @code{lcheck_deps} call,
so @code{lcheck_deps} has a (minor) adverse effect leading to an overall time of 10 minutes 10 seconds instead of 10 minutes.
@end itemize

Despite these remarks, there are case where @code{lcheck_deps} is very welcome.

@section @code{ltarget}

Usage : @code{ltarget [-<short-option>|--<long-option>]... files ...}

@code{ltarget} may be used to inform @lmake that some files must be deemed as written as if you called the @code{open} system call on each of them.
If for some reasons you run with autodep method @code{none}, this is the way to report targets.

Also, it is possible to alter the target flags for these targets. Flags accumulate and apply if the files are independently accessed.

The following options are supported :
@itemize @bullet
@item @code{-L} or @code{--follow-symlinks} : follow the last level symbolic link, default is not to follow.
@item @code{-W} or @code{--no-write}        : does not report an actual write, only target flags. Default is to report a write an alter flags.
@item @code{-E} or @code{--essential}       : show when generating user oriented graphs.
@item @code{-i} or @code{--incremental}     : target is not unliked before job execution and read accesses to it are ignored.
@item @code{-u} or @code{--no-uniquify}     : target is not uniquified if several links are pointing to it. Only meaningful for incremental targets.
@item @code{-w} or @code{--no-warning}      : no warning is emitted if target is either uniquified or unlinked while generated by another job.
@item @code{-I} or @code{--ignore}          : from now on, ignore all reads and writes to target.
@item @code{-a} or @code{--no-allow}        : unless this option is passed, @code{ltarget} makes its arguments valid targets (cf @pxref{targets-deps}).
@item @code{-s} or @code{--source-ok}       : unless this option is passed, @code{ltarget} writing to a source is an error.
@end itemize

@section @code{ldecode}

Usage : @code{ldecode association_file context code}

@code{ldecode} may be used to ask for a value (typically rather large) associated with a short code.
This must have been generated using the command @code{lencode} with the same association_file and context.
The value corresponding to the code is output on @code{stdout}.
It is an error if
@itemize @minus
@item association_file is not a source (symbolic links are followed, though).
@item code cannot be found with the accompanying context
@end itemize
Usage and use cases are more extensively documented in @xref{codec}.

@section @code{lencode}

Usage : @code{lencode association_file context [min_length]}

@code{lencode} may be used to create or retrieve an association between a value (typically rather large) and a short code.
This association must be done before @code{ldecode} is called with the code to retrieve the corresponding value.

The value must be passed to @code{stdin}.
The generated or retrieved code corresponding to the value is output on @code{stdout}.
If generated, the code is generated after a checksum computed on the passed value in hexadecimal, with a length at least min_length, but may be longer in case of conflict.
It is an error if association_file is not a source (symbolic links are followed, though).
Usage and use cases are more extensively documented in @xref{codec}.


@chapter The Python @lmake module

The @lmake module provides support to write @code{cmd} functions executed during job execution.

The @code{lmake.rules} module provides support to write rules themselves.

The @code{lmake.auto_sources} module can be used to help define sources if the default behavior is not satisfactory.

Some variables of this module can be defined in @Lmakefile for some specific purposees.

@section @code{class pdict}

This is a helpful tiny @code{class} deriving from @code{dict} that allows item access as attribute.
This is just syntactic sugar to help the manipulation of configuration @code{dict} objects.

Also, a @code{mk_deep} method exists to transform a @code{dict} into a @code{pdict} in a deep way (i.e. sub-@code{dict}'s are transformed into @code{pdict} as well).

@section @code{def multi_strip(txt)}

This is a helpful tiny function that strips its argument and suppresses the common leading spaces of all lines.
This allows and easy way to define commands using triple quote strings while maintaining a clean indentation but without such indentation appearing in the resulting string.

For example, in this code :

@example
@group
from lmake.rules import Rule
class X(Rule) :
	cmd = multi_strip('''
		line1
			indented line2
	''')
@end group
@end example

The resulting value for @code{X.cmd} is :

@example
@group
line1
	indented line2
@end group
@end example

@section @code{def version(major,minor)}

This function is used to check that the expected version is compatible with the actual version.

Upon new releases of @lmake, the major version is incremented if it is not backward compatible, else the minor version is increased if the interface is modified (i.e. new features are supported).
Hence, the check is that major versions must match equal and the actual minor version must be at least the expected minor version.

This function must be called right after having imported the @lmake module as it may adapt itself to the required version when this function is called.
For example, some default values may be modified and if they are used before this function is called, a wrong (native) value may be provided instead of the correct (adjusted to required version) one.

@subsection @code{def search_root_dir(cwd=os.getcwd())}
Return the root dir as seen from passed @code{cwd} argument.

Note that his may be different from the @code{root_dir} variable in case there is a @Lmakefile file in a subdir.

@subsection @code{def has_backend(backend)}
Return @code{True} if the passed backend is implemented, else return @code{False}.

Raises the @code{ValueError} exception is the passed backend is unknown.

@section constants

The following constants are defined :
@table @code
@item root_dir
The root directory of the repository as determined when the @lmake command was run.

Recursive sub-repositories are ignored.
Use the @code{search_root_dir} function if you want to get the nearest hierarchical root dir.
@item has_ld_audit
@code{True} if autodep method @code{'ld_audit'} is supported, else @code{False}.
@item has_ld_preload
@code{True} if autodep method @code{'ld_preload'} is supported, else @code{False}.
@item has_ptrace
@code{True} if autodep method @code{'ld_ptrace'} is supported, else @code{False}.
@item backends
The list of implemented backends. @code{local} is always present.
@item no_crc
The 64-bit @code{int} checksum when it has not been computed (yet).
@item crc_no_file
The 64-bit @code{int} checksum produced when computed on a non-existent file.
@end table

@section Job execution support

The Python @lmake module also provides a Python API to the job supporting command described above.
The correspondance is :
@table @asis
@item @code{def check_deps()}
@code{lcheck_deps}
@item @code{def depend(*files,follow_symlinks=True,verbose=False,read=True,critical=False,essential=False,ignore_error=False,required=True,ignore=False,stat_read_data=False)}
@code{ldepend}
@code{files} may be a single @code{tuple} or a @code{tuple} of @code{str}'s.
For example, you can call @code{depend('file1','file2')} or @code{depend(('file1','file2'))}.
@item @code{def target(*files,follow_symlinks=True,write=True,essential=False,incremental=False,phony=False,no_uniquify=False,no_warning=False,ignore=False,source_ok=False,allow=True)}
@code{ltarget}
@code{files} may be a single @code{tuple} or a @code{tuple} of @code{str}'s.
For example, you can call @code{target('file1','file2')} or @code{target(('file1','file2'))}.
@item @code{def decode(file,context,code)}
@code{ldecode}
The return value is the value associated with code.
@item @code{def encode(file,context,value,min_len=1)}
@code{lencode}
The return value is the generated of retrieved code.
@end table

@section @code{lmake.get_autodep}
@code{def get_autodep()}

This function returns whether autodep is currently activate (@code{True}) or deactivated (@code{False}).
When activated, the monitoring is performed normally.
When deactivated, no access monitoring is performed, as if the @code{autodep} rule attribute is set to @code{None}.
Note that even in that case, the @code{depend} and @code{target} functions work normally.

Using the @code{Autodep} @code{class}, the context version of this function, is much easier.

@section @code{lmake.set_autodep}
@code{def set_autodep(active)}

This function may be used to activate or deactivate the autodep machinery.
When activated, the monitoring is performed normally.
When deactivated, no access monitoring is performed, as if the @code{autodep} rule attribute is set to @code{None}.
Note that even in that case, the @code{depend} and @code{target} functions work normally.

Using the @code{Autodep} @code{class}, the context version of this function, is much easier.

@section @code{class Autodep}
@code{def __init__(self,enable)}

This @code{class} is initialized with a single @code{bool} as argument.

This class may be used as a context to temporarily enable or disable the autodep machinery and can be nested, as in the following example :

@example
@group
import subprocess
import lmake
class Foo(Rule) :
	targets = @{ 'DST' : 'foo' @}
	def cmd() :
		with lmake.Autodep(False) :
			subprocess.run(('no_autodep_in_script',))
			print(open('no_dep_for_this_file').read(),file=open(DST,'w')) # writing to DST is not seen
			lmake.target(DST)                                            # however this will report writing to DST
			with lmake.Autodep(True) :
				print(open('dep_recorded_for_this_file').read(),file=open(DST,'w')) # writing to DST is seen
@end group
@end example

@section The @code{lmake.rules} module

@subsection @code{class Rule}
This @code{class} is used as a base @code{class} for rules.

@subsection @code{class AntiRule}
This @code{class} is used as a base @code{class} for anti-rules.

Anti-rules specify that target files that are not buildable.
They have no dependencies nor execution.

@subsection @code{class SourceRule}
This @code{class} is used as a base @code{class} for sources defined by a pattern.

Source-rules specify that a matching target is considered a source.
If such a file is required and does not exist, it is an error condition.
They have no dependencies nor execution.

@subsection @code{class Py[23]Rule}

These classes may be used as base @code{class} for Python code doing imports.

It manages @code{.pyc} files so that user is not annoyed by Python generating @code{.pyc} files at esoteric places.

It relies on @code{stat} access made by Python to access the original @code{.py} to check @code{.pyc} validity.
As a consequence, if you want to set the @code{ignore_stat} attribute on a @code{PyRule}, you must run python with the @code{-B} option set for all rules.
Otherwise, dependencies to the original @code{.py} will be lost when the @code{.pyc} is available an up-to-date.

@code{Py2Rule} manages Python2.
@code{Py3Rule} manages Python3.
@code{PyRule} is an alias for @code{Py3Rule}.

In addition standard attributes, the following ones may be set on these rules :
@itemize @minus
@item @code{gen_module_deps} : If set (the default), the import machinery is set up to ensure all deps to all logically searched files are recorded.
This ensures dynamically generated modules will be adequately rebuilt if necessary.
If not set, Python optimizes its search and misses module files if the enclosing directory does not exist.
@item @code{mask_python_deps} : Only supported for Python3. If set, the import machinery is set up to prevent Python from generating deps when reading files.
This is useful when Python absusively stats files it does not import, which occur in certain cases.
@end itemize

@subsection @code{class DynamicPy[23]Rule}
These classes may be used as base @code{class} for Python code doing imports that are dynamically generated.

In addition to @code{Py[23]Rule} features, they patch Python import machinery to prevent optimizations that suppress accesses to inexisting modules.
Accessing inexisting modules is the way to inform @lmake that these are needed and must be generated.

@code{DynamicPy2Rule} manages Python2.
@code{DynamicPy3Rule} manages Python3.
@code{DynamicPyRule} is an alias for @code{DynamicPy3Rule}.

@subsection @code{class RustRule}
This @code{class} may be used as a base @code{class} to execute executable written in rust.

Rust uses a special link mechanism which defeats the default @code{ld_audit} autodep mechanism.
This base @code{class} merely sets the autodep method to @code{ld_preload} which works around this problem.

@subsection @code{class HomelessRule}
This @code{class} copies the @code{TMPDIR} environment variable to the @code{HOME} one.
This is a way to ensure that various tools behave the same way as if they were run for the first time.
By default  the @code{HOME} environment variable points to the root of the repository, which permits to put various init code there.

@subsection @code{class TraceRule}
This @code{class} defines a preamble for use by shell rules that set the @code{-x} flag (which traces commands) so that traces are sent to stdout.
This is useful as such traces are activity logging, not errors, which are normally reported to stdout in jobs.

@subsection @code{class DirtyRule}
This @code{class} may be used to ignore all writes that are not an official target.

By itself, it is a dangerous @code{class} and must be used with care.
It is meant to be a practical way to do trials without having to work out all the details, but in a finalized workflow, it is better to avoid the usage of this class.

@section The @code{lmake.sources} module
This module provide support functions to define sources.

@subsection @code{def manifest_sources(manifest='Manifest')}
This function returns the list of sources found in the @code{manifest} file, one per line.
Comments are supported as everything following a @code{#} itself at start of line or preceded by a space.
Leading and trailing white spaces are stripped after comment removal.

@subsection @code{def git_sources( recurse=True , ignore_missing_submodules=False )}
This function lists files under @code{git} control, recursing to sub-modules if @code{recurse} is true and ignore missing such sub-modules if @code{ignore_missing_submodules} is true.
The @code{git} repository itself can be an enclosing directory of the @lmake repository.
In that case, sources are adequately set to track @code{git} updates.

@subsection @code{def auto_sources(**kwds)}
This function tries to find sources by calling @code{manifest_sources} and @code{git_sources} in turn, untill one succeeds. Arguments are passed as pertinent.

@chapter Directories

By default, all administration data @lmake needs to track the repository state is in the @file{LMAKE} directory at the root of the repository.

But most data are either accessed only by the @lmake server, or by individual jobs, and need not be on a shared disk that is visible from the server and all execution hosts.
Such disk are typically rather slow, compared to local disks.

So there a possibility to store administration data that do not mandate sharing into local disks.

@anchor{dir-local_admin_dir}
@section @code{lmake.config.local_admin_dir}

This variable specifies the directory to use for data that are accessed by the @lmake server only.
It can be set to a directory mounted on a local disk which may be visible only by the @lmake server (i.e. on the host on which you launch the @lmake command).

This directory need not be unique for each repository as @lmake will create a unique sub-directory per repository (identified by its absolute path).

It is of paramount importance to leave this directory intact as this is where @lmake stores most of its bookkeeping data.

@chapter Config

@lmake can be configured to tailor its parameters to the user needs.

Configuration is done by setting attributes (or items) of the @code{pdict} @code{lmake.config}.

After @lmake has been run (at least once), the configuration, as understood by @lmake can be retrieved in the file @adminfile{config}.

The configuration is reloaded (if necessary) each time a @lmake command is run, which may occur while another one is also running.
However, fields may have restrictions :
@itemize @minus
@item Clean   : This field can only set initially when the repository is clean (for example after a @code{git clean -ffdx} command).
@item Static  : This field can only be modified when no other @lmake command is running.
@item Dynamic : This field can freely be modified.
@end itemize

Recognized attributes are :
@multitable @columnfractions 0.1 0.07 0.05 0.78
@headitem Attribute @tab Default @tab Update @tab Description

@item @code{disk_date_precision}
@tab @code{0.010}
@tab Static
@tab This attribute instruct @lmake to take some margin (expressed in seconds) when it must rely on file dates to decide about event orders.
It must account for file date granularity (generally a few ms) and date discrepancy between executing hosts and disk servers (generally a few ms when using NTP).
If too low, there are risks that @lmake consider that data read by a job are up to date while they have been modified shortly after.
If too high, there is a small impact on performance as @lmake will consider out of date data that are actually up to date.
The default value should be safe in usual cases and user should hardly need to modify it.

@item @code{heartbeat}
@tab @code{10}
@tab Static
@tab @lmake has a heartbeat mechanism to ensure a job does not suddenly disappear (for example if killed by the user, or if a remote host reboots).
If such an event occurs, the job will be restarted automatically.
This attribute specifies the time between 2 successive checks for a given job (subject to the restrictions of @code{heartbeat_tick} below).
If @code{None}, the heartbeat mechanism is disabled.
The default value should suit the needs of most users.

@item @code{heartbeat_tick}
@tab @code{0.1}
@tab Static
@tab @lmake has a heartbeat mechanism to ensure a job does not suddenly disappear (for example if killed by the user, or if a remote host reboots).
If such an event occurs, the job will be restarted automatically.
This attribute specifies the time between 2 successive checks globally for all jobs (subject to the restrictions of @code{heartbeat} above).
If @code{None}, no restriction apply.
The default value should suit the needs of most users.

@item @code{local_admin_dir}
@tab @code{LMAKE}
@tab Clean
@tab This variable contains a directory to be used for @lmake administration in addition to the @code{LMAKE} directory.
Actually most of the accesses are made in this directory (cf @pxref{dir-local_admin_dir}).

@item @code{link_support}
@tab @code{'Full'}
@tab Clean
@tab @lmake has several levels of symbolic link support (cf @pxref{link-support}).
This attribute specifies the used level.

@item @code{max_dep_depth}
@tab @code{1000}
@tab Static
@tab The rule selection process is a recursive one (cf @pxref{rule-selection}).
Several means are provided to avoid infinite recursion and this one is the last resort.
The search stops if the depth of the search reaches the value of this attribute, leading to the selection of a special internal rule called @code{'infinite'}.
@item @code{max_error_lines}
@tab @code{100}
@tab When a lot of error lines are generated by @lmake, other than copying the @code{stderr} of a job, only the first @code{max_error_lines} ones are actually output,
followed by a line containing @code{...}.
The purpose is to ease reading.

@item @code{network_delay}
@tab @code{1}
@tab Static
@tab When a job completes, it signals it to @lmake.
But while this informations is travelling, the job is nowhere : it is no more running and @lmake is not aware of it being completed.
If during that time, the heartbeat fires checking for job liveness or a ^C is hit asking for jobs to die, @lmake may think this job is lost.
To prevent that, @lmake waits for some time before declaring such a job as actually lost.
This attribute provides this delay in seconds.

@item @code{path_max}
@tab unlimited
@tab Static
@tab This is one of the infinite recursion protection in the rule selection process (cf @pxref{rule-selection}).
Any file with name longer than the value of this attribute is deemed not buildable.

@item @code{rules_module}
@tab empty
@tab Static
@tab Specify a module that is used in place of @code{Lmakefile} to define rules, i.e. this module must define rules the same way as described in this document.
If this entry is set, @code{Lmakefile} must have no rules defined.

The primary goal is to decouple loading configuration and loadng rules as @lmake tracks dependencies for each of them separately.
This is both more performant (when there are a lot of rules) and allows dynamic modification of the configuration (for fields that support dynamic updates).

@item @code{sources_module}
@tab @code{lmake.auto_sources} if @code{lmake.manifest} is empty, else empty
@tab Static
@tab Specify a module that is used in place of @code{Lmakefile} to define sources, i.e. this module must define sources by setting the @code{lmake.manifest} variable as described in this document.
If this entry is set, @code{Lmakefile} must have no sources defined in @code{lmake.manifest}.

The default value (@code{lmake.auto_sources}) merely call @code{lmake.sources.auto_sources()} to define @code{lmake.manifest}.
Most of the time, this is suitable so the user rarely has to bother with sources.

The primary goal is to decouple loading configuration and load sources as @lmake tracks dependencies for each of them separately.
This is both more performant (when there are a lot of sources) and allows dynamic modification of the configuration (for fields that support dynamic updates).

@item @code{reliable_dirs}
@tab @code{False} unless only local backend is used
@tab Static
@tab Specify whether directory coherence is enforced when a file is created/modified/unlinked.

It is the case for the following file systems : ceph.

It is not the case for the followin file systems : NFS.

When false, enclosing directories are recursively open before any file is accessed to ensure the right file is open,
and enclosing directory is closed after any file creation, modification or delettion.
This is due to the fact that some file systems, such as NFS.
In other words, on such file systems, the "close to open coherence" must be understood as "the data are there, but it does not mean you are guaranteed access to them".
In order to access the data, you need a reliable directory, which mean you must open the directory before such access, hoping that the directory has been closed by the writer after the last update.
And this applies recursively.

This has a performance cost but no more performant method is known to the autor.
And because of the performance cost, this option has been designed to avoid paying it for file systems that do not require such going through such a headache.

@item @code{console.date_precision}
@tab @code{None}
@tab Dynamic
@tab This attribute specifies the precision (as the number of digit after the second field, for example 3 means we see milli-seconds) with which timestamps are generated on the console output.
If @code{None}, no timestamp is generated.

@item @code{console.host_length}
@tab @code{None}
@tab Dynamic
@tab This attribute specifies the width of the field showing the host that executed or is about to execute the job.
If @code{None}, the host is not shown.
Note that no host is shown for local execution.

@item @code{console.has_exec_time}
@tab @code{True}
@tab Dynamic
@tab If this attribute is true, execution time is reported each time a job is completed.

@item @code{trace.size}
@tab @code{100_000_000}
@tab Static
@tab While @lmake runs, it generates an execution trace recording a lot of internal events meant for debugging purpose.
The trace is handled as a ring buffer, storing only the last events when the size overflows.
The larger the trace, the more probable the root cause of a potential problem is still recorded, but the more space it takes on disk.
This attributes contains the maximum size this trace can hold (@lmake keeps the 5 last traces in case the root cause lies in a previous run).

@item @code{trace.n_jobs}
@tab @code{1000}
@tab Static
@tab While @lmake runs, it generates execution traces for all jobs.
This attributes contains the overall number of such traces that are kept.

@item @code{trace.channels}
@tab all
@tab Static
@tab The execution trace @lmake generates is split into channels to better control what to trace.
This attributes contains a @code{list} or @code{tuple} of the channels to trace.

@item @code{colors}
@tab raisonably readable
@tab Dynamic
@tab @lmake generate colorized output if it is connected to a terminal (and if it understands the color escape sequences) (cf @pxref{video-mode}).
This attribute is a @code{pdict} with one entry for each symbolic color (cf @pxref{video-mode}).
Each entry is a 2-tuple of 3-tuple's.
The first 3-tuple provides the color in normal video mode (black/white) and the second one the color in reverse video (white/black).
Each color is a triplet RGB of values between 0 and 255.

@item @code{backends}
@tab
@tab Dynamic (with possible restrictions from backend)
@tab This attribute is a @code{pdict} with one entry for each backend
(cf @pxref{backends} for an explanation of what is the purpose of backends, and see the backends section for a description of the attributes).
Each entry is a pdict providing resources. Such resources are backend specific.

In addition the @code{precisions} can be set to a @code{dict} with one entry for each standard resource (@code{cpu}, @code{mem} and @code{tmp}).
This attribute must be @code{0} or a power of 2 not less than 2.

If set to a positive value, it represent a number under which full precision is retained when specified in a rule.
Above it, the relative precision is retained, rounding up.
For example, if set to 4, values 1, 2, 3, 4 are retained, but 5 is rounded to 6, 7 to 8, 9 to 12 etc (cf @pxref{resource-buckets}).

@item @code{caches}
@tab
@tab Static
@tab This attribute is a @code{pdict} with one entry for each cache.
Caches are named with an arbitrary @code{str} and are referenced in rules using this name.
The attributes are described in the caches section below.
@end multitable

@section backends

@multitable @columnfractions 0.1 0.07 0.83
@headitem Attribute @tab Default @tab Description
@item @code{backends.*.interface}
@tab best guess
@tab
When jobs are launched remotely, they must connect to @lmake when they start and when they complete.
This is done by connecting to a socket @lmake has opened for listening, which requires that we must have a means to determine an IP address to connect to.
The host running @lmake may have several network interfaces, one of them (typically only one) being usable by such remote hosts.
There is no generic way to determine this address, so in general, @lmake cannot determine it automatically.

This value may be empty (loop-back for local backend, @code{hostname} look up for remote backends), given in standard dot notation, as the name of an interface (as shown by @code{ifconfig})
or the name of a host (looked up as for @code{ping}).
@item @code{backends.local.cpu}
@tab number of physical CPU's
@tab This is a normal resource that rules can require (which is the case if resources are defaulted)
@item @code{backends.local.mem}
@tab size of physical memory
@tab This is the pysical memory necessary for jobs.
It can be specified as a number or a string representing a number followed by a standard suffix such as @code{k},  @code{M} or @code{G}.
Internally, the granularity is forced to MBytes before any possible rounding linked with the @code{precisions} attribute.
@item @code{backends.local.tmp}
@tab 0
@tab This is the disk size in the temporary directory necessary for jobs.
It can be specified as a number or a string representing a number followed by a standard suffix such as @code{k},  @code{M} or @code{G}.
Internally, the granularity is forced to MBytes before any possible rounding linked with the @code{precisions} attribute.
@end multitable

@section caches

By default, no cache is configured, but an example can be found in @file{lib/lmake.py}, commented out.

@multitable @columnfractions 0.1 0.07 0.83
@headitem Attribute @tab Default @tab Description
@item @code{caches.*.tag}
@tab -
@tab This attribute specifies the method used by @lmake to cache values.
In the current version, only 2 tags may be used :
@itemize @minus
@item @code{'none'} is a cache that caches nothing. No further configuration is required for such a cache.
@item @code{'dir'} is a cache working without daemon. The data are stored in a directory.
@end itemize
@item @code{caches.<dir>.repo}
@tab -
@tab Valid only when @code{tag} is @code{'dir'}. This attribute specifies a key identifying the repository.
In order to avoid poluting the cache during typical edit-run-debug loops with data that will never be reused, the cache restrict its data to at most one entry for each job in each repo.
This attribute is used to identiy a repository.
If 2 repositories use the same key, then results produced in one will replace those produced in the other one.
Symetrically, if you use 2 different keys for the same repo, then the cache may store several entries for the same repo.
Besides this restriction, a classical LRU algorithm is used.
@item @code{caches.<dir>.dir}
@tab -
@tab Valid only when @code{tag} is @code{'dir'}.
This attribute specifies the directory in which the cache puts its data.
The directory must pre-exist and contain a file @file{LMAKE/size} containing the size the cache may occupy on disk.
The size may be suffixed by a unit suffix (k, M, G, T, P or E). These refer to base 1024.
@end multitable

@chapter Sources

Sources are files that are deemed as intrinsic.
They cannot be derived using rules as explained in the following chapter.

Also, if a file cannot be derived and is not a source, it is deemed unbuildable, even if it actually exists.
In this later case, it will be considered dangling and this is an error condition.
The purpose of this restriction is to ensure repeatability : all buildable files can be (possibly indirectly) derived from sources using rules.

The list of sources is provided to @lmake by setting the @code{lmake.manifest} variable as the list of sources to use or the @code{lmake.config.sources_module} variable as a module to load.

The manifest can contain :
@itemize
@item Files located in the repository.
@item Directories.
In that case, the whole subtree underneath the directory are considered sources.
Directories may be in the repository or outside, but cannot contain or lie within system directories such as @file{/usr}, @file{/proc}, @file{/etc}, etc.
If outside, they can be relative or absolute.
If the repository is moved, the relative/absolute semantic is enforced.
This is true for cache related aspects as well where comparison between job data located in different repositories must be performed.
@end itemize
In both cases, names must be canonical, i.e. contain no empty component nor @file{.}, nor @file{..} except initially for relative names.

The following helper functions can be used to provide sources.
If nothing is mentioned in @Lmakefile, @code{auto_sources()} is called.

@section @code{manifest_sources(manifest='Manifest',**kwds)} :

This function sets @code{lmake.manifest} from the content of the file provided in @code{manifest}.

@code{kwds} is ignored.

It raises a @code{FileNotFoundError} exception if @code{manifest} cannot be found.

@section @code{git_sources(recurse=True,ignore_missing_submodules=False,**kwds)} :

This function sets @code{lmake.manifest} by listing files managed by @code{git}.

If @code{recurse}, sub-modules are searched as well.

If @code{ignore_missing_submodules}, missing sub-modules are ignored rather than generating an error.

@code{kwds} is ignored.

It raises a @code{FileNotFoundError} exception if the repository is not controled by @code{git}.

@section @code{auto_sources(**kwds)} :

This function successively tries @code{manifest_sources} and @code{git_sources} by passing its @code{kwds} argument until one succeeds.

It raises a @code{FileNotFoundError} exception if none succeeds.


@chapter Rules

Rules are described as Python @code{class}'es inheriting from @code{lmake.Rule}, @code{lmake.AntiRule} or @code{SourceRule}.

Inheriting from @code{lmake.Rule} is used to define production rules that allows deriving targets from dependencies.

Inheriting from @code{lmake.AntiRule} is (rarely) used to define rules that specify that matching targets @strong{cannot} be built.
Anti-rules only require the @code{targets} attribute (or those that translate into it, @code{target}, @code{post_targets} and @code{post_target}) and may usefully have a @code{prio} attribute.
Other ones are useless and ignored.

Inheriting from @code{lmake.SourceRule} may be used to define sources by patterns rather than as a list of files controlled by some sort of source-control (typically @code{git}).

In addition to user rules defined as described hereinafter, there are a certain number of special rules that applies systematically :

@multitable @columnfractions 0.1 0.9
@item Sources
@tab Sources are built in a special way : the disk is checked and if the file has been modified, the rule is triggered, which mostly does nothing except noticing the modification,
which may trigger other jobs.
This is typically the root reason why @lmake run jobs instead of doing nothing at all.
@item Uphill
@tab Any file is deemed as depending on its directory in a special way : if its directory is buildable, then the file is deemed not buildable.
This is logical : if file @file{foo} is buildable (i.e. produced as a regular file or a symbolic link), there is not way file @file{foo/bar} can be built.
If @file{foo} is produced as a regular file, this is the end of the story.
If it is produced as a symbolic link (say with @file{foo_real} as target), the dependent job will be rerun and it will then depend on @file{foo} and @file{foo_real/bar} when it opens @file{foo/bar}.
Note that if the directory applies as the star-target of a rule, then the corresponding job must be run to determine if said directory is, indeed, produced.
@item Infinite
@tab if walking the dependencies leads to infinite recursion, when the depth reaches @code{lmake.config.max_dep_depth}, this special rule is triggered which generates an error.
Also, if a file whose name is longer that @code{lmake.config.path_max} considered, it is deemed to be generated by this rule and it is in error.
This happens typically if you have a rule that, for example builds @code{@{File@}} from @code{@{File@}.x}.
If you try to build @file{foo}, @lmake will try to build @file{foo.x}, which needs @file{foo.x.x}, which needs @file{foo.x.x.x} etc.
@end multitable

Rules are described by a series of attribute as follows.

@section Dynamic values

Most attributes can either be data of the described type or a function taking no argument returning the desired value.
This allows the value to be dynamically selected depending on the job.

Such functions are evaluated in an environment in which the stems (as well as the @code{stems} variable which is a @code{dict} containing the stems
and the targets (as well as the @code{targets} variable) are defined and usable to derive the return value.
Also, depending on the attribute, the deps (as well as the @code{deps} variable) and the resources (as well as the @code{resources} variable) may also be defined.
Whether or not these are available depend on when a given attribute is needed.
For example, when defining the @code{deps}, the deps are obviously not available.

Generally, these functions are not supposed to do local disk accesses (i.e. from within the repository) as at the time they are called, such accessed files may not be up to date.
However, when @code{deps} are in the function environment, the listed files are up to date and can be accessed.
In the current release, these restrictions are not enforced by @lmake, but they will be in a future release.

For composite values (dictionaries or sequences), the entire value may be function or each value can individually be a function (but not the keys).
For dictionaries, if the value function returns @code{None}, there will be no corresponding entry in the resulting dictionary.

Note that regarding resources available in the function environment, the values are the ones instantiated by the backend.

@section @code{combine}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{set}
@item Default
@tab The list of attributes hereinafter described as having combined inheritance
@item Dynamic
@tab No.
@item Example
@tab @code{@{'my_dict_attribute'@}}
@end multitable

This attribute specify a set of attribute names to be processed with combined inheritance (cf @pxref{rule-inheritance}).

Combined attributes may only be @code{dict}, @code{set} and @code{list}.
@code{dict}'s and @code{set}'s are @code{update}d, @code{list}'s are @code{append}ed.
@code{dict}'s and @code{list}'s are ordered in MRO, base classes being after derived classes.

Note that this attribute is itself combined, and thus can easily be extended.

@section @code{paths}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{ 'environ_cmd.PATH':':' , 'environ_cmd.PYTHONPATH':':' , 'environ_cmd.LD_LIBRARY_PATH':':' @}}
@item Dynamic
@tab No.
@item Example
@tab @code{@{'environ_resources.LM_LICENSE_FILE':':'@}}
@end multitable

This attribute specify a set of entries in @code{dict} combined attributes (i.e. listed in the @code{combine} attribute) that must be handled by joining values with a separator.
When such an entry appear in a rule, its value is searched for occurrences of the special marker @code{...} surrounded by separators (the start and end of the strings are deemed to be separators)
And each such occurrence is replaced by the inherited value.

This makes it particularly useful to manage paths as it allows any intermediate base @code{class} to add its own entries, before or after the original ones.

For example, to add the directory @file{/mypath} after the inherited path, one would define the attribute @code{environ_md} as @code{@{'PATH':'...:/mypath'@}}.
To add it before, one would use @code{@{'PATH':'/mypath:...'@}}.

It is a @code{dict} whose keys are of the form <attribute>.<key> and values are the separator to use.

@section @code{name}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab None
@item Type
@tab @code{str}
@item Default
@tab @code{cls.__name__}
@item Dynamic
@tab No.
@item Example
@tab @code{'compile and link'}
@end multitable

This attribute specify a name for the rule.
This name is used each time @lmake needs to mention the rule in a message.

All rules must have a unique name.
Usually, the default value is fine, but if your rule is defined in a for loop for example,
then you have several definitions with the same @code{__name__} and you must distinguish them from each other with this attribute (usually an f-string with the loop index in it).

@section @code{virtual}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab None
@item Type
@tab @code{bool}
@item Default
@tab @code{True} if @code{cls} lacks the essential attributes to make it a rule (@code{targets} and, if not anti, @code{deps} and @code{cmd}).
@item Dynamic
@tab No.
@item Example
@tab @code{True}
@end multitable

When this attribute exists and has a @code{True} value, this @code{class} is not a rule and is only used as a base @code{class} to define concrete rules.

@section @code{prio}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{float}
@item Default
@tab @code{0} if inheriting from @code{lmake.Rule}, @code{float('+inf')} if deriving from @code{lmake.AntiRule}.
@item Dynamic
@tab No.
@item Example
@tab @code{1}
@end multitable

This attribute is used to order matching priority.
Rules with higher priorities are tried first and if none of them are applicable, rules with lower priorities are then tried (cf @pxref{rule-selection}).
However, @code{AntiRule}'s and @code{SourceRule}'s are always tried before plain rules.

@section @code{stems}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab No.
@item Example
@tab @code{@{'File':r'.*'@}}
@end multitable

Stems are regular expressions that represent the variable parts of targets which rules match.

Each entry <key>:<value> define a stem named <key> whose associated regular expression is <value>.

@section @code{job_name}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Dynamic
@tab No.
@item Default
@tab The first matching target of the most derived @code{class} in the inheritance hierarchy (i.e. the MRO) having a matching target.
@end multitable

This attribute may exceptionally be used for cosmetic purpose.
Its syntax is the same as target name (i.e. a target with no option).

When @lmake needs to include a job in a report, it will use this attribute.
If it contains star stems, they will be replaced by @code{*}'s in the report.

If defined, this attribute must have the same set of static stems (i.e. stems that do not contain *) as any matching target.

@section @code{targets}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab No.
@item Example
@tab @code{@{ 'OBJ' : '@{File@}.o' @}}
@end multitable

This attribute is used to define the regular expression which targets must match to select this rule (cf @pxref{rule-selection}).

Keys must be Python identifiers.
Values are @code{list}'s or @code{tuple}'s whose first item defines the target regular expression and following items define flags.
They may also be a simple @code{str} in which case it is as if there were no associated flags.

The regular expression looks like Python f-strings.
The fixed parts (outside @{@}) must match exactly.
The variable parts, called stems, are composed of :
@itemize @bullet
@item An optional name.
If it exists, it is used to ensure coherence with other targets and the @code{job_name} attribute, else coherence is ensured by position.
This name is used to find its definition in the stems @code{dict} and may also be used in the @code{cmd} attribute to refer to the actual content of the corresponding part in the target.
@item An optional *.
If it exists, this target is a star target, meaning that a single job will generate all or some of the targets matching this regular expression.
if not named, such stem must be defined.
@item An optional @code{:} followed by a definition (a regular expression).
This is an alternative to refering to an entry in the @code{stems} @code{dict}.
Overall, all stems must be defined somewhere (in the @code{stems} @code{dict}, in a target or in @code{job_name}) and if defined several times, definitions must be identical.
Also, when defined in a target, a definition must contain balanced @code{@{@}}'s, i.e. there must be as many @code{@{} as @code{@}}.
If a regular expression requires unbalanced @code{@{@}}, it must be put in a @code{stems} entry.
@end itemize

Regular expressions are used with the @code{DOTALL} flag, i.e. a @code{.} matches any character, including @code{\n}.

The flags may be any combination of the following flags, optionally preceded by - to turn it off.

@multitable @columnfractions 0.1 0.1 0.05 0.75
@headitem CamelCase @tab snake_case  @tab Default @tab Description
@item Essential     @tab essential   @tab Yes     @tab This target will be shown in a future graphic tool to show the workflow, it has no algorithmic effect.
@item Incremental   @tab incremental @tab No      @tab Previous content may be used to produce these targets.
In that case, these are not unlinked before execution.
However, if the link count is more than 1, they are uniquified, i.e. they are copied in place to ensure modification to the link does not alter other links.
@item Optional      @tab optional    @tab No      @tab If this target is not generated, it is not deemed to be produced by the job.
@lmake will try to find an alternative rule.
This is equivalent to being a star target, except that there is no star stem.
@item Phony         @tab phony       @tab No      @tab Accept that this target is not generated, this target is deemed generated even not physically on disk.
If a star target, do not search for an alternative rule to produce the file.
@item SourceOk      @tab source_ok   @tab No      @tab Do not generate an error if target is actually a source
@item NoUniquify    @tab no_uniquify @tab No      @tab If such a target has several hard links pointing to it, it is not uniquified (i.e. copied in place) before job execution.
@item NoWarning     @tab no_warning  @tab No      @tab Warning is not reported if a target is either uniquified or unlinked before job execution while generated by another job.
@item Top           @tab top         @tab No      @tab target pattern is interpreted relative to the root directory of the repository, else it is relative to the @code{cwd} of the rule.
@end multitable

All matching targets must have the same set of static stems (i.e. stems with no * in its name).

Matching is done by first trying to match static targets (i.e. which are not star) then star targets.
The first match will provide the associated stem definitions and flags.

Unless the @code{top} flag is set, the @code{cwd} attribute is prepended to the target pattern in order to support hierarchical repository (cf @pxref{hierarchical-repositories}).


@section @code{target}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str} or @code{list} or @code{tuple}
@item Default
@tab -
@item Dynamic
@tab No.
@end multitable

This attribute defines an unnamed target.
Its syntax is the same as any target entry except that it may not be @code{incremental}. Also, such a target may not be a @code{star} target.

During execution, @code{cmd} stdout will be redirected to this (necessarily unique since it cannot be a @code{star}) target.

@section @code{side_targets}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab No.
@end multitable

This attribute is identical to @code{targets} except that :
@itemize @minus
@item the @code{ReadIsDep} or @code{read_is_dep} flag is available that transform files accessed read-only into deps rather than targets.
@item targets listed here do not trigger job execution, i.e. they do not participate to the rule selection process (cf @pxref{rule-selection}).
@item it not compulsery to use all static stems as this constraint is only necessary to fully define a job when selected by the rule selection process.
@end itemize

@section @code{deps}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab Yes. Environment includes stems and targets.
@item Example
@tab @code{@{ 'SRC' : '@{File@}.c' @}}
@end multitable

This attribute defines the static dependencies.
It is a @code{dict} which associates Python identifiers to files computed from the available environment.

They are f-strings, i.e. their value follow the Python f-string syntax and semantic
but they are interpreted when @lmake tries to match the rule (the rule only matches if static dependencies are buildable, cf @pxref{rule-selection}).
Hence they lack the initial @code{f} in front of the string.

Accessible variables when evaluating the f-string include the @code{stems}, the @code{targets}, attributes and the module dictionary.

Alternatively, values can also be @code{list} or @code{tuple} whose first item is as described above, followed by flags.

The flags may be any combination of the following flags, optionally preceded by - to turn it off when it is present by default.
Flags may be arbitrarily nested into sub-@code{list}'s or sub-@code{tuple}'s.

@multitable @columnfractions 0.1 0.1 0.05 0.75
@headitem CamelCase Flag @tab snake_case Flag @tab Default @tab Description
@item Essential          @tab essential       @tab Yes     @tab This dep will be shown in a future graphic tool to show the workflow, it has no algorithmic effect.
@item Critical           @tab critical        @tab No      @tab This dep is critial (cf @pxref{critical-deps}).
@item IgnoreError        @tab ignore_error    @tab No      @tab This dep may be in error, job will be launched anyway.
@item StatReadData       @tab stat_read_data  @tab No      @tab If this dep is accessed with a stat-like access, it is deemed to have accessed its content, which may increase the number of rebuilds.
@item Top                @tab top             @tab No      @tab dep pattern is interpreted relative to the root directory of the repository, else it is relative to the @code{cwd} of the rule.
@end multitable

Flag order and dependency order are not significative.

Unless the @code{top} flag is set, the @code{cwd} attribute is prepended to the dep pattern in order to support hierarchical repository (cf @pxref{hierarchical-repositories}).

@section @code{dep}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Default
@tab -
@item Dynamic
@tab Yes. Environment includes stems and targets.
@end multitable

This attribute defines an unnamed static dependency.

During execution, @code{cmd} stdin will be redirected to this dependency, else it is @file{/dev/null}.

@section @code{side_deps}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab No.
@end multitable

This attribute is used to define flags to deps when they are acquired during job execution.
It does not declare a dep by itself.
Syntactically, it follows the @code{side_targets} attribute except that :
@itemize @minus
@item specified flags are dep flags rather than target flags.
@item an additional flag @code{Ignore} or @code{ignore} is available to mean that files matching this pattern must not be deps if accessed as read.
@end itemize

@section @code{order}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{list}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab No.
@end multitable

By default @code{target}, @code{side_targets} and @code{side_deps} are handled in this order (cf @pxref{targets-deps}).
If this order is inadequate, this attribute may be used to specify the order.
The order may be partial : other keys are put after the mentioned keys, keeping their relative order.

@section @code{chroot_dir}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Default
@tab @code{None}
@item Dynamic
@tab Yes. Environment includes stems, targets and deps.
@end multitable

This attribute defines a directory in which jobs will @code{chroot} into before execution begins.
It must be an absoluted path (e.g. @code{'/ubuntu22.04'}).

Note that unless the @code{root_view} is set, the repository must be visible under its original name in this chroot environment.

If @code{None}, @code{''}, @code{'/'}, no @code{chroot} is performed unless required to manage the @code{tmp_view} and @code{root_view} attributes (in which case it is transparent).
However, if @code{'/'}, namespaces are used nonetheless (cf @pxref{namespaces}).

@section @code{root_view}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Default
@tab @code{None}
@item Dynamic
@tab Yes. Environment includes stems, targets and deps.
@end multitable

This attribute defines a directory in which jobs will see the top-level directory of the repo (the root directory).
This is done by using @code{mount -rbind} (cf @pxref {namespaces}).

It must be an absolute path not lying in the temporary directory (e.g. @code{'/repo'}).

If @code{None} or @code{''}, no bind mount is performed.

If performed, the @code{$ROOT_DIR} env variable will reflect this value.

@section @code{tmp_view}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Default
@tab @code{None}
@item Dynamic
@tab Yes. Environment includes stems, targets and deps.
@end multitable

This attribute defines the name which the temporary directory available for job execution is mounted on (cf @pxref {namespaces}).

If @code{None}, @code{''} or not specified, this directory is not mounted and job must use the @code{$TMPDIR} environment variable to identify it.
Else, it must be an absolute path.
in this case, the @code{$TMPDIR} environment variable is redefined as this value when job is executed.

The physical directory is :
@itemize
@item @code{$TMPDIR} if it is specified in the environment of the job. Note that it need not be unique as @lmake will create a unique sub-directory within it.
@item Else, a @code{tmpfs} file system created for the job execution if the @code{'tmp'} resource is defined, in which case this resource indicates the size of the created @code{tmpfs}.
if the value of this resource is 0, no @code{tmpfs} file system is created.
@item Else, a directory determined by @lmake lying in the @code{LMAKE} directory.
@end itemize

@section @code{views}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab Yes. Environment includes stems, targets and deps.
@end multitable

This attribute defines a mapping from logical views to physical directories.
Accesses to logical views are mapped to their corresponding physical location. Views and physical locations may be dirs or files depending on whether they end with a @code{/} or not.
Files must be mapped to files and directories to directories.
Both logical views and physical locations may be inside or outside the repository, but it is not possible to map an external view to a local location.
The mapping is done through bind mounts (cf @pxref {namespaces}).

@section @code{cwd}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Default
@tab @code{''}
@item Dynamic
@tab No.
@end multitable

This attribute defines a directory in which jobs will @code{chdir} into before execution begins.
It must be empty to specify the repository root.
Else, it must be a relative path (to the repository root).

This attribute is also prepended to targets and deps unless they have the @code{top} flag.

@section @code{environ_cmd}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab See description
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@item Example
@tab @code{@{ 'MY_TOOL_ROOT' : '/install/my_tool' @}}
@end multitable

This attribute defines environment variables set during job execution.

The content of this attribute is managed as part of the job command, meaning that jobs are rerun upon modification.

The environment in which the @lmake command is run is ignored so as to favor reproducibility, unless explicitely transported by using value from @code{os.environ}.

If resulting value is @code{...} (the Python ellipsis), the value from the execution environment is used.
This is typically used to access some environment variables set by @code{slurm}.

By default the following environment variables are defined :
@table @code
@item HOME in Rule
The root directory of the repository, so as to prevent tools from accessing startup files that may vary from user to user.
Necessary startup files can be put inside the repository, administered with your prefered versioning tool as any other source.
In @code{HomelessRule}, it is defined as the temporary directory.
@item PATH in Rule
The standard path with @lmake bin directory in front.
The standard path is the one you get with the standard shell in absence of any startup file.
@item PYTHONPATH in PyRule
The @lmake lib directory.
@end table

Note that the current environment is accessible when @Lmakefile is read, so that it is quite simple to copy some variables from the user environment
although this practice is discouraged and should be used with much care.

@section @code{environ_resources}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@item Example
@tab @code{@{ 'MY_TOOL_LICENCE' : '12345' @}}
@end multitable

This attribute defines environment variables set during job execution.

The content of this attribute is managed as resources, meaning that jobs in error are rerun upon modification, but not jobs that were successfully built.

The environment in which the @lmake command is run is ignored so as to favor reproducibility.

Note that the current environment is accessible when @Lmakefile is read, so that it is quite simple to copy some variables from the user environment
although this practice is discouraged and should be used with much care.

If resulting value is @code{...} (the Python ellipsis), the value from the execution environment is used.
This is typically used to access some environment variables set by @code{slurm}.

@section @code{environ_ancillary}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab See description
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@item Example
@tab @code{@{ 'DISPLAY' : ':10' @}}
@end multitable

This attribute defines environment variables set during job execution.

The content of this attribute is not managed, meaning that jobs are not rerun upon modification.

The environment in which the @lmake command is run is ignored so as to favor reproducibility.

By default the following environment variables are defined :
@table @code
@item UID
The user id.
@item USER
The user login name.
@end table

Note that the current environment is accessible when @Lmakefile is read, so that it is quite simple to copy some variables from the user environment
although this practice is discouraged and should be used with much care.

If resulting value is @code{...} (the Python ellipsis), the value from the execution environment is used.
This is typically used to access some environment variables set by @code{slurm}.

@section @code{python}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{list} or @code{tuple}
@item Default
@tab system Python
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute defines the interpreter used to run the @code{cmd} if it is a @code{function}.
At the end of the supplied executable and arguments, @code{'-c'} and the actual script is appended, unless the @code{use_script} attribut is set.
In the later case, a file that contains the script is created and its name is passed as the last argument without a preceding @code{-c}.

@lmake uses Python 3.6+ to read @file{Lmakefile.py}, but that being done, any interpreter can be used to execute @code{cmd}.
In particular, Python2.7 and all revisions of Python3 are fully supported.

@section @code{shell}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{list} or @code{tuple}
@item Default
@tab @code{/bin/bash}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute defines the interpreter used to run the @code{cmd} if it is a @code{str}.
At the end of the supplied executable and arguments, @code{'-c'} and the actual script is appended.

@section @code{cmd}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{function} or @code{str}
@item Default
@tab -
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources. See description, though, if it is defined as a function.
@item Example1
@tab @code{'gcc -c -o @{OBJ@} @{SRC@}'}
@item Example2
@tab @code{def cmd() : subprocess.run(('gcc','-c','-o',OBJ,SRC,check=True))}
@end multitable

Whether @code{cmd} is a @code{str} or a @code{function}, the following environment variable are automatically set, if not explicitly set by the @code{environ} attribute :
@itemize @minus
@item @code{LD_AUDIT}          : A variable necessary for autodep if the @code{autodep} attribute is set to @code{'ld_audit'} (cf @pxref{autodep}).
@item @code{LD_PRELOAD}        : A variable necessary for autodep if the @code{autodep} attribute is set to @code{'ld_preload'} or @code{'ld_preload_jemalloc'} (cf @pxref{autodep}).
@item @code{LMAKE_AUTODEP_ENV} : A variable necessary for the autodep mechanism of @lmake, it must stay present and untouched (cf @pxref{autodep}).
@item @code{PWD}               : The initial directory in which @code{cmd} is run, as provided by the @code{cwd} attribute (often the root of the repository).
@item @code{ROOT_DIR}          : The root of the repository.
@item @code{SEQUENCE_ID}       : A value which is unique for each run.
It is  @code{1} initially and is incremented each time a job is run.
@item @code{SMALL_ID}          : A value which is unique among running job at any given time.
It is always at least @code{1} and efforts are made to maintain it as small as possible.
@item @code{TMPDIR}            : The name of a directory which is empty at the start of the job.
If the temporary directory is not kept through the use of the @code{keep_tmp} attribute or the @code{-t} option, this directory is cleaned up at the end of the job execution.
@end itemize

@subsection if it is a @code{function}

In that case, this attribute is called to run the job.
Combined inheritance is a special case for @code{cmd}.

If several definitions exist along the MRO, They must all be @code{function}'s and they are called successively in reverse MRO.
The first (i.e. the most basic) one must have no non-defaulted arguments and will be called with no argument.
The other ones may have arguments, all but the first having default values.
In that case, such @code{function}'s are called with the result of the previous one as unique argument.
Else, if a @code{function} has no argument, the result of the previous function is dropped.

During evaluation, when the job runs, its global @code{dict} is populated to contain values referenced in these @code{function}'s.
Values may come from (by order of preference) :
@itemize @minus
@item The @code{stems}, @code{targets}, @code{deps}, @code{resources} as named in their respective @code{dict}.
@item @code{stems}, @code{targets}, @code{deps}, @code{resources} that contain their respective whole @code{dict}, @code{job_tokens} that contain its value.
@item Any attribute defined in the class, or a base class (as for normal Python attribute access).
@item Any value in the module @code{dict}.
@item Any builtin value
@item undefined variables are not defined, which is ok as long as they are not accessed.
@end itemize

Because jobs are executed remotely using the interpreter mentioned in the @code{python} attribute
and to avoid depending on the whole @Lmakefile (which would force to rerun all jobs as soon as any rule is modified),
these @code{function}'s and their context are serialized to be transported.
The serialization process may improve over time but as of today, the following applies :
@itemize @minus
@item Basic objects are transported as is : @code{None}, @code{...}, @code{bool}, @code{int}, @code{float}, @code{complex}, @code{str}, @code{bytes}.
@item @code{list}, @code{tuple}, @code{set} and @code{dict} are transported by transporting their content. Note that reconvergences (and a fortiori loops) are not handled.
@item @code{function}'s are transported as their source accompanied with their context : global accessed variables and default values for arguments.
@item Imported objects (@code{function}'s and @code{class}'es and generally all objects with a @code{__qualname__} attribute) are transported as an @code{import} statement.
@item Builtin objects are transported spontaneously, without requiring any generated code.
@end itemize

Values are captured according to the normal Python semantic, i.e. once the @code{Lmakefile} module is fully imported.
Care must be taken for variables whose values change during the @code{import} process.
This typically concerns loop indices.
To capture these at definition time and not at the end, such values must be saved somewhere.
There are mostly 2 practical possibilities :
@itemize @minus
@item Declare an argument with a default value. Such default value is saved when the function is defined.
@item Define a class attribute. Class attributes are saved when its definition ends, which is before a loop index.
@end itemize

The job is deemed to be successful if the last function returns a false value.

@subsection if it is a @code{str}

In that case, this attribute is executed as a shell command to run the job.
Combined inheritance is a special case for @code{cmd}.
While walking the MRO, if for a base class @code{cmd} is defined as a @code{function} and it has a @code{shell} attribute, the value of this attribute is used instead.
The purpose is that it is impossible to combine @code{str}'s and @code{function}'s because they use different paradigms.
As a consequence, a base class may want to have 2 implementations, one for subclasses that use Python @code{cmd} and another for subclasses that use shell @code{cmd}.
For such a base class, the solution is to define @code{cmd} as a @code{function} and set its @code{shell} attribute to the @code{str} version.

If several definitions exist along the MRO, They must all be @code{str}'s and they are run successively in reverse MRO in the same process.
So, it is possible for a first definition to define an environment variable that is used in a subsequent one.

As for other attributes that may be dynamic, @code{cmd} is interpreted as an f-string.

The job is deemed to be successful if the return code of the overall process is @code{0}.

@section @code{cache}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Constraint
@tab One of the caches listed in config.
@item Default
@tab <not cached>
@item Dynamic
@tab Yes. Environment includes stems, targets.
@end multitable

This attribute specifies the cache to use for jobs executed by this rule.
When a job is executed, its results are stored in the cache.
If space is needed (all caches are constrained in size), any other entry can be replaced.
The cache policy (described in its own section, in the config chapter) tries to identify entries that are likely to be useless in the future.

@section @code{backend}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Constraint
@tab One of the supported backends.
@item Default
@tab @code{'local'}
@item Dynamic
@tab Yes. Environment includes stems, targets and deps.
@end multitable

This attribute specifies the backend to use to launch jobs (cf @pxref{backends}).

@section @code{autodep}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Constraint
@tab One of @code{'none'}, @code{'ld_preload'}, @code{'ld_preload_jemalloc'}, @code{'ld_audit'} or @code{'ptrace'}
@item Default
@tab @code{'ld_audit'} if supported else @code{'ld_preload'}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute specifies the method used by autodep (cf @pxref{autodep}) to discover hidden dependencies.

@section @code{resources}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab Yes. Environment includes stems, targets and deps.
@item Example
@tab @code{@{ 'MY_RESOURCE' : '1' @}}
@end multitable

This attribute specifies the resources required by a job to run successfully.
These may be cpu availability, memory, commercial tool licenses, access to dedicated hardware, ...

The syntax is the same as for @code{deps}, except that in addition to other variables, deps can be referenced.

After interpretation, the @code{dict} is passed to the @code{backend} to be used in its scheduling (cf @pxref{local-backend} for the local backend).

@section @code{max_stderr_len}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{int}
@item Default
@tab @code{100}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps.
@end multitable

This attribute defines the maximum number of lines of stderr that will be displayed in the output of @lmake.
The whole content of stderr stays accessible with the @code{lshow -e} command.

@section @code{allow_stderr}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute has a false value, the simple fact that a job generates a non-empty stderr is an error.
If it is @code{True}, writing to stderr is allowed and does not produce an error. The @lmake output will exhibit a warning, though.

@section @code{auto_mkdir}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute has a @code{True} value, executing a @code{chdir} syscall (e.g. executing @code{cd} in bash) will create the target directory if it does not exist.

This is useful for scripts in situations such as :
@itemize @minus
@item The script does @code{chdir a}.
@item Then try to read file @file{b} from there.
@item What is expected is to have a dependency on @file{a/b} which may not exist initially but will be created by some other job.
@item However, if directory @file{a} does not exist, the @code{chdir} call fails and the file which is open for reading is @file{b} instead of @file{a/b}.
@item As a consequence, no dependency is set for @file{a/b} and the problem will not be resolved by a further re-execution.
@item Setting this attribute to @code{True} creates directory @file{a} on the fly when @code{chdir} is called so that it succeeds and the correct dependency is set.
@end itemize

@section @code{keep_tmp}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute is set to a true value, the temporary directory is kept after job execution.
It can be retreived with @code{lshow -i}.
Sucessive executions of the same job overwrite the temporary directory, though, so only the content corresponding to the last execution is available.
When this attribute has a @code{False} value, the temporary directory is washed at the end of the job execution.

@section @code{force}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab No.
@end multitable

When this attribute is set to a @code{True} value, jobs are always considered out-of-date and are systematically rerun if a target is needed.
It is rarely necessary.

@section @code{max_submit_count}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{int}
@item Default
@tab @code{10}
@item Dynamic
@tab No.
@end multitable

This attribute specifies the maximum number of times a job can be submitted for a single @lmake command.
The goal is to protect agains potential infinite loop cases.
The default value should be both comfortable (avoid hitting it in normal situations) and practical (avoid too many submission before stopping).

@section @code{timeout}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{float}
@item Constraint
@tab >=0
@item Default
@tab no timeout
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute has a non-zero value, job is killed and a failure is reported if it is not done before that many seconds.

@section @code{job_tokens}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str} or @code{int}
@item Constraint
@tab >=1 and <256
@item Default
@tab @code{1}
@item Dynamic
@tab Yes. Environment includes stems and targets.
@end multitable

This attribute has the same syntax as a resource, except that a @code{float} is accepted.
If it is a @code{str}, it must be convertible to a float after interpretation.

It is only used to estimate the ETA (cf @pxref{eta-estimation}).

@section @code{n_tokens}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{int}
@item Constraint
@tab >=1
@item Default
@tab @code{1}
@item Dynamic
@tab No.
@end multitable

This attribute indicates to @lmake a quantity of abstract resources used to estimate the expected parallelism of jobs within this rule.

It is only used to estimate the ETA (cf @pxref{eta-estimation}).

Note that although this field is static, it may be modified while @lmake is running and new value will be taken into account as soon as a new @lmake command is launched.
It is thus possible to refer to backend resources.

@section @code{start_delay}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{float}
@item Default
@tab @code{3}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute is set to a non-zero value, start lines are only output for jobs that last longer than that many seconds.
The consequence is only cosmetic, it has no other impact.

@section @code{kill_sigs}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{list} or @code{tuple}
@item Default
@tab @code{(signal.SIGKILL,)}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute provides a list of signals to send the job when @lmake decides to kill it.
A job is killed when :
@itemize @minus
@item @kbd{^C} is hit if it is not necessary for another running @lmake command that has not received a @kbd{^C}.
@item When timeout is reached.
@item When @code{check_deps} is called and some dependencies are not up to date.
@end itemize

The signals listed in this list are sent in turn, once every second.
Longer interval can be obtained by inserting @code{0}'s. @code{0} signals are not sent and anyway, these would have no impact if they were.

If the list is exhausted and the job is still alive, a more agressive method is used.
The process group of the job, as well as the process group of any process connected to a stream we are waiting for, are sent @code{SIGKILL} signals instead of just the process group of the job.
The streams we are waiting for are @code{stderr}, and @code{stdout} unless the @code{target} attribute is used (as opposed to the @code{targets} attribute)
in which case @code{stdout} is redirected to the the target and is not waited for.

Note: some backends, such as Slurm, may have other means to manage timeouts. Both mechanisms will be usable.

@section @code{n_retries}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{int}
@item Default
@tab @code{0}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute provides the number of allowed retries before giving up when a job is lost.
For example, a job may be lost because of a remote host being misconfigured, or because the job management process (called @code{job_exec}) was manually killed.

In that case, the job is retried, but a maximum number of retry attemps are allowed, after which the job is considered in error.

@section @code{use_script}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute commands an implementation detail.
If false, jobs are run by launching the interpreter followed by @code{-c} and the command text.
If true, jobs are run by creating a temporary file containing the command text, then by launching the interpreter followed by said file name.
If the size of the command text is too large to fit in the command line, this attribute is silently forced true.

@chapter The @file{LMAKE} directory

This directory contains numerous information that may be handy for the user.

It also contains a @file{lmake} directory containing data for @lmake's own private usage.

@section @file{LMAKE/config}

This file contains a description of the @code{lmake.config} @code{dict} as it has been understood by @lmake after having processed @Lmakefile.

@section @file{LMAKE/rules}

This file contains a description of the rules as it has been understood by @lmake after having processed @Lmakefile.

@section @file{LMAKE/manifest}

This file contains a description of the sources as it has been understood by @lmake after having processed @Lmakefile.

@section @file{LMAKE/config_deps}

This file contains a list of files that @lmake has read to process @Lmakefile.
Each line contains a file, preceded by a @code{+} if file exists or a @code{!} if it does not.

@section @file{LMAKE/rules_deps}

If @code{lmake.rules_module} has been set, this file contains a list of files that @lmake has read to process it.
Each line contains a file, preceded by a @code{+} if file exists or a @code{!} if it does not.

@section @file{LMAKE/sources_deps}

If @code{lmake.sources_module} has been set or if using the default behavior to list sources, this file contains a list of files that @lmake has read to process it.
Each line contains a file, preceded by a @code{+} if file exists or a @code{!} if it does not.

@section @file{LMAKE/outputs/<date>}

This file contains a transcript of the @lmake command that has been run at @file{<date>}.

@section @file{LMAKE/last_output}

This file is a symbolic link to the last transcript.

@section @file{LMAKE/targets}

This file contains the targets that have been required by @lmake commands in chronological order (with duplicates removed).

@section @file{LMAKE/quarantine}

This directory contains all files that have been quarantined.
A file is quantantined when @lmake decides it must be unlinked and it contains manual modifications, i.e. modifications made outside the control of @lmake.
In that case, in order to be sure that no user work is lost, the file is quarantined in this directory rather than unlinked.

@chapter Some considerations

This chapter contains some considerations that appear in several places of this documentation.
It is meant to be the target of cross-references.

@anchor{rule-inheritance}
@section Rule inheritance

Rules are Python @code{class}'es that inherit from @code{lmake.Rule} (or @code{lmake.AntiRule} or @code{lmake.SourceRule}).

However, Python's native inheritance mechanism is not ideal to describe a rule as one would like to prepare a base @code{class} such as :
@itemize @minus
@item provide environment variables
@item provide some default actions for some files with given pattern
@item provide some automatic dependencies
@item ...
@end itemize

As these are described with @code{dict}, you would like to inherit @code{dict} entries from the base @code{class} and not only the @code{dict} as a whole.
A possibility would have been to use the @code{__prepare__} method of a meta-class to pre-define inherited values of such attributes,
but that would defeat the practical possibility to use multiple inheritance by suppressing the diamond rule.

The chosen method has been designed to walk through the MRO at class creation time and :
@itemize @minus
@item Define a set of attributes to be handled through combination. This set is defined by the attribute @code{combine}, itself being handled by combination.
@item Combined attribute are handled by updating/appending rather than replacing when walking through MRO in reverse order.
@item Entries with a value None are suppressed as update never suppress a given entry.
Similarly, values inserted in a set prefixed with a @code{'-'} remove the corresponding value from the @code{set}.
@end itemize

Because this mechanism walks through the MRO, the diamond rule is enforced.

@code{dict}'s and @code{list}'s are ordered so that the most specific information appear first, as if classes are searched in MRO.

@anchor{regexpr}
@section Regular expressions
Internally, @lmake uses a regular expression library, that may change with versions, but which are always very close to the Python @code{re} module.

As of today, the standard @code{std::regex} package is used with the @code{ECMASript} grammar.
The following differences with Python @code{re} are known :
@itemize @bullet
@item named groups are not supported.
There are hardly any reason to use named groups in stems.
This would allow back references as number based back references cannot be used as one cannot know what number to use.
However, the same stem can be used several time and all but the first one will be back references to the first one.

For example if you want to match files such as @file{image/image_small.jpg} and @file{image/image_big.jpg}, you can use @code{'@{Image:\w+@}/@{Image@}_@{Size:\w+@}.jpg'}.
A file such as @file{image1/image2_big.jpg} will not match.
@item braces (@code{@{@}}) are sometimes recognized as literal braces by Python, even when not escaped with @code{\}.
This is not the case with @code{std::regex}, they always must be escaped.
@end itemize

@anchor{targets-deps}
@section Handling an access
At first glance, recognizing a target from a dep when a job runs seems pretty easy when the accesses to the disk can be traced : reading a file is a dep, writing to it is a target.
And this is what is done informally, but there are a lot of corner cases.

The specification devised hereinafter has been carefully thought to allow @lmake to run adequate jobs to reach a stable state from any starting point.
More specifically, think of the following sequence :
@itemize @minus
@item @code{git clean -ffdx}
@item @code{lmake foo}
@item @code{git pull}
@item @code{lmake foo}
@end itemize

The second @code{lmake foo} command is supposed to do the minimum work to reach the same content of @file{foo} as would be obtained with the sequence :
@itemize @minus
@item @code{git pull}
@item @code{git clean -ffdx}
@item @code{lmake foo}
@end itemize

This what stable state means : the content of @file{foo} is independent of the history and only depends on the rules and the content of sources, both being managed through @code{git} in this example.

In this specification, directories are ignored (i.e. the presence or content of a directory has no impact) and symbolic links are similar to regular files whose content is the link itself.

@subsection Reading and writing files
The first point is to precisely know what reading and writing mean.

Writing to file @file{foo} means :
@itemize
@item A system call that writes or initiate writing to @file{foo}, e.g. @code{open("foo",O_WRONLY|O_TRUNC)} or @code{symlink(...,"foo")},
assuming the @code{autodep} rule attribute is not set to @code{'none'}.
@item Unlinking @file{foo}, e.g. @code{unlink("foo")}, is also deemed to be writing to it.
@item A call to @code{lmake.target('foo',write=True)}. Note that @code{True} is the default value for the @code{write} argument.
@item The execution of @code{ltarget foo} in which the @code{-W} option is not passed.
@item Under the condition that these actions are not preceded by a call to @code{lmake.target('foo',ignore=True)} or the execution of @code{ltarget -I foo}.
@item Also under the condition that @file{foo} does not match a @code{targets} or @code{side_targets} entry with the @code{Ignore} flag set.
@item Also under the condition that @file{foo} lies in the repository (i.e. under the directory containing @file{Lmakefile.py} but not in its @file{LMAKE} sub-directory).
@end itemize

Reading file @file{foo} means :
@itemize
@item A system call that reads or initiate reading @file{foo}, e.g. @code{open("foo",O_RDONLY)}, @code{readlink("foo",...)} or @code{stat("foo",...)},
assuming the @code{autodep} rule attribute is not set to @code{'none'}.
@item Unless the @code{config.link_support} attribute is set to @code{'none'},
any access (reading or writing) to @file{foo} which follows symlinks is an implicit @code{readlink}.
@item Unless the @code{config.link_support} attribute is set to @code{'file'} or @code{'none'},
any access (reading or writing) to @file{foo}, whether it follows symlinks or not, is an implicit @code{readlink} of all directories leading to it.
@item Note that some system calls can be both a read and a write, e.g. @code{open("foo", O_RDWR)} but also @code{rename("foo",...)}.
In that case, the read occurs before the write.
@item A call to @code{lmake.depend('foo',read=True)}. Note that @code{True} is the default value for the @code{read} argument.
@item The execution of @code{ldepend foo} in which the @code{-R} option is not passed.
@item Under the condition that these actions are not preceded by a call to @code{lmake.depend('foo',ignore=True)} or the execution of @code{ldepend -I foo}.
@item Also under the condition that @file{foo} is not listed in @code{deps} or matches a @code{side_deps} entry, with the @code{Ignore} flag set.
@item Also under the condition that @file{foo} lies in the repository (i.e. under the directory containing @file{Lmakefile.py} but not in its @file{LMAKE} sub-directory) or in a source directory.
@end itemize

@subsection Being a target
A file may be a target from the begining of the job execution, or it may become a target during job execution.
In the latter case, it is not a target until the point where it becomes one.
A file cannot stop being a target : once it has become a target, this is until the end of the job execution.

A file is a target from the begining of the job execution if it matches a @code{targets} or @code{side_targets} entry.

A file becomes a target when it is written to (with the meaning mentioned above).

@subsection Being a dep
A file may be a dep from the begining of the job execution, or it may become a dep during job execution.

A file cannot stop being a dep : once it has become a dep, this is until the end of the job execution.

A file is a dep from the begining of the job execution if it listed as a @code{deps} in the rule.

A file becomes a dep when it is read (with the meaning mentioned above) while not a target at that time.

@subsection Errors
Some cases lead to errors, independently of the user script.

The first case is when there is clash between static declarations.
@code{targets}, @code{side_targets}, @code{side_deps} entries may or may not contain star stems.
In the latter case, and including the static deps listed in @code{deps}, they are static entries.
It is an error if the same file is listed several times as a static entry.

The second case is when a file is both a dep and a target.
You may have noticed that the definition above does not preclude this case, mostly because a file may start its life as a dep and become a target.
This is an error unless the file is finally unlinked (or was never created).

The third case is when a target was not declared as such.
@file{foo} can be declared as target by :
@itemize
@item matching a @code{targets} or @code{side_targets} entry.
@item calling @code{lmake.target('foo',allow=True} (which is the default value for the @code{allow}).
@item executing @code{ltarget foo} in which the @code{-a} option is not passed.
@end itemize
A target that is not declared is an error.

@subsection Processing a target
Targets are normally erased before the start of the job execution, unless they are flagged as @code{incremental}.
In case a target is also a dep, it is automatically flagged as @code{incremental}, whether it is an error or not.

@subsection Best effort

@lmake tries to minimize the execution of jobs, but may sometimes miss a point and execute a job superfluously.
This may include erasing a file that has no associated production rule.
Unless a file is a dep of no job, @lmake may rebuild it at any time, even when not strictly necessary.

In the case @lmake determines that a file may have actually been written manually outside its control, it fears to overwrite a user-generated content.
In that case, @lmake quarantines the file under the @file{LMAKE/quarantine} directory with its original name.
This quarantine mechanism, which is not necessary for @lmake processing but is a facility for the user, is best effort.
There are cases where @lmake cannot anticipate such an overwrite.

@anchor{namespaces}
@section Namespaces

Namespaces are used to isolate jobs.
This is used to provide the semantic for the @code{chroot_dir}, @code{root_view}, @code{tmp_view} and @code{views} attributes.

In that case, pid's are also isolated which allow reliable job end : when the top-level process exits, the namespaces are destroyed and no other process can survive.
This guarantees that no daemon is left behind, uncontrolled.

Note that this is true even when @code{chroot_dir} is @code{'/'}, which otherwise provides no other effect by itself.

Namespaces can be used in the following situations :
@itemize @bullet
@item @lmake provides a cache mechanism allowing to prevent executing a job which was already executed in the same or another repository.
However, some jobs may use and record absolute paths.
In that case, the cache will be inefficient as the result in a repository is not identical to the one in another repository.
This is current practice, in particular in the EDA tools community (which may be rather heavy and where caching is mostly desirable).
Using the @code{root_view} attribute is a good way to work around this obstacle.
@item @lmake tracks all dependencies inside the reposity and listed source directories. But it does not track external dependencies, typically the system (e.g.the @file{/usr} directory).
However, the @code{chroot_dir} attribute is part of the command definition and a job will be considered out of date if its value is modified.
Hence, this can be used as a marker representing the whole system to ensure jobs are rerun upon system updates.
@item some softwares (e.g. EDA tools) are designed to operate on a directory rather than dealing with input files/directories and output files/directories.
This goes against reentrancy and thus reliability, repeatability, parallelism etc.
This problem can be solved with symbolic links if they are allowed.
In all cases, it can be solved by using the @code{tmp_view} and copying data back and forth between the repository and the tmp directory.
Or, more efficient, it can be solved by adequately mapping a logical steady file or directory to a per job physical file or directory (respectively).
@end itemize

@anchor{backends}
@section Backends

Backends are in charge of actually launching jobs when the @lmake engine has identified that it had to be run.
It is also in charge of :
@itemize @minus
@item Killing jobs when the @lmake engine has identified it had to be so.
@item Scheduling jobs so as to optimize the runtime, based on some indications provided by the @lmake engine.
@item Rescheduling jobs when new scheduling indications becomes available.
@end itemize

A backend has to take decisions of 2 kinds :
@itemize @minus
@item Is a job eligible for running ?
From a dependency perspective, the @lmake engine guarantees it is so.
But the job needs some resources to run and these resources may already be busy because of some other jobs already running.
@item If several jobs are eligible, which one(s) to actually launch.
@end itemize

Each backend is autonomous in its decisions and has its own algorithm to take them.
However, generally speaking, they more or less work by following the following principles :
@itemize @minus
@item For the first question, the backend maintain a pool of available resources and a job is eligible if its required resources can fit in the pool.
When launched, the required resources are subtracted from the pool and when terminated, they are returned to it.
@item For the second question, each job has an associated pressure provided by the @lmake engine and the backend actually launches the eligible job with the highest pressure.
@end itemize

The required resources are provided by the @lmake engine to the backend as a @code{dict} which is the one of the job's rule after f-string interpretation.

The pressure is provided in the form of @code{float} computed as the accumulated ETE along the critical path to the final targets asked on the @lmake command line.
To do that, future job ETE have to be estimated.
For jobs that have already run, last successful execution time is used.
When this information is not available, i.e. when the job has never run successfully, a moving average of the execution times of the jobs sharing the same rule is used as a best guess.

The @lmake backend also provides the current ETA (cf @pxref{eta-estimation}) of the final targets to allow the backends from different repository to take the best collective decision.

In addition to dedicated resources, all backends manage the following 3 resources :
@itemize @minus
@item @code{cpu} : The number of threads the job is expected to run in parallel. The backend is expected to reserve enough resources for such a number of threads to run smoothly.
@item @code{mem} : The memory size the job is expected to need to run smoothly.
The backend is expected to ensure that such memory is available for the job.
Unit must be coherent with the one used in the configuration. It is MB by default.
@item @code{tmp} : The size of necessary temporary disk space.
@end itemize

@anchor{local-backend}
@section Local backend

The local backend launches jobs locally, on the host running the @lmake command.
Also, there is no cooperation between backends from different repositories and the user has to ensure there is no global resource conflict.

This backend is configured by providing entries in the @code{lmake.config.backends.local} @code{dict}.
The key identifies the resource and the value is a @code{int} that identifies a quantity.

Then, each rule whose @code{backend} attribute is @code{'local'} provides a @code{resources} attribute such that :
@itemize @minus
@item The key identifies a resource (which must match a resource in the configuration).
@item The value (possibly tailored by job through the use of the f-string syntax) is either
@itemize @minus
@item a @code{int} or a @code{str} that can be interpreted as  @code{int}
@item or a @code{str} of the form @code{'a<b'} where @code{a} and @code{b} can be interpreted as @code{int}
@end itemize
This later form instruct the local backend that as much as @code{b} resources is preferable, but @code{a} is enough to run the job.
@end itemize
The variable available to the job as global variables (python case) or environment variables (shell case) contains the actual quantity of resources allocated to this job.

The local backend ensures that the sum of all the resources of the running jobs never overshoot the configured available quantity.

By default, the configuration contains the 2 generic resources : @code{cpu} and @code{mem} configured respectively as the overall number of available cpus and the overall available memory (in MB).
@itemize @minus
@item @code{cpu} : The number of cpu as returned by @code{os.wched_getaffinity(0)}.
@item @code{mem} : The physical memory size as returned by @code{s.sysconf('SC_PHYS_PAGES')*os.sysconf('SC_PAGE_SIZE')} in MB.
@end itemize
Each rule has a default @code{resources} attribute requiring one CPU.

@anchor{slurm-backend}
@section Slurm backend

The slurm backend connects to a slurm daemon to schedule jobs, which allows :
@itemize @minus
@item a global schuduling policy (while the local backend only sees jobs in its own repository).
@item the capability to run jobs on remote hosts (while the local backend only run jobs on the local host).
@end itemize

The configuration is composed of :
@itemize @bullet
@item @code{n_max_queued_jobs} : @lmake scatters jobs according to the required resources and only submit a few jobs to slurm for each set of asked resources.
This is done to decrease the load of the slurm daemon as @lmake might have millions of jobs to run and the typical case is that they tend require only a small set of different resources
(helped in this by the limited precision on CPU, memory and temporary disk space requirements).
for each given set of resources, only the jobs with highest priorities are submitted to slurm, the other ones are retained by @lmake so as to limit the number of waiting jobs in slurm queues
(the number of running job is not limited, though).
This attribute specifies the number of waiting jobs for each set of resources that @lmake may submit to slurm.
If too low, the schedule rate may decrease because by the time taken, when a job finishes, for @lmake to submit a new job, slurm might have exhausted its waiting queue.
If too high, the schedule rate may decrase because of the slurm daemon being overloaded.
A reasonable value probably lies in the 20-100 range.
@item @code{repo_key} : This is a string which is add in front of @lmake job names to make slurm job names.
This key is meant to be a short identifier of the repository.
By default it is the base name of the repository followed by @code{:}.
@item @code{use_nice} : @lmake has and advantage over slurm in terms of knowledge : it knows the dependencies, the overall jobs necessary to reach the asked target and the history of the time
taken by each job.
This allows it to anticipate the needs and know, even globally when numerous @lmake commands run, in the same repository or on several ones, which jobs should be given which priority.
Note that @lmake cannot leverage the dependency capability of slurm as dependencies are dynamic by nature : new dependencies can appear during job execution, adding newedges to the dependency graph,
jobs can have to rerun, so a dependent job may not be able to start when its dependency is done, and a job can be steady, so a dependent job may not have to run at all.

The way it works is th following :
@itemize @minus
@item First @lmake computes and ETA for each @lmake command (cf @pxref{eta-estimation}. This ETA is a date, it is absolute, and can be compared between commands running in different repositories
@item Then it computes a pressure for each job. The pressure is the time necessary to reach the asked target of the @lmake command given the run time for all intermediate jobs
(including the considered job).
@item The subtraction of the pressure from the ETA gives a reasonable and global estimate of when it is desirable to schedule a job, and hence can be used as a priority.
@end itemize

The way to communicate this information is to set for each job a nice value that represents this priority.
Because this may interfere with other jobs submitted by other means, this mechanism is made optional,
although it is much better than other scheduling policies based on blind guesses of the futur (such as fair-share, qos, etc.).

@end itemize

There are 2 additional parameters that you can set in the @code{PriorityParams} entry of the slurm configuration in the form of param=value, separated by @code{,} :
@itemize @minus
@item @code{time_origin} : as the communicated priority is a date, we need a reference point.
This reference point should be in the past, not too far, to be sure that generated nice values are in the range @code{0} - @code{1<<31}.
@lmake make sometimes generates dates in the past when it wrongly estimates a very short ETA with a high pressure.
Taking a little bit of margin of a few days is more than necessary in all practical cases.
Default value is 2023-01-01 00:00:00.
Date is given in the format YYYY-MM-DD HH:MM optionally followed by +/-HH:MM to adjust for time zone.
This is mostly ISO8601 except the T between date and time replaced by a space, which is more readable and corresponds to mainstream usage.
@item @code{nice_factor} : this is the value that the nice value increases each second. It is a floating point value.
If too high, the the nice value may wrap too often. If too low, job scheduling precision may suffer.
The default value is @code{1} which seems to be a good compromise.
@end itemize
Overall, you can ignore these parameters for @lmake internal needs, the default values work fine.
They have been implemented to have means to control interactions with jobs submitted to slurm from outside @lmake.

The @code{resources} rule attributes is composed of :
@itemize @minus
@item standard resources @code{cpu}, @code{mem} and @code{tmp}.
@item @code{excludes} @code{feature}, @code{gres}, @code{licence}, @code{nodes}, @code{part}, @code{qos}, @code{reserv} : these are passed as is to the slurm daemon.
For heterogeneous jobs, these attribute names may be followed by an index identifying the task (for example @code{gres0}, @code{gres1}).
The absence of index is equivalent to index 0.
@end itemize

@anchor{autodep}
@section Autodep

Autodep is a mechanism through which jobs are spied to automatically detect which disk accesses are done.
From this information @lmake can determine if accesses were within the constraints provided by the rule and can list the hidden dependencies.

Several methods are available to spy jobs.
Not all methods are supported on all systems, though.

In all cases, the environment variable @code{LMAKE_AUTO_DEP_ENV} must remain in the environment untouched for the autodep mechanism to work correctly.

@subsection @code{'None'} or @code{'none'}

The job is not instrumented.
The only intrusion is the presence of the environment variable @code{LMAKE_AUTODEP_ENV}.

The only way to report activity is through the use of @code{ldepend} / @code{ltarget} or similar functions available in the @code{lmake} module.

The main advantage is that this method is not invasive (or marginally).
The main inconvenient is that no automatic hidden dependencies are recorded, one has to explicitely call @code{ldepend} and experience shows it is very difficult not to forget some.

This method is @strong{not} recommanded.

@subsection @code{'LdPreload'} or @code{'ld_preload'}

The job is run with a library loaded using the @code{LD_PRELOAD} environment variable that catches some calls to the @file{libc.so} (such as @code{open}) to track activity.
This environment variable may be modified as long as the librairy introduced by @lmake stays present.

This requires @file{libc.so} to be dynamically linked.

This method is very performant.

The main advantage is that this method is available even on rather old versions of Linux.
The main inconvenient is that it is somewhat invasive and there are cases of incompatibilities (e.g. sometimes the use of the @code{jemalloc} package depending on its configuration).
Also, it will not run correctly if some commands have the @file{libc} statically linked and this will go undetected.

This method is recommanded on systems that lack the rtld-audit capability when jobs do not use @code{jemalloc}.

@subsection @code{'LdPreloadJemalloc'} or @code{'ld_preload_jemalloc'}

This method is very similar to the previous method except it fully support @code{'jemalloc'}.
The drawback, though, is that it may miss a few dependencies, in some rare occasions, in case accesses are made before @code{main()} is called.

This method is recommanded on systems that lack the rtld-audit capability when jobs use @code{jemalloc}.

@subsection @code{'LdAudit'} or @code{'ld_audit'}

This method is similar to @code{ld_preload} except that the rtld-audit (through the @code{LD_AUDIT} environment variable) mechanism is used instead of @code{LD_PRELOAD},
which is less invasive (cases where it is not transparent are very awkward).
This environment variable may be modified as long as the librairy introduced by @lmake stays present.

This also requires @file{libc.so} to be dynamically linked but failure to do so can be detected and an error is generated, mandating the use of another method (except @code{ld_preload}).

The main advantage is that is is both performant, very little invasive and static linkage of @code{libc} is exceptional (and can be detected).
The main inconvenient is that it requires a rather recent version of Linux and there are cases of incompatibilites
(e.g. code written in @code{rust}, including the rust compilers @code{cargo} and @code{rustc}).

This method is recommanded on systems that support it.

@subsection @code{'Ptrace'} or @code{'ptrace'}

The job is run @code{ptrace}'ed. The seccomp mechanism is used to reduce the performance hit to the minimum possible but still, it is often unacceptable.
There is no requirement that @file{libc.so} be dynamically linked.
It is almost not invasive (mostly the job cannot use ptrace itself, i.e. you will not be able to run an executable level debugger).

Th main adavantage is that it works with a statically linked @code{libc}.
The main inconvenient is that the performance hit can be severe.

This method is recommanded as a fall back when the previous (@code{ld_preload} and @code{ld_audit}) methods cannot be used.

@anchor{link-support}
@section Link support
@lmake has several levels of symbolic link support :
@itemize @minus
@item If @code{'None'} or @code{'none'}, Symbolic links are not supported, no effort is done to resolve them.
@item If @code{'File'} or @code{'file'}, Symbolic links are supported only when they point to files (much like hard links), so intermediate directories are not checked for symbolic links.
@item If @code{'Full'} or @code{'full'}, All symbolic links are supported. This is the most secure but also the most heavy in terms of performance as all intermediate directories have to be checked.
@end itemize

@anchor{rule-selection}
@section Rule selection

When @lmake needs to ensure that a file is up to date, the first action is to identify which rule, if any, must be used to generate it.
This rule selection process works in several steps described below.

A file is deemed buildable if the rule selection process leads to a job that generates the file.

@subsection Name length
First, the length of the target name is checked agains @code{lmake.config.path_max}.
If the target name is longer, then the process stops here and the file is not buildable.

@subsection Sources
The second step is to check target agains sources and source directories.

If the target is listed as a source it is deemed buildable.
No execution is associated, though, the file modifications made by the user are tracked instead.

If the target is within a directory listed as a source directory (i.e. appears ending with a @code{/} in the manifest), it is deemed buildable if it exists.
If it does not exist, it is not buildable.
In both cases, the process stops here.

@subsection Up-hill directory
The third step is to see if a up-hill directory (i.e. one of the directory along the directory path leading to the file) is (recursively) buildable.

If it is the case, the rule selection process stops here and the file is not buildable.

@subsection @code{AntiRule} and @code{SourceRule}
The following step is to match the target against @code{AntiRule}'s and @code{SourceRule}'s (ordered by their @code{prio} attribute, high values are considered first).
If one is found, the target is buildable if it matches a @code{SourceRule} and is not if it matches an @code{AntiRule}.

If it matches a @code{SourceRule} and it does not exist, it is still buildable, but has an error condition.

In all cases, as soon as such a match is found, the process stops here.

@subsection Plain rules

The rules are split into groups. Each group contains all of the rules that share a given @code{prio}.
Groups are ordered with higher @code{prio} first.

The following steps is executed for each group in order, until a rule is found. If none is found, the file declared not buildable.

@subsection Match a target
For a given rule, the file is matched against each target in turn (cf @pxref{regexpr}).
Static targets are tried first in user order, then star targets in user order, and matching stops at the first match.
Target order is made of @code{targets} and @code{target} entries in reversed MRO order (i.e. higher classes in the Python class hierarchy are considered first),
then @code{post_targets} and @code{post_target} entries in MRO order (i.e. lower classes in the Python class hierarchy are considered first.

If a target matches, the matching defines the value of the static stems (i.e. the stems that appear without a @code{*}).
Else, the rule does not apply.

@subsection Check static dependencies

The definition of the static stems allow to compute :
@itemize @minus
@item The other targets of the rule. Static targets become the associated file, star targets becomes regular expressions in which static stems are expanded.
@item Static dependencies by interpreting them as f-strings in which static stems and targets are defined.
@end itemize

Static dependencies are then analyzed to see if the are (recursively) buildable, and if any is not buildable, the rule does not apply.

@subsection Group recap
After these 2 previous steps have been done for the rules of a group, the applicable rules are analyzed the following way :
@itemize
@item If no rule apply, next group is analyzed.
@item If the file matches several rules as a sure target (i.e. a static target and all static deps are sure),
the file is deemed buildable, but if required to run, no job will be executed and the file will be in error.
@item If the file matches some rules as a non-sure target (i.e. a star target or a dep is not sure), the corresponding jobs are run.
If no such jobs generate the file, next group is analyzed.
If several of them generate the file, the file is buildable and in error.
@end itemize

@anchor{critical-deps}
@section Critical deps

The question of critical deps is a performance only question. Semantically, whether a dep is critical or not has no impact on the content of the files built by @lmake.

During dependency analysis, when a dep (call it @file{dep1}) has been used and turns out to be out-of-date, @lmake must choose between 2 strategies regarding the deps that follow :
@itemize @bullet
@item
One possibility is to anticipate that the modification of @file{dep1} has no impact on the list of following deps.
With such an anticipation, @lmake will keep the following deps, i.e. when ensuring that deps are up-to-date before launching a job, @lmake will launch all necessary jobs to rebuild
all dependencies in parallel, even if the deps have been explicitely declared parallel.
@item
Another possivility is to anticipate that such a modification of @file{dep1} will drastically change the list of following deps.
With such an anticipation, as soone as @lmake sees a modified dep, it will stop its analysis as the following deps, acquired with an out-of-date content of @file{dep1} is meaningless.
@end itemize

The first strategy is speculative : launch everything you hear about, and we will see later what is useful.
The second strategy is conservative : build only what is certain to be required.

Generally speaking, a speculative approach is much better, but there are exceptions.

Typical use of critical deps is when you have a report that is built from the results of tests provided by a list of tests (a test suite).

For example, let's say you have :
@itemize @minus
@item 2 tests whose reports are built in @file{test1.rpt} and @file{test2.rpt} by some rather heavy means
@item a test suite @file{test_suite.lst} listing these reports
@item a rule that builds @file{test_suite.rpts} by collating reports listed in @file{test_suite.lst}
@end itemize

In such a situation, the rule building @file{test_suite.rpts} typically has @file{test_suite.lst} as a static dependency but the actual reports @file{test1.rpt} and @file{test2.rpt} are
hidden dependencies, i.e. automatically discovered when building @file{test_suite.rpts}.

Suppose now that you make a modification that makes @file{test2.rpt} very heavy to generate. Knowing that, you change your test_suite so list a lighter @file{test3.rpt} instead.
The succession of jobs would then be the following :
@itemize @minus
@item @file{test1.rpt} and @file{test2.rpt} are rebuilt as they are out-of-date after your modification.
@item @file{test_suite.rpts} is rebuilt to collate theses reports.
@item @lmake then sees that @file{test3.rpt} is needed instead of @file{test2.rpt}.
@item Hence, @file{test3.rpt} is (re)built.
@item @file{test_suite.rpts} is finally built from @file{test1.rpt} and @file{test3.rpt}.
@end itemize

There are 2 losses of performance here :
@itemize @minus
@item @file{test2.rpt} is unnecessarily rebuilt.
@item @file{test1.rpt} and @file{test3.rpt} are rebuilt sequentially.
@end itemize

The problem lies in the fact that @file{test1.rpt} and @file{test2.rpt} are rebuilt before @lmake had a chance to re-analyze the test suite showing that the new tests are test1 and test3.
Generally speaking, this is a good strategy : such modifications of the dependency graph happens rather rarely and speculating that it is pretty stable by building known dependencies before
launching a job is the right option.
But here, because collating is very light (something like just executing @code{cat} on the reports), it is better to check @file{tests_suilte.lst} first,
and if it changed, rerun the collation before ensuring (old) tests have run.

This is the purpose of the @code{critical} flag.
Such a flag can either be passed when declaring static deps in a rule, or dynamically using @code{lmake.depend} or @code{ldepend}.

The collating rule would look like :
@itemize @minus
@item Set the @code{critial} flag on @file{test_suite.lst} (before or after actually reading it, this has no impact).
@item Read @file{test_suite.lst}.
@item Call @code{ldepend} on the reports listed in @file{test_suite.lst}.
This is optional, just to generate parallel dependencies instead of automatic sequential dependencies (but if done, it must be before actually reading the reports).
@item Collate reports listed in @file{test_suite.lst}.
@end itemize

And the succession of job would be :
@itemize @minus
@item @file{test_suite.rpts} is rebuilt before analyzing @file{test1.rpt} and @file{test2.rpt} because @file{test_suite.lst} has changed.
@item @lmake sees that @file{test3.rpt} is needed instead of @file{test2.rpt}.
@item Hence, @file{test1.rpt} and @file{test3.rpt} are (re)built in parallel.
@item @file{test_suite.rpts} is finally built from @file{test1.rpt} and @file{test3.rpt}.
@end itemize

@anchor{hierarchical-repositories}
@section Hierarchical repositories

Hierarchical repositories are currently broken and will be fixed shortly.

@XXX{fix hierarchical repositories

Hierarchical repositories are repositories that contain repositories, i.e. some @Lmakefile are present in sub-directories.

In that situation, it is reasonable to assume that the @Lmakefile are made to handle building files underneath it.

To support this situation, @lmake allow you to simply import these @Lmakefile and the @code{cwd} attributes will automatically be set to the right value so that :
@itemize
@item Targets only match within the sub-repo (and escape is possibly by setting the @code{top} flag to the target to provide global rules).
@item The same applies to deps.
@item @code{cmd} is run from this sub-repository, i.e. its cwd is set accordingly.
@item The priority of the rule is boosted by adding to it the directory depth of the sub-repository times @code{lmake.config.sub_prio_boost}.
@end itemize
}

@anchor{eta-estimation}
@section ETA estimation

An ETA estimation is made possible because the execution time for each job is recorded in @lmake book-keeping after all successful runs
(if a job ends in error, it may very well have been much faster and the previous execution time is probably a better estimate than this one).
When a job has never run successfully, an ETE is used instead of its actual execution time by taking a moving average of all the jobs of the same rule.

This being given, a precise ETA would require a fake execution of the jobs yet to be run which can take all dependencies and resources into account.
But this is way too expensive, so a faster process must be done, even at the expense of precision.

In all cases, the ETA assumes that no new hidden dependencies are discovered and that no file is steady so that all jobs currently remaining will actually be executed.

2 approaches can be considered to estimate the time necessary to carry out remaining jobs :
@itemize
@item Resources limited : dependencies are ignored, only resources are considered.
Roughly, the time is the division of the quantity of resources necessary by the quantity of resources available.
For example, if you need 10 minutes of processing and you have 2 cpus, this will last 10/2=5 minutes.
@item Dependencies limited : resources are ignored and only dependencies are considered. This means you only look at the critical path.
For example if you need to run a 2 minutes job followed by a 3 minutes job, and in parallel you must run a 4 minutes job, this will last 2+3=5 minutes.
@end itemize

@lmake uses the first approach. For that it must know the critical resource for each job.
This is the purpose of the @code{n_tokens} and @code{job_tokens} attributes of the rules.
Each job accounts for ETE*@code{job_tokens}/@code{n_tokens}, and all these are accumulated to produce an overall time.
The ETA is then the current time + this accumulated time.

@anchor{video-mode}
@section Video mode and colors

If lmake is connected to a terminal, then the terminal foreground and background colors are probed and if the brightness of the background color is less than that of the foreground color,
video mode is set to normal, else it is set to reverse.

In that case, lmake output is colored and the (configurable) color set is chosen depending on video mode.

@anchor{resource-buckets}
@section Resource buckets

It may be wise to quantify resources with relatively large steps for resources @code{mem} and @code{tmp}, especially if these may be computed with a formula.

The reason is linked to the way the backends select jobs.
When a backend (actually both the local backend and the slurm essentially work the same way) search for the next job to launch, it walk through the available jobs to
find the eligible one with the highest priority.
When doing that, only jobs with different resources need to be compared as for a given set of resources, they can be pre-ordered by priority.
As a consequence, the running time is proportional to the number of different resources.
If the @code{mem} and @code{tmp} needed space is computed from some metrics, it may be very well possible that each job has a different number, leading to a selection process
whose time is proportional to the number of waiting jobs, which can be very high (maybe millions).
To help reduce this overhead, one may want to put jobs into buckets with defined values for these resources.
This can be done with a sound formula to compute the values.
But as this is potentially important for @lmake itself, @lmake provides an easy means to achieve this goal by defining a given precision.
After all, you probably do not care if the reserved memory is 990MB or 1024MB.

The @code{config.backends.precisions} field allows you to easily define the adequate granularity. The larger this number, the finer the granularity.
A fine granularity allows a better use of the available resources.
A coarser graniularity allows a more efficient job selection process.
So the right answer is a sound balance between these two aspects.
A value of 4 or 8 is probably a reasonable value.

In presence of jobs with a high degree of parallelism requiring a lot of cpus, the same may be applied for the required number of cpus.

@anchor{tmp}
@section Mapping the temporary directory

Mapping the temporary directory feature is an answer to some situations which are apparently against the @lmake execution model.

@lmake sees jobs as having some inputs and generating some outputs.
But some tools operate on data (typically a directory) without making a distinction between input and output.

Imagine, for example you have 2 closely related tools :
@itemize
@item Let's call these 2 tools phase1 and phase2.
@item phase1 is used to prepare a directory, for example it generates some source files and put the result in the directory.
@item phase2 operates on this directory, for example it compiles the source files prepared by phase1 and puts the compiled files next to the sources, in the same directory.
@item Suppose, in addition, that phase2 takes and argument, for example it may have several optimization levels for the compilation process.
@end itemize

Then, you want to organize your flow to have a first job using phase1, then several dependent jobs using phase2, potentially running in parallel.
One way to do that is to set up your flow the following way :
@itemize
@item Name the output of phase1 @file{phase1.out}
@item name the output of phases @file{phase2.arg.out} where @file{arg} may have several values.
@item In the rule to run phase1, simply drive it to generate its data in @file{phase1.out}.
@item In the rule to run phase 2, first copy @file{phase1.out} to @file{phase2.arg.out}, then use phase2 to operate on @file{phase2.arg.out}.
The copy process can be further optimized by linking in some situations, but his is not the purpose of this discussion.
@end itemize

This is fine, as long as copying the data is allowed.
Some tools store absolute paths in their own data, so that the copy of @file{phase1.out} to @file{phase2.arg.out} invalidates the data and makes them unusable.
In that case, a modified flow may be :
@itemize
@item In the rule to run phase1, drive it to generate its data in $TMPDIR, then copy $TMPDIR to @file{phase1.out}.
@item In the rule to run phase2, first copy @file{phase1.out} to $TMPDIR, then use phase2 to operate on $TMPDIR, then copy $TMPDIR to @file{phase2.arg.out}.
@end itemize

The problem is that the $TMPDIR used by phase1 may (and typically is) different from the $TMPDIR used for phase2.
This is not a bad @lmake design or a lack of luck, this is unavoidable if you want to run several instances of phase2 in parallel : they cannot all have the same $TMPDIR.

To face this situation, you can ask @lmake to arrange so that each of these jobs see $TMPDIR as a fixed name, for example /tmp, although the true underlying files are in different directories.
This way, the flow shown above works as expected.

This seems like an awkward situation, but is common practice in the CAD tools domain.

@anchor{codec}
@section Encoding and decoding

In some situations with heavily parameterized generated files, file names can become very long.
Think of the mere compilation of a C++ file @file{foo.c}. You may want to specify :
@itemize
@item the optimization level through a -@code{-O} argument
@item Whether debug checks are enable through the definition of @code{NDEBUG}
@item a trace level through the definition of a macro such as @code{TRACE_LEVEL}
@item whether and how to instrument with @code{-fsanitize}
@item whether some internal data are 32 or 64 bits
@item whether to use a reference algorithm or an agressively optimized one used in production.
@item ...
@end itemize
You may want to be able to generate any combination so as, for example, compare the output of any 2 of them for validation purpose.
You easily end up with an object file with a name such as @file{foo.O3.NDEBUG.TRACE_LEVEL=1.sanitize=address.32.o}.
Already 50 characters or so.
In a real projects, file names can easily be 200, 300, 400 characters long.

As long as the file name, with adequate shorthands such as using @code{TL} instead of @code{TRACE_LEVEL} fits within a few hundreds of characters, the situation is heavy but manageable.
But if you need, say 3000 characters to specify a file, then it becomes completely impractical.

When the configuration can be devised in advance, in a stable way, an efficient alternative is to create a file to contain it, which becomes a configuration name,
and just specify the configuration name in the generated file.

In the example above, you may have a file @file{test.opts} that contains options for testing and @file{prod.opts} that contains options for production.
then, your object file is simply named @file{foo.test.o} or @file{foo.prod.o}.

When it is not, the situation is more complex and you need to automatically generate these configuration files with reasonably short names.
A practical and stable way to generate short names is to compute a checksum on the parameters.
You then need a way to retrieve the original parameters from the checksum to generate the generated file (the @file{.o} file in our example).
In doing so, you must account for :
@itemize @minus
@item robustness    : because such checksums are subject to the birthday paradox, you need either to deal with collisions are provide enough margin (roughly doubling the size) to avoid them.
@item repeatability : your system must not prevent you from being able to repeat a scenario that was generated some days, weeks, months earlier.
@item merging       : when you invent a name, think that some colleagues working on the same project may also invent names, and they may collide.
Tools such as @code{git} are there to help you in this process, but your scheme must be git friendly.
@item performance   : you must have a scheme that support as many code/value associations as necessary for your case, without spending most of its time searching for value when given a code.
@item communication : ideally, you may want to signal a bug to a colleague by just telling him "build that target, and you see the bug".
If the target refers to a code, he may need some further steps to create the code/value association, which goes against communication.
@end itemize

One way to deal with this case is to create a central database, with the following pros and cons :
@itemize @minus
@item robustness    : collisions can easily be dealt with.
@item repeatability : this is a probleme. When dealing with collisions, some codes change, which change old repository because the database is not itself versioned. This is a serious problem.
@item merging       : no merging.
@item perfomance    : accessing the data in a performant way is easy. Detecting modifications so that @lmake can take sound decisions may be more challenging.
@item communication : excellent, the database is shared
@item installation  : you need a server, configure clients to connect to it, etc. it is some work
@item maintainance  : as any central services, you may inadvertently enter wrong data, you need a way to administer it as it has the potential to block the whole team.
@end itemize

The @code{lencode}/@code{ldecode} commands (or the @code{lmake.encode}/@code{lmake.decode} fonctions) are there to address this question.

The principle of opeartion is the following :
@itemize @minus
@item There are a certain number of files storing code/value associations. These are sources seen from @lmake, i.e. they are normally managed by @code{git}.
@item To keep the number of such files to a reasonably low level (say low compared to the overal number of sources), there are contexts, mostly used as a subdivision of files
@item So, a file provides a certain number of tables (the contexts), each table associating some codes with some values
@item These tables are stored in files as lines containing triplet : context, code, value
@item When reading, @code{lencode}/@code{ldecode} are very flexible. The files may contain garbage lines, duplicates, collisions, they are all ignored.
When 2 values are associated with the same code by 2 different lines, a new code is generated by lenghtening one of them with further digites of the checksum computed on the value.
When 2 codes are associated with the same value by 2 different lines, only one code is retained, the shorter of the 2 (or any if of equal length).
@item When writing, @code{lencode}/@code{ldecode} are very rigid. File is generated sorted, with no garbage lines, nor duplicates, or collisions.
@item When @lmake starts and read a file, it write it back in its canonical form.
@item When @lmake runs, that @code{lencode} is used and generate new codes on the fly, additional lines are merely appended to the file.
@end itemize

This has the following properties :
@itemize @minus
@item Information is under git. No further server, central database, management, configuration etc.
@item repeatability is excellent. As long as you do not merge, your are insensitive to external activities.
When merging, the probability of collision depends on the length of the used codes, which is under user control.
Moreover, the length increasing automatically with collisions maintain the number of such collision to a reasonably low level, even in fully automatic mode.
@item Merging is very easy : actually one need not even merge. The simple collision file generated by @code{git} can be used as is. This makes this tool very @code{git} friendly.
@item Robustness is perfect : collisions are detected and dealt with.
@item Coherence is perfect : seen from @lmake, each association is managed as a source.
If anything changes (i.e. a new value is associated with an old code or a new code is associated with an old value), the adequate jobs are rerun.
@item Performance is very good as the content of the file is cached in a performance friendly format by @lmake. And update to the file is done by a simple append.
However, the file is sorted at every @lmake command, making the content more rigid and the merge process easier.
@item Associations files can be editing by hand, so that human friendly codes may be associated to some heavily used values.
@code{lencode} will only generate codes from checksums, but will handle any code generated externally (manually or otherwise).
In case of collision and when @lmake must suppress one of 2 codes, externally generated codes are given preference as they believed to be more readable.
If 2 externally generated codes collide, a numerical suffix is appended or incremented to solve the collision.
@end itemize

@chapter FAQ

@section @code{gcc} does not generate dependencies on some generated @file{.h} files, how to handle this ?
When @code{gcc} starts, it looks at all its include directories listed through options such as @code{-I} (@code{-iquote}, @code{-isystem} and @code{-idirafter}).
If a directory does not exist, it is removed from its internal list and when a file is included with @code{#include}, such directories are not tried.
As a consequence, no dep to files within these directories are generated.
To circumvent this adverse optimization done by @code{gcc}, all directories that lie in the repository must exist before @code{gcc} is started.
An easy way to ensure that by creating a dependency to a marker file within each such directory and to create a very simple rule that generates such marker file.

An exemple is shown here :

@example
@group
class Mrkr(lmake.Rule) :
	prio   = float('inf')      # in case of clash with another rule the other rule is perfect, as long as mrkr is not a directory
	target = '@{__dir__@}mrkr'
	cmd    = ''                # target is open as its stdout, this is enough, we have nothing to put in the target
class Gcc(lmake.Rule) :
	targets = @{ 'OBJ' : '@{File:.+@}.o' @}
	deps    = @{ 'SRC' : '@{File:.+@}.c' @}
	cmd     = 'ldepend a/mrkr b/mrkr c/mrkr ; gcc -Ia -Ib -Ic -c -o @{OBJ@} @{SRC@}'
@end group
@end example

@XXX{to be completed}

@chapter Glossary

@table @asis
@item Birthday paradox
This is a wellknown counter intuitive problem linked to checksum collision. It is extensively described there : https://en.wikipedia.org/wiki/Birthday_problem
@item CAD
Computer Aided Design.
A domain used to produce various objects, in partiulcar integrated ciruits, characterized by heavy processing and complex flows.
@item diamond rule
A feature of Python that allows the following behavior :
@itemize
@item A class @code{D} inherits from @code{B} and @code{C} in that order.
@item Both @code{B} and @code{C} inherit from a class @code{A}.
@item A method @code{m} is defined on @code{A} and @code{C} but not on @code{B}.
@item Then if @code{m} is called from an instance of @code{D}, @code{C.m} will be called and not @code{B.m} (which turns out to be @code{A.m}).
@end itemize
This feature is a central point that makes Python multiple inheritance easy to use and enables the class hierarchy shopping list style.
@item ETA
Estimated Time of Arrival. This is the date at which a given event (such as a job being completed) is estimated to occur.
@item ETE
Estimated Time En route. This is the remaining time necessary to complete a task.
@item LRU
Least Recently Used. A classical cache replacement policy where the entry that was least recently used is discarded when a new one is allocated.
@item MRO
Method Research Order, the inheritance chain from the current class to its most basic base, usually @code{object}.
Python computes the MRO in such a way as to enforce the diamond rule.
@end table

@bye
