\input texinfo

@c This file is part of the lmake distribution (git@github.com:cesar-douady/open-lmake.git)
@c Copyright (c) 2023 Doliam
@c This program is free software: you can redistribute/modify under the terms of the GPL-v3 (https://www.gnu.org/licenses/gpl-3.0.html).
@c This program is distributed WITHOUT ANY WARRANTY, without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

@macro XXX{txt}
@end macro

@macro lmake
@code{lmake}
@end macro

@macro adminfile{file}
@file{LMAKE/\file\}
@end macro

@macro Lmakefile
@file{Lmakefile.py}
@end macro

@set TITLE The lmake Manual
@set UPDATED 22 April 2023
@set UPDATED-MONTH April 2023
@set EDITION @dfn{work in progress}
@set VERSION 0.1

@settitle @value{TITLE}
@setchapternewpage odd
@c Combine the variable and function indices:
@syncodeindex vr fn
@c Combine the program and concept indices:
@syncodeindex pg cp
@c FSF publishers: format makebook.texi instead of using this file directly.
@c %**end of header

@copying
This file documents the @lmake utility, which determines
automatically which pieces of a large workflow need to be remade
and issues the commands to remake them.

This is Edition @value{EDITION}, last updated @value{UPDATED},
of @cite{@value{TITLE}}, for @lmake version @value{VERSION}.

Copyright @copyright{}  2023 Doliam.

@quotation
Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 3 or
any later version published by the Free Software Foundation
@end quotation
@end copying

@summarycontents
@contents

@top @lmake
@insertcopying


@chapter Overview of @lmake

The @lmake utility automatically determines automatically which pieces of a large workflow need to be remade
and issues the commands to remake them.
This manual describes @lmake, which was implemented by Cesar Douady.

Our examples show C/C++ and Python programs, since they are most common, but you can use
@lmake with any programming language to run any phase of your CI/CD as long as these can be scripted.
Indeed, @lmake is not limited to programs.
You can use it to describe any task where some files must be (re)computed automatically
from others whenever recomputing would generate such files differently than what they currently are.
Such situations include dependency modifications, but also command modifications, dependency list modifications,
apparition of an include file that was in the search path before an include file was actually accessed, symbolic link modifications, etc.

@lmake is designed to be scalable, robust and efficient.

By scalable, we mean that @lmake can manage millions of files and tens of thousands of CPU hours without any difficulty,
so there is never any reason to have any kind of recursive invocation, @lmake can handle the whole project all at once.

By robust, we mean that @lmake guarantees that if a job is not rerun, then rerunning it would lead to the same content (or a content that is equally legal).
This includes automatic capture of so called hidden dependencies (i.e. dependencies that are not explicitely stated in the rules, e.g. include files).

We also mean that @lmake, as any software, it may have bug.
Such bugs can lead to crashes and to pessimistic behavior (a job is rerun while it was not necessary).
But special attention has been devoted in its design to ensure that it is never optimistic (a job not being rerun while it should have been).
In case of any adverse event (lmake crashes or spurious system reboot),
@lmake automatically recovers potentially corrupted states in a safe way to avoid having to remake the whole project because a few files are corrupted.

Note that @lmake does not only recorver from its own flees, but also a lot of experience is embedded into it to work around system bugs.
This includes for example violations by NFS of its close-to-open synchronization guarantee (which happens, under heavy system load, maybe once in 10.000 accesses)
or SGE/SLURM spuriously disappearing.

By efficient, we mean that jobs are run in parallel, optionally using a batcher such as Slurm, managing limited resources as declared in @Lmakefile.
We also mean that @lmake makes a lot of effort to determine if it is necessary to run a job (while always staying pessismistic).
Such effort includes checksum based modification detection rather than date based, so that if a job is rerun and produces an identical content, subsequent jobs are not rerun.
Also, @lmake embed a build cache whereby jobs can record their results in a cache so that if the same run needs to be carried out by another user,
it may barely fetch the result from the cache rather than run the - potentially lengthy - job.


@section Preparing and running @lmake.

To prepare to use @lmake, you must write a file called
the @Lmakefile that describes the relationships among files
in your workflow and provides commands for generating each file.
In a program, typically, the executable file is updated from object
files, which are in turn made by compiling source files.
Then unit tests are run from the executable and input files, and the output is compared to some references.

Once a suitable @Lmakefile exists, each time you change anything in the workflow (source files, recipes, ...)
this simple shell command:

@example
lmake <my_target>
@end example

@noindent
suffices to perform all necessary steps so that @file{<my_target>} is reproduced as if all steps leading it were carried out while actually carrying out only necessary steps.
The @lmake program maintains an internal state in the @file{LMAKE} directory
to decide which of the files need to be regenerated.
For each of those files, it issues the recipes recorded in @Lmakefile.
During the execution of recipes, @lmake instruments them in order to gather which files were read and written in order to determine hidden dependencies and whether such actions were legal.
These information are recorded in the @file{LMAKE} directory.

You can provide command line arguments to @lmake to somewhat control this process.

@section Problems and Bugs

If you have problems with @lmake or think you've found a bug,
please report it to the developers; we cannot promise to do anything but
we might well want to fix it.

Before reporting a bug, make sure you've actually found a real bug.
Carefully reread the documentation and see if it really says you can do
what you're trying to do.
If it's not clear whether you should be able to do something or not, report that too; it's a bug in the documentation!

Before reporting a bug or trying to fix it yourself, try to isolate it
to the smallest possible @Lmakefile that reproduces the problem.
Then send us the @Lmakefile and the exact results @lmake gave you, including any error messages.
Please don't paraphrase these messages: it's best to cut and paste them into your report.
When generating this small @Lmakefile, be sure to not use any non-free
or unusual tools in your recipes: you can almost always emulate what
such a tool would do with simple shell commands.
Finally, be sure to explain what you expected to occur; this will help us decide whether the problem was really in the documentation.

if your problem is non-deterministic, i.e. it shows up once in a while, include the entire content of the @file{LMAKE} directory.
This directory contains extensive execution traces meant to help developers to track down problems.
Make sure, though, to trim it from any sensitive data.

Once you have a precise problem you can report it in one of two ways.
Either send electronic mail to:

@example
    xxx@@yyy.zzz
@end example

@noindent
or use our Web-based project management tool, at:

@example
    https://xxx.yyy.zzz
@end example

@noindent
In addition to the information above, please be careful to include the
version number of @lmake you are using.
You can get this information from the file @file{LMAKE/version}.
Be sure also to include the type of machine and operating system you are using.
One way to obtain this information is by running the command @samp{uname -a}.


@chapter An Introduction to @Lmakefile syntax

You need a file called a @Lmakefile to tell @lmake what to do.

In this chapter, we will discuss a simple @Lmakefile that describes how to
compile, link and test a tiny executable @file{hello_world} which consists of 3 C++ source files (@file{hello_world.cc}, @file{hello.cc} and @file{world.cc})
and 2 header files (@file{hello.hh} and @file{world.hh}).
This tiny executable just writes @code{hello world} on its output.
There is a reference output (@file{hello_world.ref}) that @lmake uses to check if the execution is correct.

So, the entire project contains the following files :
@itemize
@item @file{hello.hh}
@item @file{hello.cc} (includes @file{hello.hh})
@item @file{world.hh}
@item @file{world.cc} (includes @file{world.hh})
@item @file{hello_world.cc} (includes @file{hello.hh} and @file{world.hh})
@item @file{hello_world.ref}
@end itemize

When @lmake recompiles this tiny executable, each changed C++ source file must be recompiled.
If a header file has changed, each C++ source file that includes the header file must be recompiled.
Each compilation produces an object file corresponding to the source file.
Then, if any source file has changed, all the object files, whether newly made or saved from previous compilations, must be linked together to produce the new tiny executable.
Finally, if the tiny executable changed, its unit test must be rerun and if the resulting output changes (or if the reference is modified), the actual output must be recompared against the reference.

As its name suggests, @Lmakefile is actually a Python file.
@lmake embeds a Python interpreter (version 3.6+) to interpret @Lmakefile.
Because Python is among the most powerful and widely used programming language, this choice allows @lmake users to have access to a very powerful language to express complicated workflows
without the need to learn a new language.
As a side effect, it also allows the developpers to provide such a powerful means without having to design and implement it.
Among the features of Python that come handy when describing workflows, one can list variables, functions, f-strings, conditionals, loops and inheritance.

The goal of @Lmakefile is to describe 3 aspects of your workflow :
@itemize @bullet
@item some global configuration
@item the list of the sources of the workflow
@item the derivation rules
@end itemize

This is done by importing the @lmake module and defining the 3 variables @code{lmake.config}, @code{lmake.sources} and @code{lmake.rules}.
When reading @Lmakefile, @lmake simply imports this module by issuing @code{import Lmakefile} in a Python 3.6+ interpreter and looks at these 3 variables.
@lmake provides some help for these 3 goals, though.

Once @Lmakefile has been read, @lmake writes in the @file{LMAKE} directory a digest of these 3 variables in the files @file{LMAKE/config}, @file{LMAKE/sources} and @file{LMAKE/rules}.
These may be consulted in case of doubt about what @lmake has understood of your @Lmakefile file.

@section Configuration

The configuration describes some global aspects of the workflow.
The @lmake module contains a reasonable default value for the @code{lmake.config} variable and in an introduction chapter, there is nothing much to say.
In a simple workflow, ignoring the configuration step is a good starting point.

@section Sources

@lmake needs to know the list of the source files.
The mere presence on disk of a file is not sufficient for @lmake to qualify it as a source.
This is because the aim of @lmake is to provide a reproductible workflow.
For example, if you work under @code{git}, as it is very common, once you have been able to build a target, you must be able to commit and push, then a colleague (or yourself in another repository)
must be able to do a pull and build the same target to get the same result.
If a file exists in your original repository, but is not tracked by @code{git} and is used to build your target, your colleague will not be able to reproduce the same target with the same content.
In such a situation, @lmake will consider your file as @dfn{dangling} and accessing it will be an error.

Source files are listed in @code{lmake.sources} as a @code{list} or a @code{tuple}.
By default, if @code{lmake.sources} is not set, @lmake will look for a file named @file{Manifest} and use it as a list of files, one per line.
If no @file{Manifest} file is present, it will then issue a @code{git ls-files --recurse-submodules} command to gather the list of sources.

@section Rules

Rules are classes that listed in the @code{lmake.rules} variables.
Rather than manually adding them to this variables, rules can simply be defined as classes inheriting from the class @code{lmake.Rule}.
In addition to listing derived classes in the @code{lmake.rules} variables, the  @code{lmake.Rule} base class provide defaults for various attributes that are of
secondary importance for simple rules.

To be recognized as a usable rule, rules must have the following attributes :
@itemize @bullet
@item @code{targets}
@item @code{cmd}
@end itemize

Generally, it will also have these attributes :
@itemize @bullet
@item @code{stems}
@item @code{deps}
@end itemize

@example
@group
class Compile(lmake.Rule) :
	stems   = @{ 'File' : r'.*'         @}
	targets = @{ 'OBJ'  : '@{File@}.o'  @}
	deps    = @{ 'SRC'  : '@{File@}.cc' @}
	cmd     = 'gcc -c -o $OBJ $SRC'
@end group
@end example

Let's look at each element in this rule.

@subsection @code{name}
The first element is the class name @code{Compile}.
This name will be used by @lmake in reporting when it needs to refer to this rule, in error messages or when it reports execution.
Generally speaking, all rules have a @code{name} attribute which defaults to the class name if not explicitly set.
Here, the @code{name} of our rule is @code{'Compile'} but we could have set the attribute @code{name} to @code{'cc compilation'} for example.

@subsection @code{stems}
Then comes the @code{stems} attribute.
This attribute provides a vocabulary of (Python) regular expressions that can be further referenced in other attributes.

@subsection @code{targets}
Then, there is the @code{targets} attribute.
This attribute defines the files that may be generated by this rule.
Its syntax looks like Python 3.6+ f-strings, except that variable parts (in @code{@{@}}) must be plain variables (not actual expressions).
However, this works the other way around, compared to f-strings. With an f-string, you start from a value of @code{File}, say @code{'foo'}, and from that, you can derive the string
@code{'foo.o'} from the f-string @code{'@{File@}.o'}.
But here, we start from a file @file{foo.o} and we find that this rule applies if we define @code{File} as @code{'foo'}.
More precisely, @lmake matches the file name @code{'foo.o'} against the regular expression @code{r'(?P<File>.*)\.o'} and Python provides the group @code{'File'} as @code{'foo'}.

The reason why the Python 3.6+ f-strings syntax has been leverage is by symmetry with the @code{deps} attribute described below.

There may be more than a single target (and this is why this attribute is a @code{dict}).
In that case, the rule is supposed to generate all of them when it is executed and any of them will trigger its execution.

@subsection @code{deps}
Then, we find the @code{deps} attribute.
This attribute define the explicit dependencies the rule need before it can be run.
This is a @code{dict} mapping keys to actual Python 3.6+ f-strings.
Once @code{File} has been determined by matching a target, it is fed to the f-strings to determine the explicit dependencies.
@lmake will automatically determine actual dependencies by spying the rule execution, so one could think mentioning them explicitly is useless.
To some extent, this is true, with these limitations :

@itemize @bullet

@item
Explicit dependencies are not only used to determine if a rule must be run or not, they are also used to determine if a rule apply or not.
For a rule to apply, it must match a given file as a target, but also, the computed explicit dependencies must be sources or recursively buildable.
By contrast, if a hidden dependencies cannot be built (and if it does not actually exist), this is silently ignored (more to come later on this subject).

Imagine for example that you have a rule to compile C++ files and another rule to compute C files. Given @file{foo.o}, @lmake must determine which rule to apply.
With explicit dependencies, @lmake has the necessary information to select the adequate rule : it will look for files @file{foo.cc} and @file{foo.c} and if one is a source or is buildable,
it can then select the corresponding rule.
Note that if both are sources or buildable, the situation will be ambiguous and @lmake will report an error.
On the opposite, if none are sources or buildable, @file{file.o} will be deemed not buildable.

@item
From a performance perspective, this allows @lmake to know up front that a dependency is required before running a job.
If a dependency is not explicitly mentioned, a target may be built by @lmake, spying its accesses.
@lmake then discovers the dependency, and if it is not up to date, build it and rerun the rule with up to date dependencies.
This double run (which occurs only the first time @lmake hit the given target) can be avoided if the dependency is explicit.

@end itemize

Generally speaking, obvious dependencies (such as the source file for a compilation step) should be mentioned explicitly and the other ones (such as include files for a compilation step)
can be left as hidden dependencies.

@subsection @code{cmd}
Finally we see the @code{cmd} attribute.
This attribute specifies the recipe to use to build targets from dependencies.
The @code{cmd} attribute can be either a @code{str} or a function.

If it is a @code{str}, it contains a shell script that will be executed when the rule is triggered
(the shell can be customized and defaults to the default system shell, usually @file{/bin/bash}).
Before execution, its environment will be augmented with the definitions of stems, targets and dependencies (and a few others that will be described later).
This way, scripts are easy to read and write.

It can also be a function and our example rule could have been written as :
@example
@group
import subprocess as sp
class Compile(lmake.Rule) :
	stems   = @{ 'File' : r'.*'       @}
	targets = @{ 'OBJ'  : '@{File@}.o'  @}
	deps    = @{ 'SRC'  : '@{File@}.cc' @}
	def cmd() :
		sp.run( ('gcc','-c','-o',OBJ,SRC) , check=True )
@end group
@end example

In that case, this function is executed in a Python interpreter when the rule is triggered
(the Python used to run this function can be customized and defaults to the Python used to read @Lmakefile).
Before execution, the definitions of stems, targets and dependencies are put in the global @code{dict} (and a few others that will be described later).
This way, functions are easy to read and write.

@section A simple @Lmakefile

Here is a simple @Lmakefile that sustains our hello_world example :

@example
@group
import lmake

# use default config

# automatic sources

class Base(lmake.Rule) :
	stems = @{ 'File' : r'.*' @}

class Compile(Base) :
	targets = @{ 'OBJ' : '@{File@}.o'  @}
	deps    = @{ 'SRC' : '@{File@}.cc' @}
	cmd     = 'gcc -c -o $OBJ $SRC'

class LinkHelloWorld(lmake.Rule) :
	targets = @{ 'EXE' : 'hello_world' @}
	deps    = @{
		'HELLO_WORLD' : 'hello_world.o'
	,	'HELLO'       : 'hello.o'
	,	'WORLD'       : 'world.o'
	@}
	cmd = 'gcc -o $EXE $HELLO_WORLD $HELLO $WORLD'

class Run(Base) :
	target = '@{File@}.out'
	deps   = @{ 'EXE' : '@{File@}' @}
	cmd    = '$EXE'

class Check(Base) :
	target = '@{File@}.ok'
	deps = @{
		'OUT' : '@{File@}.out'
	,	'REF' : '@{File@}.ref'
	@}
	def cmd() :
		assert open(OUT).read()==open(REF).read()
@end group
@end example

Note a certain number of elements we have not introduced yet :
@itemize @bullet
@item
We use a base class to define the stem @code{File}, so we do not need to repeat its definition in each rule.
@item
In rule @code{Run}, we have defined the attribute @code{target} as a @code{str} rather than attribute @code{targets} as a @code{dict}.@*
This this handy in simple situations and has the following meaning :
@itemize @bullet
@item There is a single target
@item Its content is generated from the stdout of @code{cmd} execution
@end itemize
@item
If @code{cmd} is a @code{str}, the status of the job is determined from the status of the script.
If @code{cmd} is a function, raising an exception or returning convertible to @code{True} will trigger an error status for the rule execution
@end itemize

To run our example, we need to execute @code{lmake hello_world.ok} and this will do all necessary steps that ensure proper generation of the @code{hello_world} executable,
including compilation, link, execution and check.

Note that we do not have to ever mention hidden dependencies (@file{hello.h} and @file{world.h}), these are handled automatically.

A few reactions of @lmake to user actions when you execute @code{lmake hello_world.ok} :
@itemize @bullet

@item If you modify @file{hello.cc}, @lmake will recompile to @file{hello.o}, then relink to @file{hello_world},
then re-generate to @file{hello_world.out} and finally re-check to @file{hello_world.ok} if @file{hello_world.out} changed or stop there if it did not.

@item If you modify @file{hello.hh}, @lmake will recompile to @file{hello.o} and to @file{hello_world.o} in parallel (if resources permit), then proceed with the rest of the flow as above.

@item If you merely modify a comment in @file{hello.cc}, @lmake will recompile to @file{hello.o} (which will be identical to its previous content) and stop there.

@item If you modify the compilation script (e.g. to add the @code{'-O'} option), all compilations are rerun and most probably the rest as well.

@item If you @code{rm} @file{hello.o}, nothing happens.
@item If you @code{rm} @file{hello.o} and modify @file{world.cc}, @lmake will recompile to @file{world.o}, then understands that it needs to @file{hello.o} for the link phase and
will recompile to it, then proceed with the rest of the workflow.

@item If you modify @file{hello.cc} and @file{hello.o}, @lmake will refuse to regenerate @file{hello.o} over your modifications as it fears to destroy an information which is important for you.
For example, you may have saved an important work in this wrong file and you may not have a copy elsewhere.

@end itemize


@chapter User Commands

All commands may be launched from anywhere in a repository.
A repository is a directory containing @Lmakefile.
This means that before being executed, all commands walk up the directory tree until it finds a file named @Lmakefile, which is then considered to be the repository.

Argument and reports are systematically localized to the current working directory.
For example, if you launch @code{lmake b} from directory @file{a} in your repository,
@lmake will execute jobs from the repository root, and during this execution, it will refer to file @file{a/b} as @file{b} and file @file{c} as @file{../c}.

If launched from a terminal, output is colored.
Colors are different depending on whether terminal if dark/light or light/dark.
These colors can be configured.
The colors bears a semantic :
@itemize @bullet
@item Green means success.
@item Red means error.
@item Magenta means warning.
@item Blue means notes generated by the tool.
@item Gray means information of secondary importance.
@item Uncolored means output from user code. This output can be colored by user code (e.g. gcc generates colored error messages, which is very helpful).
@end itemize

@section @lmake

Usage : @code{lmake [-a|--archive] [-e|--forget-old-errors] [[-j|--jobs] max_jobs] [-m|--manual-ok] [-o|--live-out] [-l|--local] [-v|--versbose-backend] targets...}

@lmake launches all necessary jobs to ensure that targets are generated following rules specified in @Lmakefile.

@lmake generates an output line for each significant event :
@itemize @bullet
@item When a job starts if it is long (duration that qualifies a job as long is configurable). This start line is deemed of secondary importance.
@item When a job terminates.  Such lines are followed by the content of stderr if any and status is known.
@item When the job status is finally known, if it was not known when it terminated.
Such lines are followed by the content of stderr if any.
Typically the job status is not known at the end of execution when a new dep was discovered that turned out to be out-of-date.
In that case, the dependency is rebuilt, and if the new content is identical to the old one, @lmake can then decide that the job was run with up-to-date deps.
@end itemize

During execution, if launched from a terminal, @lmake also generates a progression status in the title bar.
This progression status line contains :
@itemize @bullet
@item the number of executed jobs (split between useful, rerun and hit)
@item the number of queued jobs, i.e. jobs that are waiting for resources to be run
@item the number of waiting jobs, i.e. jbos that are waiting for dependencies to be run
@end itemize

At the end of the execution, if the asked targets are not successfully generated, a summary is generated reminding the errors (with a configurable max, 20 by default)
and the stderr of the first error. Intermediate targets are deemed of secondary importance.

When run @lmake launches a server and direct its request to it.
This server can then serve other @lmake requests, so that several @lmake process can run simultaneously in the same repository.

During a @lmake process, all jobs are launched according to the state of the repository at the time the @lmake command was launched.
This way, edition in the repository can go on while the @lmake process runs.
If it turns out that a file is needed that has been modified since @lmake was launched, it will be deemed in error for that process.
This way, if you want a reliable run, then you must not modify the repository while @lmake is running.
But if you are running @lmake in an interactive mode, it is very comfortable to be able to go on with your edition session while some regression testing is running.
At worst, you will have an error mentionning a file has been overwritten, but you will not have an incoherent result based on some old files and some newer files.

Options :
@itemize @bullet
@item @code{-a}|@code{--archive} : ensure all intermediate files are up to date, in addition to the asked targets.
This is useful for example if you want to archive a fully built repository.
@item @code{-e}|@code{--forget-old-errors} : assume encountered errors are transicent.
Contrarily to the @code{lforget -e} command, this only concerns this execution, not subsequent ones.
@item @code{-j}|@code{--jobs} max_jobs : When this option is used, @lmake will limit the overall number of simultaneous jobs to max_jobs per backend.
If several @lmake commands run simultaneously, a job cannot be launched on behalf of a given command if the number of running jobs is not less than its associated max_jobs.
@item @code{-m}|@code{--manual-ok} : normally, @lmake refuses to launch a job that may overwrite a modification done by the user
as @lmake fears to jettison important information from the user.
With this option, the user instructs @lmake that this fear is not pertinent.
@item @code{-o}|@code{--live-out} : normally, @lmake does not output the stdout of jobs (such stdout is accessible with the @code{lshow} command).
However, sometimes it is practical to have the output while jobs are running.
Generating such output for all jobs would produce an intermixed flow of characters of all jobs running in parallel making such an output unreadable.
When this option is used, only the jobs directly producing the asked targets have their output generated on the output of @lmake.
Because most of the time there is a single target, this ensures that there is a single job generating its output, avoiding the intermixing problem.
@item @code{-l}|@code{--local} : with this option, jobs are launched locally (i.e. using the @code{local} backend) instead of the backend mentioned in the rule.
Note that if 2 @lmake commands with different values for this option are running simultaneously, in case a job is necessary for both, it may be launched locally or remotely.
The originally targetted backend is in charge of mapping required resources mentioned in the rule to local resources understandable by the local backend.
@item @code{-s}|@code{--source-ok} : normally, @lmake refuses to launch a job that may overwrite a source.
With this option, the user instructs @lmake that this is allowed.
@item @code{-t}|@code{--keep-tmp} : normally, @lmake washes the temporary directory allocated to a job at the end of job execution.
With this option, the user instructs @lmake to keep the temporary directories, as if the @code{keep_tmp} attribute was set for all rules.
The kept temporary directory can be retreived with @code{lshow -i}.
@item @code{-v}|@code{--verbose-backend} : enable the generation of some execution information from backend.
This is not systematic as this may incur a performance hit.
Such information is available by using @code{lshow -b}.
@end itemize

@subsection output

While @lmake runs, it outputs a log.
This log is also recorded in @file{LMAKE/outputs/<start date>} with the following differences :
@itemize @minus
@item It is not colored.
@item Files are relative to the root of the repository, not to the current working directory where the @lmake command has been launched.
@end itemize

The log contains a line, possibly followed by attached information when the following events occur :
@itemize @minus
@item A job is started, if the job duration is longer than the @code{start_delay} attribute of the rule.
@item A job is completed.
@item A job status is known, while it was not known when it completed.
@item A source file has been seen as modified.
@item A frozen file or a target of a frozen job is needed.
@end itemize

Once the build process is complete, a summary is generated with :
@itemize @minus
@item The frozen files and jobs that we necessary to carry out the build.
@item The jobs in error (the first of them is accompanied with its stderr).
@end itemize

@section @code{lshow}

Usage : @code{lshow [ [-d|--deps] | [-D|-inv-deps] | [-i|--info] | [-s|--script] | [-S|--exec-script] | [-E|--env] | [-e|--stderr] |[-o|--stdout] [-b|--backend]
[-t|--targets] ] [-v|--verbose] targets...}

@code{lshow} provides various information about jobs.
The jobs are those officially generating the targets (i.e. the jobs that would be selected by @lmake if needing to generate it) if any,
else it may be the jobs that actually generated the target.

Options :
@itemize @bullet
@item @code{-d}|@code{--deps} : output the list of all the deps of the jobs.
Unless the verbose flag is specified, only existing deps are shown.
Each line is composed of 5 fields  separated by spaces :
@itemize @minus
@item Flags : each flag is either a letter if set, or a @code{-} if not :
	@itemize .
	@item @code{c} : dep is critical (see @pxref{critical-deps}).
	@item @code{s} : dep is essential, i.e. dep is show in a future graphical tool.
	@item @code{e} : ignore errors on dep, i.e. job can be run even if this dep is built in error.
	@item @code{r} : dep is required, i.e. job is in error if dep is not buildable. For static deps, job is not even tried if dep is not buildable (and another rule is used if possible).
	@item @code{S} : dep is static.
	@end itemize
@item Accesses : each kind of accesses is either a letter if done, or a @code{-} if not :
	@itemize .
	@item @code{L} : dep has been accessed as a symbolic link.
	@item @code{R} : dep has been accessed as a regular file.
	@item @code{T} : dep has been accessed with a stat-like system call (i.e. its inode has been accessed).
	@end itemize
@item Key : the key if the dep is static, else blank.
@item Ascii art showing parallel deps (deps coming from a single call to @code{ldepend} or @code{lmake.depend} are considered parallel).
@item Name of the dep.
@end itemize
If a dep does not exist, it is deemed secondary information and is shown in gray.
@item @code{-D}|@code{--inv-deps} : show jobs that depend on targets.
@item @code{-i}|@code{--info} : show various self-reading info about jobs, such as reason to be launched, execution time, host that executed it, ...
@item @code{-s}|@code{--script} : show the scripts used to execute the jobs.
@item @code{-S}|@code{--exec-script} : show the scripts used to execute the jobs in a form that can be directly executed by standard @code{sh}.
@item @code{-E}|@code{--env} : show the environment used to run the script
@item @code{-e}|@code{--stderr} : show the stderr of the jobs.
@item @code{-o}|@code{--stdout} : show the stdout of the jobs.
@item @code{-b}|@code{--backend} : show some execution information from backend generated when @lmake is run with the @code{-v} flag.
@item @code{-t}|@code{--targets} : show the targets of the jobs.
Unless the verbose flag is specified, only existing targets are shown.
Each line is composed of 4 fields  separated by spaces :
@itemize @minus
@item Info : composed of 4 letters :
@itemize .
@item match  : @code{-} if target can be matched (as a dep by another rule), @code{#} if it cannot.
@item exists : @code{-} if target exists, @code{!} if it does not (it may have been unlinked after having been written).
@item access : @code{-} if target was neither read nor written, @code{R} if it was only read, @code{W} if it was only written, @code{U} if it was both read and written.
@item star   : @code{-} if target is static, @code{*} if it is a star target.
@end itemize
@item Flags : composed of one letter for each flag that may appear in the @code{ltarget} command.
The letter is the short option name if set, else @code{-}.
@item Key : key under which target has been recognized, or @code{<unexpected>} if it has not been recognized.
@item The name of the target.
@end itemize
If a target does not exist, it is deemed secondary information and is shown in gray.
@end itemize

@section @code{lfreeze}

Usage : @code{lfreeze [ [-a|--add] | [-d|--delete] ] targets...} or @code{lfreeze [-l|--list] | [-D|--delete-all]}

@code{lfreeze} is used to manipulate frozen jobs and files.
Frozen files are considered by @lmake as sources although they are not listed as such by @Lmakefile.
Frozen jobs are not run and considered up to date.
Each time such a file or job is referenced by @lmake, an output line is generated mentioning it and such usages appear in the summary.

These precautions are taken because frozen files presence goes against repeatability.

Frozen files and jobs are useful to run a flow from A to B. To do that you type @code{lfreeze A} followed by @code{lmake B}.

Options :
@itemize @bullet
@item @code{-a}|@code{--add} : add targets to the list of frozen files.
@item @code{-d}|@code{--delete} : remove targets from the list of frozen files.
@item @code{-l}|@code{--list} : list frozen files.
@item @code{-D}|@code{--delete-all} : delete all frozen files.
@end itemize

@section @code{lforget}

Usage : @code{lforget [-d] [-t] targets...} or @code{lforget [-e|-r]}

@code{lforget} is used to ask lmake to forget about some of its history.
In its first form, subsequent @lmake commands will forget about the build history of the mentioned targets.
As a consequence, these targets will appear out of date.

This is exceptionally useful in situations where @lmake's hypotheses are broken :
@itemize @minus
@item A file outside the repository is modified. Because @lmake does not track modifications outside the repository, it canot rerun jobs that must be rerun, this must be done manually.
@item An error is transcient. Another option is to launch @code{lmake -e} which asks to consider jobs in error as out-of-date.
@end itemize

Options are :
@itemize @minus
@item @code{-d}|@code{--deps}    : In addition, @lmake will forget about hidden deps.
@item @code{-t}|@code{--targets} : In addition, @lmake will forget about star targets.
Caveat : upon next run, these targets will not be unlinked, with a possible rerun as a consequence if non-incremental targets are read before being written.
@end itemize

In its second form, subsequent @lmake commands will :
@itemize @minus
@item @code{-e}|@code{--error} : consider errors seen so far as transcient errors and will rerun corresponding jobs.
@item @code{-r}|@code{--resources} : not trust builds with old resources and rerun targets that have been successfully built with old resources.
@end itemize

The @code{-e} option is useful when you have actully seen transcient errors.
Just rerunning jobs in error will wash these.
If you need finer control, then you must use the first form of @code{lforget} to control what must be forgotten on a job by job basis.

The @code{-r} option is useful in the following scenario :
@itemize @minus
@item You have run jobs J1 and J2. J1 completed successfully but J2 lacked some memory and ended in error.
@item Then you have modified  the allocated memory, increasing J2's memory and decreasing J1's memory because you think it is better balanced this way.
@item Then you remade both jobs. J2 reran because it was in error and now completes successfully. J1 did not rerun because it was ok and modifying some resources would not change the result.
@item However, it could be that now J1 does not have enough memory any more. It is not a problem in itself because its content is correct, but it may not be reproducible.
@item You want to make sure your repository is fully reproducible.
@item In that case, you run @code{lforget -r}. J1 will rerun because it was not run with the new resources, as if its command was modified. J2 will not because it has already run since then.
@end itemize

@section @code{autodep}

Usage : @code{autodep [[-o|--out] file] [[-m|--autodep-method] method] [[-s|--link-support] level] [[-d|--auto-mkdir]] [[-i|--ignore-stat]] executable args...}

@code{autodep} is a small tool that may be useful when designing a flow.
It allows to see what information (dependencies and targets) are recorded by code instrumentation @lmake injects in jobs to track activity without actually run a job under its control.

The trace generated by @code{autodep} is halfly digested in the sens that :
@itemize @minus
@item Only a summary of pertinent accesses are provided, unlike @code{strace} can generate a line for each access.
There is a line for each accessed file, which may be a read or nothing, possibly followed by a write or an unlink.
@item Accesses outside the repository are not tracked.
@item When symbolic links are supported, they are resolved according to the required support level and additional dependencies may be generated when needed for @lmake to work properly.
@item It is not fully digested as target flags that are provided in rules are not taken into account.
A full digestion to mimic @lmake would require a whole lot of information that would make the user interface significantly heavier, defeating the usefulness of this tool.
@end itemize

Accesses are split into 2 categories :
@itemize @minus
@item Targets : a prefix mention the type of target, unlink versus write, preceded by a read or not.
@item Deps : a kind of ascii art render parallel accesses.
@end itemize

Options :
@itemize @bullet
@item @code{-o}|@code{--out} @file{file} :  generate output to @file{file}, by default output is generated to @code{stderr}.
@item @code{-m}|@code{--autodep-method} @code{method} : use @code{method} to instrument job. Can be one of :
@itemize @minus
@item @code{none} : command is not instrumented (except that the environment variable @code{LMAKE_AUTODEP_ENV} is set). The only way to report activity is through the use of @code{ldepend} and co.
@item @code{ld_preload} : command is run with a library loaded using the @code{LD_PRELOAD} environment variable that catches some calls @file{libc.so} (such as @code{open}) to track activity.
This requires @file{libc.so} to be dynamically linked.
@item @code{ld_audit} : this is similar to @code{ld_preload} except that @code{LD_AUDIT} mechanism is used instead of @code{LD_PRELOAD},
which is less invasive (cases where it is not transparent are very awkward).
This also requires @file{libc.so} to be dynamically linked.
@item @code{ptrace} : command is run @code{ptrace}'ed. The seccomp mechanism is used to reduce the performance hit to the minimum possible but still, it is often unacceptable.
There is no requirement that @file{libc.so} be dynamically linked.
@end itemize
Not all methods are supported on all systems.
@item @code{-s}|@code{--link-support} @code{level} : level of support for symbolic links (@pxref{link-support}).
@item @code{-d}|@code{--auto-mkdir} : Directories are automatically created behind the scene upon calling the @code{chdir} system call.
This may be necessary if your command does an equivalent of @code{cd a ; cat b} to read @file{a/b} where the existence of @file{a} is not guaranteed by some other means.
In that case, without this option, if directory @file{a} does not exist, the @code{cd} is not done and @lmake generates a dependency to @file{b} instead of @file{a/b}.
@item @code{-i}|@code{--ignore-stat} : Stat-like accesses (i.e. access that just access the inode) are ignored.
This may be a performance boost as it is not uncommon that such accesses represent the vast majority of tracked system calls, at the expense of reliability.
@end itemize

@section @code{xxhsum}

Usage : @code{xxhsum file}

XXH is a very high performance, high quality checksum generation algorithm internally used by @lmake to find out whether file was actually modified or not when its date is changed.
XXH is high quality but @strong{not} crypto-robust.
This means that you can defeat it if you write a code specially aimed at this purpose, but not otherwise, by chance.
The version used in @lmake is 56/64 bits : Checksums are computed on 64 bits but when comparing 2 checksums, if they match on 56 (lsb) bits but not on the full 64 bits,
@lmake will consider we enter into a @emph{danger zone} and will stop.
Theoretical computation gives that you can generate thousands of files per second for thousands of year before entering the @emph{danger zone}.
However this theoretical computation assumes that XXH is nearly perfect, which seems to be the case with regards to experiments, but of course it is impossible to do such experiments with
a particular data set that may be far from random and from the actual data set used to evaluate XXH.
In the very improbable case where your data set would be particularly unfriendly with XXH, @lmake will crash with an error rather than silently forgetting to rerun a job.

@code{xxhsum} allow you to generate the checksum of a file.

Because @lmake handles symbolic links as themselves and not as the file they point to (i.e. @lmake works in the physical world), @code{xxhsum} does not follow symbolic links.
The checksum generated for a symbolic link is computed after the link content and such checksums do not clash with regular files with the same content (a different salt is used).

Also, the execute permission bit is also used to compute the checksum of regular files.
@lmake does not handle security bits (read and write permissions), but the execute bit is a semantic bit (possibly in addition to security) and thus is managed by @lmake.

@chapter Job Commands

The commands listed hereafter are meant to be executed from within a job, not as standalone commands.

@section @code{ldepend}

Usage : @code{ldepend [--no-follow|-P] [--critical|-c] [--ignore-error|-e] [--no-required|-r] [--essential|-s] [--verbose|-v] files ...}

@code{ldepend} may be used to inform @lmake that some files must be deemed as read as if you called the @code{open} system call on each of them.
To this extent, it is not that much different from @code{cat} (except performance wise, depend is of course much faste since @code{files} are not really accessed).

Also, generated dependencies are parallel, i.e. a modification on a dependency will not mask an error on another one.
For example, if you do @code{cat a b}, @lmake sees 2 @code{open} system calls, to @file{a} then to @file{b},
exactly the same sequence that if you did @code{cat $(cat a)} where @file{a} contains @code{b} as its only content.

Suppose now that @file{b} is an error. This is a reason for your job to be in error.
But if you modify @file{a}, in the former case, this @strong{cannot} solve your error while in the later case, it may, if the new content of a points to file that may be successfully built.
Because @lmake cannot distinguish between the 2 cases, upon a modification of @file{a}, the job will be rerun in the hope that the error is solved.
Parallel dependencies wil prevent this to happen.

If you do @code{ldepend a b} and @file{a} is modified and @file{b} is in error, the job is not rerun and stays in error.

Also, if for some reasons you run with autodep method @code{none}, this is the way to report dependencies.

The following options are supported :
@itemize @bullet
@item @code{-v}|@code{--verbose}     : write lines composed of the crc and the name separated by a space for each required dependency.
@item @code{-P}|@code{--no-follow}   : do not follow the last level symbolic link.
@item @code{-c}|@code{--critical}    : create critical deps (see @pxref{critical-deps}).
@item @code{-e}|@code{--no-error}    : ignore the error status of the passed dependencies.
@item @code{-r}|@code{--no-required} : accept that dpes may not be buildable, as for a normal read access (in that case, the read may fail, but @lmake is ok)
@item @code{-s}|@code{--esential}    : passed dependencies will not appear in the flow shown with a graphical tool.
@end itemize

@section @code{lcheck_deps}

Usage : @code{lcheck_deps}

@code{lcheck_deps} ensures that all dependencies accessed so far are up-to-date.
If this not the case, the job is killed, generating a @code{rerun} report, the dependencies are rebuilt and the job is rerun.

This is useful before starting a heavy computation. Typically, dependencies are computed and accessed before the heavy sequence and calling @code{check_deps} allows to avoid
running a heavy computation with bad inputs. It is not a semantic problem as @lmake will realize the situation, rebuild the dependencies are rerun the job, but it may be performance problem.

Imagine for exemple that you have to compile @file{heavy.c} that includes a file @file{generated.h} generated by the command @file{generator}.
Imagine then that you type @code{lmake generated.h}, you look at it, find that the file is syntactically correct but contains a bug.
You then modify @file{generator} and because you are confident in your modification, you type @code{lmake heavy.o}.

@lmake will run the compilation of @file{heavy.o}, which lasts 10 minutes and discover that you need @file{generated.h}, which is out-of-date.
It will then rebuild @file{generated.h} and rerun the compilation to @file{heavy.o}, another 10 minutes.

Suppose now that your compilation script separate the preprocessor (say 10 secondes) phase from the compilation (10 minutes) phase and call @code{lcheck_deps} inbetween.
In that case, the first run will stop after preprocessing as @code{lcheck_deps} will kill the job at that moment and the overall time will be 10 minutes 10 secondes instead of 20 minutes.

Note the following points :
@itemize @minus
@item This is a (performance) problem only during the first run of @file{heavy.o}.
On subsequent runs, in particular during a typical edit-compile-debug loop, @lmake will know the dependencies and will launch jobs in the proper order.
But during the first run, it has no knowledge that @file{heavy.c} actually includes @file{generated.h}.
@item Most often, when @file{generated.h} is out-of-date, it is syntactically incorrect (for example it does not exist),
so the first run fails quite early (without spending its heavy optimization time).
@item In the case where @file{generated.h} is rebuilt identically to its previous content, there will be no second run without @code{lcheck_deps} call,
so @code{lcheck_deps} has a (minor) adverse effect leading to an overall time of 10 minutes 10 seconds instead of 10 minutes.
@end itemize

Despite these remarks, there are case where @code{lcheck_deps} is very welcome.

@section @code{ltarget}

Usage : @code{ltarget [-<short-option>|--<long-option>]... files ...}

@code{ltarget} may be used to inform @lmake that some files must be deemed as written as if you called the @code{open} system call on each of them.
If for some reasons you run with autodep method @code{none}, this is the way to report targets.

It is possible to alter the target flags for these targets which, by default, have the flags mentioned in the rule.

The following options are supported :
@itemize @bullet
@item @code{-u} or @code{--unlink}       : report an unlink rather than writing
@item @code{-P} or @code{--no-follow}    : do not follow the last level symbolic link
@item @code{-c} or @code{--crc}          : generate a crc for this target (compulsery if Match)
@item @code{-d} or @code{--dep}          : reads not followed by writes trigger dependencies
@item @code{-e} or @code{--essential}    : show when generating user oriented graphs
@item @code{-f} or @code{--phony}        : unlinks are allowed (possibly followed by reads which are ignored)
@item @code{-s} or @code{--source-ok}    : ok to overwrite source files
@item @code{-t} or @code{--stat}         : inode accesses (stat-like) are not ignored
@item @code{-w} or @code{--write}        : writes are allowed (possibly followed by reads which are ignored)
@item @code{-C} or @code{--no-crc}       : do not generate a crc for this target (compulsery if Match)
@item @code{-D} or @code{--no-dep}       : reads not followed by writes do not trigger dependencies
@item @code{-E} or @code{--no-essential} : do not show when generating user oriented graphs
@item @code{-F} or @code{--no-phony}     : unlinks are not allowed (possibly followed by reads which are ignored)
@item @code{-S} or @code{--no-source-ok} : not ok to overwrite source files
@item @code{-T} or @code{--no-stat}      : inode accesses (stat-like) are ignored
@item @code{-W} or @code{--no-write}     : writes are not allowed (possibly followed by reads which are ignored)
@end itemize


@chapter The Python @lmake module

The @lmake Python module serves 2 purposes :
@itemize @bullet
@item provide base classes and helpers to write @Lmakefile
@item provide some support during job execution
@end itemize

While unavoidable for the first purpose (writing @Lmakefile), it is rarely necessary for job execution.
When imported during job execution, the parts specificly targetted at writing @Lmakefile are not defined.
These are described in their respective chapters below.

Besides necessary variables, functions and classes to write @Lmakefile, the config, rules and sources parts are described in their respective chapters below,
the @lmake module defines a few constants that are of general use.

Some variables fo this module can be defined in @Lmakefile for some specific purposees.

@section specific variables

@section @code{class pdict}

This is a helpful tiny @code{class} deriving from @code{dict} that allows item access as attribute.
This is just syntactic sugar to help the manipulation of configuration @code{dict} objects.

@section @code{def version(major,minor)}

This function is used to check that the expected version is compatible with the actual version.

Upon new releases of @lmake, the major version is incremented if it is not backward compatible, else the minor version is increased if the interface is modified (i.e. new features are supported).
Hence, the check is that major versions must match equal and the actual minor version must be at least the expected minor version.

This function must be called right after having imported the @lmake module as it may adapt itself to the required version when this function is called.
For example, some default values may be modified and if they are used before this function is called, a wrong (native) value may be provided instead of the correct (adjusted to required version) one.

@section Helpers for @Lmakefile

@subsection @code{class Rule}
This @code{class} is used as a base @code{class} for rules.

@subsection @code{class AntiRule}
This @code{class} is used as a base @code{class} for anti-rules.

Anti-rules specify that target files that are not buildable.
They have no dependencies nor execution.

@subsection @code{class SourceRule}
This @code{class} is used as a base @code{class} for sources defined by a pattern.

Source-rules specify that if a matching target exists, it is considered a source.
They have no dependencies nor execution.

@subsection @code{class PyRule}

This @code{class} may be used as a base @code{class} for Python code doing imports.

It manages @code{.pyc} files so that user is not annoyed by Python generating @code{.pyc} files at esoteric places.

It relies on @code{stat} access made by Python to access the original @code{.py} to check @code{.pyc} validity.
As a consequence, if you want to set the @code{ignore_stat} attribute on a @code{PyRule}, you must run python with the @code{-B} option set.
Otherwise, dependencies to the original @code{.py} will be lost when the @code{.pyc} is available an up-to-date.

@subsection @code{class DynamicPyRule}
This @code{class} may be used as a base @code{class} for Python code doing imports that are generated dynamically.

In addition to @code{PyRule} features, it patches Python import machinery to prevent optimizations that suppress accesses to inexisting modules.
Accessing inexisting modules is the way to inform Python that this module is needed and must be generated.

@subsection @code{class RustRule}
This @code{class} may be used as a base @code{class} to execute executable written in rust.

Rust uses a special link mechanism which defeats the default @code{ld_audit} autodep mechanism.
This base @code{class} merely sets the autodep method to @code{ld_preload} which works around this problem.

@subsection @code{class HomelessRule}
This @code{class} copies the @code{TMPDIR} environment variable the @code{HOME} one.
This is a way to ensure that various tools behave the same way as if they were run for the first time.
By default  the @code{HOME} environment variable points to the root of the repository, which permits to put various init code there.

@subsection @code{class DirtyRule}
This @code{class} may be used to ignore all writes that are not an official target.

By itself, it is a dangerous @code{class} and must be used with care.
It is meant to be a practical way to do trials without having to work out all the details, but in a finalized workflow, it is better to avoid the usage of this class.

@subsection @code{def search_root_dir(cwd=os.getcwd())}
Return the root dir as seen from passed @code{cwd} argument.

Note that his may be different from the @code{root_dir} variable in case there is a @Lmakefile file in a subdir.

@subsection @code{def has_backend(backend)}
Return @code{True} if the passed backend is implemented, else return @code{False}.

Raises the @code{ValueError} exception is the passed backend is unknown.

@section constants

The following constants are defined :
@table @code
@item Kilo
@code{1_000}
@item Mega
@code{1_000_000}
@item Giga
@code{1_000_000_000}
@item inf
@code{float('inf')}
@item root_dir
The root directory of the repository as determined when the @lmake command was run.

Recursive sub-repositories are ignored.
Use the @code{search_root_dir} function if you want to get the nearest hierarchical root dir.
@item has_ld_audit
@code{True} if autodep method @code{'ld_audit'} is supported, else @code{False}.
@item has_ld_preload
@code{True} if autodep method @code{'ld_preload'} is supported, else @code{False}.
@item has_ptrace
@code{True} if autodep method @code{'ld_ptrace'} is supported, else @code{False}.
@item no_crc
The 64-bit @code{int} checksum when it has not been computed (yet).
@item crc_no_file
The 64-bit @code{int} checksum produced when computed on a non-existent file.
@end table

@section Job execution support

The Python @lmake module also provides a Python API to the job supporting command described above.
The correspondance is :
@table @asis
@item @code{def check_deps()}
@code{lcheck_deps}
@item @code{def depend(*files,follow_symlinks=True,error=True,required=True,essential=True,verbose=False)}
@code{ldepend}
@code{files} may be a single @code{tuple} or a @code{tuple} of @code{str}'s.
For example, you can call @code{depend('file1','file2')} or @code{depend(('file1','file2'))}.
@item @code{def target(*files,unlink=False,follow_symlinks=True,crc,dep,essential,phony,source_ok,stat,write)}
@code{ltarget}.
When a keyword argument other than @code{unlink} is not mentioned, the corresponding flag is the one mentioned in the rule.
@code{files} may be a single @code{tuple} or a @code{tuple} of @code{str}'s.
For example, you can call @code{target('file1','file2')} or @code{target(('file1','file2'))}.
@end table

@chapter Directories

By default, all administration data @lmake needs to track the repository state is in the @file{LMAKE} directory at the root of the repository.

But most data are either accessed only by the @lmake server, or by individual jobs, and need not be on a shared disk that is visible from the server and all execution hosts.
Such disk are typically rather slow, compared to local disks.

So there a possibility to store administration data that do not mandate sharing into local disks.

@anchor{dir-local_admin_dir}
@section @code{lmake.local_admin_dir}

This variable specifies the directory to use for data that are accessed by the @lmake server only.
It can be set to a directory mounted on a local disk which may be visible only by the @lmake server (i.e. on the host on which you launch the @lmake command).
This directory must be unique for each repository, i.e. @lmake considers it as a sandbox within which it can freely play.

@anchor{dir-remote_admin_dir}
@section @code{lmake.remote_admin_dir}

This variable specifies the directory to use for data that are accessed by the remote executing hosts only (not shared among them).
It can be set to a directory mounted on a local disk of each remote hosts, i.e. it must exist on each remote host but does not necessarily designate the same area on all of them.
This directory must be unique for each repository, i.e. @lmake considers it as a sandbox within which it can freely play.

It can be freely modified (or removed) when @lmake is not running.

@anchor{dir-remote_tmp_dir}
@section @code{lmake.remote_tmp_dir}

This variable specifies the path name of the file system available to user jobs for temporary storage for the remote executing hosts only (not shared among them).
It can be set to a directory mounted on a local disk of each remote hosts, i.e. it must exist on each remote host but does not necessarily designate the same area on all of them.
This directory must be unique for each repository, i.e. @lmake considers it as a sandbox within which it can freely play.

It can be freely modified (or removed) when @lmake is not running.

@chapter Config

@lmake can be configured to tailor its parameters to the user needs.

Configuration is done by setting attributes (or items) of the @code{pdict} @code{lmake.config}.

After @lmake has been run (at least once), the configuration, as understood by @lmake can be retrieved in the file @adminfile{config}.

Recognized attributes are :
@multitable @columnfractions 0.1 0.07 0.83
@headitem Attribute @tab Default @tab Description

@item @code{local_admin_dir}
@tab @code{LMAKE}
@tab This variable contains a directory to be used for @lmake administration in addition to the @code{LMAKE} directory.
Actually most of the accesses are made in this directory (@pxref{dir-local_admin_dir}).

@item @code{remote_admin_dir}
@tab @code{LMAKE}
@tab This variable contains a directory to be used for remote execution administration (@pxref{dir-remote_admin_dir}).

@item @code{remote_tmp_dir}
@tab @code{LMAKE}
@tab This variable contains a directory to be used as a temporary storage for remote execution (@pxref{dir-remote_tmp_dir}).

@item @code{heartbeat}
@tab @code{60}
@tab @lmake launches job through a batcher, one of them being the @code{local} batcher that launches jobs locally.
Also, a remote host executing job may reboot, or the job may be killed, or ... the batcher may simply lose it (yes, it happens from time to time, for example with SGE or Slurm).
In order to save resources (file descriptors), no connection is maintained between @lmake and jobs while they are running (there may be thousands of them).
As a consequence, @lmake has no idea whether a job is running or disappeared.
Without protection, a killed job would lead @lmake to block, waiting undefinitely (or until its timeout if it already started) for it to start or complete.
To avoid this, submitted jobs are watched periodically to check if they still exist.
This attribute provides the interval in seconds between such heartbeats.
@item @code{link_support}
@tab @code{'Full'}
@tab @lmake has several levels of symbolic link support (@pxref{link-support}).
This attribute specifies the used level.
@item @code{source_dirs}

This variable contains a @code{list} of directories that contain source files.

Such source directories can be provided absolute or relative.
This has no impact as long the repository is not moved.
But in case it is, relative source directories must be moved accordingly or these dependencies will be lost (as if they had been deleted).

By default, this variable is empty, but gathering sources from @code{git} (as is done by default in absence of file @file{Manifest}) will add the @code{git} root directory to it.

@item @code{max_dep_depth}
@tab @code{1000}
@tab The rule selection process is a recursive one (@pxref{rule-selection}).
Several means are provided to avoid infinite recursion and this one is the last resort.
The search stops if the depth of the search reaches the value of this attribute, leading to the selection of a special internal rule called @code{'infinite'}.
@item @code{max_error_lines}
@tab unlimited
@tab a lot of error lines are generated by @lmake, only the first @code{max_error_lines} ones are actually output, followed by a line containing @code{...}.
The purpose is to ease reading.
@item @code{network_delay}
@tab @code{3}
@tab When a job completes, it signals it to @lmake.
But while this informations is travelling, the job is nowhere : it is no more running and @lmake is not aware of it being completed.
If during that time, the heartbeat fires checking for job liveness or a ^C is hit asking for jobs to die, @lmake may think this job is lost.
To prevent that, @lmake waits for some time before declaring such a job as actually lost.
This attribute provides this delay in seconds.
@item @code{trace_size}
@tab @code{100_000_000}
@tab While @lmake runs, it generates an execution trace recording a lot of internal events meant for debugging purpose.
Such traces are stored in the directory @adminfile{trace}.
The larger the trace, the more probable the root cause of a potential problem is still recorded, but the more space it takes on disk.
This attributes contains the maximum number of lines this trace can hold (@lmake keeps the 5 last traces in case the root cause lie in a previous run).
@item @code{path_max}
@tab
@tab This is one of the infinite recursion protection in the rule selection process (@pxref{rule-selection}).
Any file with name longer than the value of this attribute is deemed not buildable.
@item @code{sub_prio_boost}
@tab @code{1}
@tab Increment to add to rules defined in sub-repository to boost local rules.
It is multiplied by the directory depth of the sub-repository.
@item @code{console.date_precision}
@tab @code{None}
@tab This attribute specifies the precision (as the number of digit after the second field, for example 3 means we see milli-seconds) with which timestamps are generated on the console output.
If @code{None}, no timestamp is generated.
@item @code{console.host_length}
@tab @code{None}
@tab This attribute specifies the width of the field showing the host that executed or is about to execute the job.
If @code{None}, the host is not shown.
Note that no host is shown for local execution.
@item @code{console.has_exec_time}
@tab @code{True}
@tab If this attribute is true, execution time is reported each time a job is completed.
@item @code{colors}
@tab
@tab @lmake generate colorized output if it is connected to a terminal (and if it understands the color escape sequences) (@pxref{video-mode}).
This attribute is a @code{pdict} with one entry for each symbolic color (@pxref{video-mode}).
Each entry is a 2-tuple of 3-tuple's.
The first 3-tuple provides the color in normal video mode (black/white) and the second one the color in reverse video (white/black).
Each color is a triplet RGB of values between 0 and 255.
@item @code{backends}
@tab
@tab This attribute is a @code{pdict} with one entry for each backend
(@pxref{backends} for an explanation of what is the purpose of backends, and see the backends section for a description of the attributes).
Each entry is a pdict providing resources. Such resources are backend specific.

In addition the @code{precisions} can be set to a @code{dict} with one entry for each standard resource (@code{cpu}, @code{mem} and @code{tmp}).
This attribute must be @code{0} or a power of 2 not less than 2.

If set to a positive value, it represent a number under which full precision is retained when specified in a rule.
Above it, the relative precision is retained, rounding up.
For example, if set to 4, values 1, 2, 3, 4 are retained, but 5 is rounded to 6, 7 to 8, 9 to 12 etc (@pxref{resource-buckets}).
@item @code{caches}
@tab
@tab This attribute is a @code{pdict} with one entry for each cache.
Caches are named with an arbitrary @code{str} and are referenced in rules using this name.
The attributes are described in the caches section below.
@end multitable

@section backends

@multitable @columnfractions 0.1 0.07 0.83
@headitem Attribute @tab Default @tab Description
@item @code{backends.*.interface}
@tab best guess
@tab
When jobs are launched remotely, they must connect to @lmake when they start and when they complete.
This is done by connecting to a socket @lmake has opened for listening, which requires that we must have a means to determine an IP address to connect to.
The host running @lmake may have several network interfaces, one of them (typically only one) being usable by such remote hosts.
There is no generic way to determine this address, so in general, @lmake cannot determine it automatically.

This value may be empty (loop-back for local backend, @code{hostname} look up for remote backends), given in standard dot notation, as the name of an interface (as shown by @code{ifconfig})
or the name of a host (looked up as for @code{ping}).
@item @code{backends.local.cpu}
@tab number of physical CPU's
@tab This is a normal resource that rules can require (which is the case if resources are defaulted)
@item @code{backends.local.mem}
@tab size of physical memory
@tab This is the pysical memory necessary for jobs.
It can be specified as a number or a string representing a number followed by a standard suffix such as @code{k},  @code{M} or @code{G}.
Internally, the granularity is forced to MBytes before any possible rounding linked with the @code{precisions} attribute.
@item @code{backends.local.tmp}
@tab 0
@tab This is the disk size in the temporary directory necessary for jobs.
It can be specified as a number or a string representing a number followed by a standard suffix such as @code{k},  @code{M} or @code{G}.
Internally, the granularity is forced to MBytes before any possible rounding linked with the @code{precisions} attribute.
@end multitable

@section caches

By default, no cache is configured, but an example can be found in @file{lib/lmake.py}, commented out.

@multitable @columnfractions 0.1 0.07 0.83
@headitem Attribute @tab Default @tab Description
@item @code{caches.*.tag}
@tab -
@tab This attribute specifies the method used by @lmake to cache values.
In the current version, only 2 tags may be used :
@itemize @minus
@item @code{'none'} is a cache that caches nothing. No further configuration is required for such a cache.
@item @code{'dir'} is a cache working without daemon. The data are stored in a directory.
@end itemize
@item @code{caches.<dir>.repo}
@tab -
@tab Valid only when @code{tag} is @code{'dir'}. This attribute specifies a key identifying the repository.
In order to avoid poluting the cache during typical edit-run-debug loops with data that will never be reused, the cache restrict its data to at most one entry for each job in each repo.
This attribute is used to identiy a repository. If 2 repositories use the same key, then results produced in one will replace those produced in the other one.
Besides this restriction, a classical LRU algorithm is used.
@item @code{caches.<dir>.dir}
@tab -
@tab Valid only when @code{tag} is @code{'dir'}. This attribute specifies the directory in which the cache puts its data.
@item @code{caches.<dir>.size}
@tab -
@tab Valid only when @code{tag} is @code{'dir'}. This attribute specifies the maximum size the cache can occupy.
@end multitable


@chapter Sources

Sources are files that are deemed as intrinsic.
They cannot be derived using rules as explained in the following chapter.

Also, if a file cannot be derived and is not a source, it is deemed unbuildable, even if it actually exists.
In this later case, it will be considered dangling and this is an error condition.
The purpose of this restriction is to ensure repeatability : all buildable files can be (possibly indirectly) derived from sources using rules.

The list of sources is provided to @lmake by setting the lmake.sources variable.

The following helper functions can be used to provide sources.
If nothing is mentioned in @Lmakefile, @code{auto_sources()} is called.

@section @code{manifest_sources(manifest='Manifest',**kwds)} :

This function sets @code{lmake.sources} from the content of the file provided in @code{manifest}.

@code{kwds} is ignored.

It raises a @code{FileNotFoundError} exception if @code{manifest} cannot be found.

@section @code{git_sources(recurse=True,ignore_missing_submodules=False,**kwds)} :

This function sets @code{lmake.sources} by listing files managed by @code{git}.

If @code{recurse}, sub-modules are searched as well.

If @code{ignore_missing_submodules}, missing sub-modules are ignored rather than generating an error.

@code{kwds} is ignored.

It raises a @code{FileNotFoundError} exception if the repository is not controled by @code{git}.

@section @code{auto_sources(**kwds)} :

This function successively tries @code{manifest_sources} and @code{git_sources} by passing its @code{kwds} argument until one succeeds.

It raises a @code{FileNotFoundError} exception if none succeeds.


@chapter Rules

Rules are described as Python @code{class}'es inheriting from @code{lmake.Rule}, @code{lmake.AntiRule} or @code{SourceRule}.

Inheriting from @code{lmake.Rule} is used to define production rules that allows deriving targets from dependencies.

Inheriting from @code{lmake.AntiRule} is (rarely) used to define rules that specify that matching targets @strong{cannot} be built.
Anti-rules only require the @code{targets} attribute (or those that translate into it, @code{target}, @code{post_targets} and @code{post_target}) and may usefully have a @code{prio} attribute.
Other ones are useless and ignored.

Inheriting from @code{lmake.SourceRule} may be used to define sources by patterns rather than as a list of files controlled by some sort of source-control (typically @code{git}).

Rules are described by a series of attribute as follows.

@section Dynamic values

Most attributes can either be data of the described type or a function taking no argument returning the desired value.
This allows the value to be dynamically selected depending on the job.

Such functions are evaluated in an environment in which the stems (as well as the @code{stems} variable which is a @code{dict} containing the stems
and the targets (as well as the @code{targets} variable) are defined and usable to derive the return value.
Also, depending on the attribute, the deps (as well as the @code{deps} variable) and the resources (as well as the @code{resources} variable) may also be defined.
Whether or not these are available depend on when a given attribute is needed.
For example, when defining the @code{deps}, the deps are obviously not available.

Generally, these functions are not supposed to do local disk accesses (i.e. from within the repository) as at the time they are called, such accessed files may not be up to date.
However, when @code{deps} are in the function environment, the listed files are up to date and can be accessed.
In the current release, these restrictions are not enforced by @lmake, but they will be in a future release.

For composite values (dictionaries or sequences), the entire value may be function or each value can individually be a function (but not the keys).
For dictionaries, if the value function returns @code{None}, there will be no corresponding entry in the resulting dictionary.

Note that regarding resources available in the function environment, the values are the ones instantiated by the backend.

@section @code{combine}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{set}
@item Default
@tab The list of attributes hereinafter described as having combined inheritance
@item Dynamic
@tab No.
@item Example
@tab @code{@{'my_dict_attribute'@}}
@end multitable

This attribute specify a set of attribute names to be processed with combined inheritance (@pxref{rule-inheritance}).
Combined attributes may only be @code{dict}, @code{set} and @code{list}.
@code{dict}'s and @code{set}'s are @code{update}d, @code{list}'s are @code{append}ed.
@code{dict}'s and @code{list}'s are ordered in reverse MRO, base classes being before derived classes.

@section @code{name}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab None
@item Type
@tab @code{str}
@item Default
@tab @code{cls.__name__}
@item Dynamic
@tab No.
@item Example
@tab @code{'compile and link'}
@end multitable

This attribute specify a name for the rule.
This name is used each time @lmake needs to mention the rule in a message.

All rules must have a unique name.
Usually, the default value is fine, but if your rule is defined in a for loop for example,
then you have several definitions with the same @code{__name__} and you must distinguish them from each other with this attribute (usually an f-string with the loop index in it).

@section @code{virtual}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab None
@item Type
@tab @code{bool}
@item Default
@tab @code{True} if @code{cls} lacks the essential attributes to make it a rule (@code{targets} and, if not anti, @code{deps} and @code{cmd}).
@item Dynamic
@tab No.
@item Example
@tab @code{True}
@end multitable

When this attribute exists and has a @code{True} value, this @code{class} is not a rule and is only used as a base @code{class} to define concrete rules.

@section @code{prio}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{float}
@item Default
@tab @code{0} if inheriting from @code{lmake.Rule}, @code{float('+inf')} if deriving from @code{lmake.AntiRule}.
@item Dynamic
@tab No.
@item Example
@tab @code{1}
@end multitable

This attribute is used to order matching priority.
Rules with higher priorities are tried first and if none of them are applicable, rules with lower priorities are then tried (@pxref{rule-selection}).

@section @code{stems}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab No.
@item Example
@tab @code{@{'File':r'.*'@}}
@end multitable

Stems are regular expressions that represent the variable parts of targets which rules match.

Each entry <key>:<value> define a stem named <key> whose associated regular expression is <value>.

@section @code{job_name}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Dynamic
@tab No.
@item Default
@tab The first matching target of the most derived @code{class} in the inheritance hierarchy (i.e. the MRO) having a matching target.
@end multitable

This attribute may exceptionally be used for cosmetic purpose.
Its syntax is the same as target name (i.e. a target with no option).

When @lmake needs to include a job in a report, it will use this attribute.
If it contains star stems, they will be replaced by @code{*}'s in the report.

If defined, this attribute must have the same set of static stems (i.e. stems that do not contain *) as any matching target.

@section @code{targets}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab No.
@item Example
@tab @code{@{ 'OBJ' : '@{File@}.o' @}}
@end multitable

This attribute is used to define the regular expression which targets must match to select this rule (@pxref{rule-selection}).

Keys must be Python identifiers.
Values are @code{list}'s or @code{tuple}'s whose first item defines the target regular expression and following items define flags.
They may also be a simple @code{str} in which case it is as if there were no associated flags.

The regular expression looks like Python f-strings.
The fixed parts (outside @{@}) must match exactly.
The variable parts, called stems, are composed of :
@itemize @bullet
@item An optional name.
If it exists, it is used to ensure coherence with other targets and the @code{job_name} attribute, else coherence is ensured by position.
This name is used to find its definition in the stems @code{dict} and may also be used in the @code{cmd} attribute to refer to the actual content of the corresponding part in the target.
@item An optional *.
If it exists, this target is a star target, meaning that a single job will generate all or some of the targets matching this regular expression.
if not named, such stem must be defined.
@item An optional : followed by a definition (a regular expression).
This is an alternative to refering to an entry in the @code{stems} @code{dict}.
Overall, all stems must be defined somewhere (in the @code{stems} @code{dict}, in a target or in @code{job_name}) and if defined several times, definitions must be identical.
Also, when defined in a target, a definition must contain balanced @code{@{@}}'s, i.e. there must be as many @code{@{} as @code{@}}.
If a regular expression requires unbalanced @code{@{@}}, it must be put in a @code{stems} entry.
@end itemize

The flags may be any combination of the following flags, optionally preceded by - to turn it off when it is present by default.

@multitable @columnfractions 0.1 0.1 0.05 0.75
@headitem CamelCase Flag @tab snake_case Flag @tab Default @tab Description
@item Crc @tab crc @tab Yes @tab A checksum is computed on these targets when generated. Compulsery for matching targets.
@item Dep @tab dep @tab Yes @tab If such a file is read and not written, it will actually be a dependency, not a target.
@item Essential @tab essential @tab Yes @tab This target will be shown in a future graphic tool to show the workflow, it has no algorithmic effect.
@item Incremental @tab incremental @tab No @tab Previous content may be used to produce these targets. In that case, these are not unlinked before execution.
@item ManualOk @tab manual_ok @tab No @tab Modifying these targets outside @lmake control will not prevent job from executing.
@item Match @tab match @tab Yes @tab This entry may be used to select this rule.
@item Phony @tab phony @tab No @tab A possible content for target is to be not present on disk. If a star target, all matching files are deemed generated by this rule.
@item SourceOk @tab source_ok @tab No @tab Do not trigger an error if target is indeed a source.
This may occur if another target is required or if this target is a star target (otherwise, the rule will not be executed as target will be recognized as a source).
@item Star @tab star @tab if star stem present @tab Target is a star target, even if no star stem is present (which means next rule will be tried if file is not generated).
@item Stat @tab stat @tab Yes @tab @code{inode} accesses (e.g. stat) are deeemed to be read (else they are ignored).
@item Top @tab top @tab No @tab target pattern is interpreted relative to the root directory of the repository, else it is relative to the @code{cwd} of the rule.
@item Warning @tab warning @tab No @tab Warning is reported if a target is unlinked before job execution while generated by another job.
@item Write @tab write @tab Yes @tab Job is allowed to write to this target.
@end multitable

All matching targets must have the same set of static stems (i.e. stems with no * in its name).

Matching is done by first trying to match static targets (i.e. which are not star) then star targets.
The first match will provide the associated stem definitions and flags.

Unless the @code{top} flag is set, the @code{cwd} attribute is prepended to the target pattern in order to suppor hierarchical repository (@pxref{hierarchical-repositories}).


@section @code{target}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str} or @code{list} or @code{tuple}
@item Default
@tab -
@item Dynamic
@tab No.
@end multitable

This attribute defines an unnamed target as the last target.
Its syntax is the same as any target entry except that it may not be @code{incremental}, @code{phony} nor @code{star}.

During execution, @code{cmd} stdout will be redirected to this (necessarily unique since it cannot be a @code{star}) target.

It is exclusive with the @code{post_target} attribute.

@section @code{post_targets}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab No.
@end multitable

This attribute is identical to @code{targets} except that :
@itemize @minus
@item their entries are in reversed order
@item they are put at the end of the targets
@end itemize

@section @code{post_target}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str} or @code{list} or @code{tuple}
@item Default
@tab -
@item Dynamic
@tab No.
@end multitable

This attribute is identical to @code{target} except that :

@itemize @minus
@item it is defined as the last @code{post_targets} (before being reversed)
@item it is exclusive with the @code{target} attribute.
@end itemize

@section @code{deps}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab Yes. Environment includes stems and targets.
@item Example
@tab @code{@{ 'SRC' : '@{File@}.c' @}}
@end multitable

This attribute defines the static dependencies.
It is a @code{dict} which associates Python identifiers to files computed from the available environment.

They are f-strings, i.e. their value follow the Python f-string syntax and semantic
but they are interpreted when @lmake tries to match the rule (the rule only matches if static dependencies are buildable, @pxref{rule-selection}).
Hence they lack the initial @code{f} in front of the string.

Accessible variables when evaluating the f-string include the @code{stems}, the @code{targets}, attributes and the module dictionary.

Alternatively, values can also be @code{list} or @code{tuple} whose first item is as described above, followed by flags.

The flags may be any combination of the following flags, optionally preceded by - to turn it off when it is present by default.
Flags may be arbitrarily nested into sub-@code{list}'s or sub-@code{tuple}'s.

@multitable @columnfractions 0.1 0.1 0.05 0.75
@headitem CamelCase Flag @tab snake_case Flag @tab Default @tab Description
@item Critical           @tab critical        @tab No      @tab This dep is critial (see @pxref{critical-deps}).
@item IgnoreError        @tab ignore_error    @tab No      @tab This dep may be in error, job will be launched anyway.
@item Essential          @tab essential       @tab Yes     @tab This dep will be shown in a future graphic tool to show the workflow, it has no algorithmic effect.
@item Top                @tab top             @tab No      @tab dep pattern is interpreted relative to the root directory of the repository, else it is relative to the @code{cwd} of the rule.
@end multitable

Flag order and dependency order are not significative.

Unless the @code{top} flag is set, the @code{cwd} attribute is prepended to the dep pattern in order to suppor hierarchical repository (@pxref{hierarchical-repositories}).

@section @code{dep}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Default
@tab -
@item Dynamic
@tab Yes. Environment includes stems and targets.
@end multitable

This attribute defines an unnamed static dependency.

During execution, @code{cmd} stdin will be redirected to this dependency, else it is @file{/dev/null}.

@section @code{chroot}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Default
@tab -
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute defines a directory in which jobs will @code{chroot} into before execution begins.

The job wrapper itself stays in the original file system in which it is launched, only the job does a @code{chroot}.

@section @code{tmp}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Default
@tab -
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute defines the name under which the temporary directory allocated for the job is seen by it.
This means the job runs in a sand box in which the temporary directory is mapped to a directory named after this attribute (see @pxref{tmp} for the usefulness of this feature).

@section @code{cwd}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Default
@tab The nearest root dir as seen from the module defining the rule.
@item Dynamic
@tab No.
@end multitable

This attribute defines a directory in which jobs will @code{chdir} into before execution begins.

This attribute is also prepended to targets and deps unless they start with a @code{/}.

@section @code{local_marker}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Default
@tab @code{'$CWD'} (i.e. the string @code{$CWD} it self, not the value of the CWD environment variable)
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute defines a marker which is search in environment variables present in the @code{environ_*} attributes.
When an occurrence is found, it is replaced by the value of the @code{cwd} attribute.

The goal of this attribute is to allow to express rules without explicite reference to the repository.
This in turn allow the cache to provide results computed in a repository to another another repository, which is mostly its purpose.
If the repository (i.e. the directory holding it) is part of the command of a rule, then when the cache check for command coherence, it will find a discrepency, preventing result forwarding.

This mechanism apply to the environment variables as the other attributes need not refer explicitely to the repository.
On the contrary, it would be cumbersome if such environment variables as PATH, PYTHONPATH, HOME, ... could not refer the repository.

@section @code{environ_cmd}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab See description
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@item Example
@tab @code{@{ 'MY_TOOL_ROOT' : '/install/my_tool' @}}
@end multitable

This attribute defines environment variables set during job execution.

The content of this attribute is managed as part of the job command, meaning that jobs are rerun upon modification.

The environment in which the @lmake command is run is ignored so as to favor reproducibility, unless explicitely transported by using value from @code{os.environ}.

If resulting value is @code{...} (the Python ellipsis), the value from the execution environment is used.
This is typically used to access some environment variables set by @code{slurm}.

By default the following environment variables are defined :
@table @code
@item HOME
The root directory of the repository, so as to prevent tools from accessing startup files that may vary from user to user.
Necessary startup files can be put inside the repository, administered with your prefered versioning tool as any other source.
@item PATH
The standard path with @lmake bin directory in front.
The standard path is the one you get with the standard shell in absence of any startup file.
@item PYTHONPATH
The @lmake lib directory.
@end table

Note that the current environment is accessible when @Lmakefile is read, so that it is quite simple to copy some variables from the user environment
although this practice is discouraged and should be used with much care.

@section @code{environ_resources}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@item Example
@tab @code{@{ 'MY_TOOL_LICENCE' : '12345' @}}
@end multitable

This attribute defines environment variables set during job execution.

The content of this attribute is managed as resources, meaning that jobs in error are rerun upon modification, but not jobs that were successfully built.

The environment in which the @lmake command is run is ignored so as to favor reproducibility.

Note that the current environment is accessible when @Lmakefile is read, so that it is quite simple to copy some variables from the user environment
although this practice is discouraged and should be used with much care.

If resulting value is @code{...} (the Python ellipsis), the value from the execution environment is used.
This is typically used to access some environment variables set by @code{slurm}.

@section @code{environ_ancillary}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab See description
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@item Example
@tab @code{@{ 'DISPLAY' : ':10' @}}
@end multitable

This attribute defines environment variables set during job execution.

The content of this attribute is not managed, meaning that jobs are not rerun upon modification.

The environment in which the @lmake command is run is ignored so as to favor reproducibility.

By default the following environment variables are defined :
@table @code
@item UID
The user id.
@item USER
The user login name.
@end table

Note that the current environment is accessible when @Lmakefile is read, so that it is quite simple to copy some variables from the user environment
although this practice is discouraged and should be used with much care.

If resulting value is @code{...} (the Python ellipsis), the value from the execution environment is used.
This is typically used to access some environment variables set by @code{slurm}.

@section @code{python}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{list} or @code{tuple}
@item Default
@tab system Python
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute defines the interpreter used to run the @code{cmd} if it is a @code{function}.
At the end of the supplied executable and arguments, @code{'-c'} and the actual script is appended.

@section @code{shell}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{list} or @code{tuple}
@item Default
@tab @code{/bin/bash}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute defines the interpreter used to run the @code{cmd} if it is a @code{str}.
At the end of the supplied executable and arguments, @code{'-c'} and the actual script is appended.

@section @code{cmd}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{function} or @code{str}
@item Default
@tab -
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources. See description, though, if it is defined as a function.
@item Example1
@tab @code{'gcc -c -o @{OBJ@} @{SRC@}'}
@item Example2
@tab @code{def cmd() : subprocess.run(('gcc','-c','-o',OBJ,SRC,check=True))}
@end multitable

Whether @code{cmd} is a @code{str} or a @code{function}, the following environment variable are automatically set, if not explicitly set by the @code{environ} attribute :
@itemize @minus
@item @code{LD_AUDIT}          : A variable necessary for the autodep mechanism of @lmake if the @code{autodep} attribute is set to @code{'ld_audit'} (@pxref{autodep}).
@item @code{LD_PRELOAD}        : A variable necessary for the autodep mechanism of @lmake if the @code{autodep} attribute is set to @code{'ld_preload'} (@pxref{autodep}).
@item @code{LMAKE_AUTODEP_ENV} : A variable necessary for the autodep mechanism of @lmake, it must stay present and untouched (@pxref{autodep}).
@item @code{PWD}               : The initial directory in which @code{cmd} is run, as provided by the @code{cwd} attribute (often the root of the repository).
@item @code{ROOT_DIR}          : The root of the repository.
@item @code{SEQUENCE_ID}       : A value which is unique for each run.
It is  @code{1} initially and is incremented each time a job is run.
@item @code{SMALL_ID}          : A value which is unique among running job at any given time.
It is always at least @code{1} and efforts are made to maintain it as small as possible.
@item @code{TMPDIR}            : The name of a directory which is empty at the start of the job.
If the temporary directory is not kept through the use of the @code{keep_tmp} attribute or the @code{-t} option, this directory is cleaned up at the end of the job execution.
@end itemize

@subsection if it is a @code{function}

In that case, this attribute is called to run the job.
Combined inheritance is a special case for @code{cmd}.

If several definitions exist along the MRO, They must all be @code{function}'s and they are called successively in reverse MRO.
The first (i.e. the most basic) one must have no non-defaulted arguments and will be called with no argument.
The other ones may have arguments, all but the first having default values.
In that case, such @code{function}'s are called with the result of the previous one as unique argument.
Else, if a @code{function} has no argument, the result of the previous function is dropped.

During evaluation, when the job runs, its global @code{dict} is populated to contain values referenced in these @code{function}'s.
Values may come from (by order of preference) :
@itemize @minus
@item The @code{stems}, @code{targets}, @code{deps}, @code{resources} as named in their respective @code{dict}.
@item @code{stems}, @code{targets}, @code{deps}, @code{resources} that contain their respective whole @code{dict}, @code{job_tokens} that contain its value.
@item Any attribute defined in the class, or a base class (as for normal Python attribute access).
@item Any value in the module @code{dict}.
@item Any builtin value
@item undefined variables are not defined, which is ok as long as they are not accessed.
@end itemize

Because jobs are executed remotely using the interpreter mentioned in the @code{python} attribute
and to avoid depending on the whole @Lmakefile (which would force to rerun all jobs as soon as any rule is modified),
these @code{function}'s and their context are serialized to be transported.
The serialization process may improve over time but as of today, the following applies :
@itemize @minus
@item Basic objects are transported as is : @code{None}, @code{...}, @code{bool}, @code{int}, @code{float}, @code{complex}, @code{str}, @code{bytes}.
@item @code{list}, @code{tuple}, @code{set} and @code{dict} are transported by transporting their content. Note that reconvergences (and a fortiori loops) are not handled.
@item @code{function}'s are transported as their source accompanied with their context : global accessed variables and default values for arguments.
@item Imported objects (@code{function}'s and @code{class}'es and generally all objects with a @code{__qualname__} attribute) are transported as an @code{import} statement.
@item Builtin objects are transported spontaneously, without requiring any generated code.
@end itemize

Values are captured according to the normal Python semantic, i.e. once the @code{Lmakefile} module is fully imported.
Care must be taken for variables whose values change during the @code{import} process.
This typically concerns loop indices.
To capture these at definition time and not at the end, such values must be saved somewhere.
There are mostly 2 practical possibilities :
@itemize @minus
@item Declare an argument with a default value. Such default value is saved when the function is defined.
@item Define a class attribute. Class attributes are saved when its definition ends, which is before a loop index.
@end itemize

The job is deemed to be successful if the last function returns a false value.

@subsection if it is a @code{str}

In that case, this attribute is executed as a shell command to run the job.
Combined inheritance is a special case for @code{cmd}.
While walking the MRO, if for a base class @code{cmd} is defined as a @code{function} and it has a @code{shell} attribute, the value of this attribute is used instead.
The purpose is that it is impossible to combine @code{str}'s and @code{function}'s because they use different paradigms.
As a consequence, a base class may want to have 2 implementations, one for subclasses that use Python @code{cmd} and another for subclasses that use shell @code{cmd}.
For such a base class, the solution is to define @code{cmd} as a @code{function} and set its @code{shell} attribute to the @code{str} version.

If several definitions exist along the MRO, They must all be @code{str}'s and they are run successively in reverse MRO in the same process.
So, it is possible for a first definition to define an environment variable that is used in a subsequent one.

As for other attributes that may be dynamic, @code{cmd} is interpreted as an f-string.

The job is deemed to be successful if the return code of the overall process is @code{0}.

@section @code{cache}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Constraint
@tab One of the caches listed in config.
@item Default
@tab <not cached>
@item Dynamic
@tab Yes. Environment includes stems, targets.
@end multitable

This attribute specifies the cache to use for jobs executed by this rule.
When a job is executed, its results are stored in the cache.
If space is needed (all caches are constrained in size), any other entry can be replaced.
The cache policy (described in its own section, in the config chapter) tries to identify entries that are likely to be useless in the future.

@section @code{backend}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Constraint
@tab One of the supported backends.
@item Default
@tab @code{'local'}
@item Dynamic
@tab Yes. Environment includes stems, targets and deps.
@end multitable

This attribute specifies the backend to use to launch jobs (@pxref{backends}).

@section @code{autodep}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str}
@item Constraint
@tab One of @code{'none'}, @code{'ld_preload'}, @code{'ld_audit'} or @code{'ptrace'}
@item Default
@tab @code{'ld_audit'} if supported else @code{'ld_preload'}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute specifies the method used by autodep (@pxref{autodep}) to discover hidden dependencies.

@section @code{resources}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Combined
@item Type
@tab @code{dict}
@item Default
@tab @code{@{@}}
@item Dynamic
@tab Yes. Environment includes stems, targets and deps.
@item Example
@tab @code{@{ 'MY_RESOURCE' : '1' @}}
@end multitable

This attribute specifies the resources required by a job to run successfully.
These may be cpu availability, memory, commercial tool licenses, access to dedicated hardware, ...

The syntax is the same as for @code{deps}, except that in addition to other variables, deps can be referenced.

After interpretation, the @code{dict} is passed to the @code{backend} to be used in its scheduling (@pxref{local-backend} for the local backend).

@section @code{stderr_len}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{int}
@item Default
@tab -
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute defines the maximum number of lines of stderr that will be displayed in the output of @lmake.
The whole content of stderr stays accessible with the @code{lshow -e} command.

@section @code{allow_stderr}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute has a false value, the simple fact that a job generates a non-empty stderr is an error.
If it is @code{True}, writing to stderr is allowed and does not produce an error. The @lmake output will exhibit a warning, though.

@section @code{auto_mkdir}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute has a @code{True} value, executing a @code{chdir} syscall (e.g. executing @code{cd} in bash) will create the target directory if it does not exist.

This is useful for scripts in situations such as :
@itemize @minus
@item The script does @code{chdir a}.
@item Then try to read file @file{b} from there.
@item What is expected is to have a dependency on @file{a/b} which may not exist initially but will be created by some other job.
@item However, if directory @file{a} does not exist, the @code{chdir} call fails and the file which is open for reading is @file{b} instead of @file{a/b}.
@item As a consequence, no dependency is set for @file{a/b} and the problem will not be resolved by a further re-execution.
@item Setting this attribute to @code{True} creates directory @file{a} on the fly when @code{chdir} is called so that it succeeds and the correct dependency is set.
@end itemize

@section @code{ignore_stat}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute is set to a @code{True} value, stat-like syscalls (i.e. syscalls that access the i-node only) are ignored.
The @code{'-Stat'} flag on targets provide a more flexible mecanism.
The only advantage of this attribute is that precisely because it is rather crude, stat-like syscalls can be filtered very early and performances are better.

@section @code{keep_tmp}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute is set to a true value, the temporary directory is kept after job execution.
It can be retreived with @code{lshow -i}.
Sucessive executions of the same job overwrite the temporary directory, though, so only the content corresponding to the last execution is available.
When this attribute has a @code{False} value, the temporary directory is washed at the end of the job execution.

@section @code{force}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{bool}
@item Default
@tab @code{False}
@item Dynamic
@tab No.
@end multitable

When this attribute is set to a @code{True} value, jobs are always considered out-of-date and are systematically rerun if a target is needed.
It is rarely necessary.

@section @code{timeout}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{float}
@item Constraint
@tab >=0
@item Default
@tab no timeout
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute has a non-zero value, job is killed and a failure is reported if it is not done before that many seconds.

@section @code{job_tokens}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{str} or @code{int}
@item Constraint
@tab >=1 and <256
@item Default
@tab @code{1}
@item Dynamic
@tab Yes. Environment includes stems and targets.
@end multitable

This attribute has the same syntax as a resource, except that a @code{float} is accepted.
If it is a @code{str}, it must be convertible to a float after interpretation.

It is only used to estimate the ETA (@pxref{eta-estimation}).

@section @code{n_tokens}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{int} ()
@item Constraint
@tab >=1
@item Default
@tab @code{1}
@item Dynamic
@tab No.
@end multitable

This attribute indicates to @lmake a quantity of abstract resources used to estimate the expected parallelism of jobs within this rule.

It is only used to estimate the ETA (@pxref{eta-estimation}).

@section @code{start_delay}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{float}
@item Default
@tab @code{0}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

When this attribute is set to a non-zero value, start lines are only output for jobs that last longer than that many seconds.
The consequence is only cosmetic, it has no other impact.

@section @code{kill_sigs}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{list} or @code{tuple}
@item Default
@tab @code{()}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute provides a list of signals to send the job when @lmake decides to kill it.
A job is killed when :
@itemize @minus
@item @kbd{^C} is hit if it is not necessary for another running @lmake command which has not received a @kbd{^C}.
@item When timeout is reached.
@item When @code{check_deps} is called and some dependencies are not up to date.
@end itemize

The signals listed in this list are sent in turn, once every second. If the list is exhausted and the job is still alive, @code{KILLSIG}'s are sent, once per second.
Longer interval can be obtained by inserting @code{0}'s. @code{0} signals are not sent and anyway, these would have no impact if they were.

Note: some backends, such as Slurm when it is available, may have other means to manage timeouts. Both mechanisms will be usable.

@section @code{n_retries}

@multitable @columnfractions 0.1 0.9
@item Inheritance
@tab Python
@item Type
@tab @code{int}
@item Default
@tab @code{0}
@item Dynamic
@tab Yes. Environment includes stems, targets, deps and resources.
@end multitable

This attribute provides the number of allowed retries before giving up when a job is lost.
For example, a job may be lost because of a remote host being misconfigured, or because the job management process (called @code{job_exec}) was manually killed.

In that case, the job is retried, but a maximum number of retry attemps are allowed, after which the job is considered in error.

@chapter The @file{LMAKE} directory

This directory contains numerous information that may be useful to the user.

There are other files than those described here which are for @lmake own management.

@section @file{LMAKE/config}

This file contains a description of the @code{lmake.config} @code{dict} as it has been understood by @lmake after having processed @Lmakefile.

@section @file{LMAKE/rules}

This file contains a description of the rules as it has been understood by @lmake after having processed @Lmakefile.

@section @file{LMAKE/sources}

This file contains a description of the sources as it has been understood by @lmake after having processed @Lmakefile.

@section @file{LMAKE/makefiles}

This file contains a list of files that @lmake has read to process @Lmakefile.

@section @file{LMAKE/outputs/<date>}

This file contains a transcript of the @lmake command that has been run at @file{<date>}.

@section @file{LMAKE/last_output}

This file is a symbolic link to the last transcript.

@section @file{LMAKE/targets}

This file contains the targets that have been required by @lmake commands in chronological order (with duplicates removed).

@chapter Some considerations

This chapter contains some considerations that appear in several places of this documentation.
It is meant to be the target of cross-references.

@anchor{rule-inheritance}
@section Rule inheritance

Rules are Python @code{class}'es that inherit from @code{lmake.Rule} (or @code{lmake.AntiRule} or @code{lmake.SourceRule}).

However, Python's native inheritance mechanism is not ideal to describe a rule as one would like to prepare a base @code{class} such as :
@itemize @minus
@item provide environment variables
@item provide some default actions for some files with given pattern
@item provide some automatic dependencies
@item ...
@end itemize

As these are described with @code{dict}, you would like to inherit @code{dict} entries from the base @code{class} and not only the @code{dict} as a whole.
A possibility would have been to use the @code{__prepare__} method of a meta-class to pre-define inherited values of such attributes,
but that would defeat the practical possibility to use multiple inheritance by suppressing the diamond rule.

The chosen method has been to walk through the MRO at class creation time and :
@itemize @minus
@item Define a set of attributes to be handled through combination. This set is defined by the attribute @code{combine}, itself being handled by combination.
@item Combined attribute are handled by updating/appending rather than replacing when walking through MRO in reverse order.
@item Entries with a value None are suppressed as update never suppress a given entry.
Similarly, values inserted in a set prefixed with a @code{'-'} remove the corresponding value from the @code{set}.
@end itemize

Because this mechanism walks through the MRO, the diamond rule is enforced.

@anchor{backends}
@section Backends

Backends are in charge of actually launching jobs when the @lmake engine has identified that it had to be run.
It is also in charge of :
@itemize @minus
@item Killing jobs when the @lmake engine has identified it had to be so.
@item Scheduling jobs so as to optimize the runtime, based on some indications provided by the @lmake engine.
@item Rescheduling jobs when new scheduling indications becomes available.
@end itemize

A backend has to take decisions of 2 kinds :
@itemize @minus
@item Is a job eligible for running.
From a dependency perspective, the @lmake engine guarantees it is so.
But the job needs some resources to run and these resources may already be busy because of some other jobs already running.
@item If several jobs are eligible, which one(s) to actually launch.
@end itemize

Each backend is autonomous in its decisions and has its own algorithm to take them.
However, generally speaking, they more or less work by following the following principles :
@itemize @minus
@item For the first question, the backend maintain a pool of available resources and a job is eligible if its required resources can fit in the pool.
When launched, the required resources are subracted from the pool and when terminated, they are returned to it.
@item For the second question, each job has an associated pressure provided by the @lmake engine and the backend actually launches the eligible job with the highest pressure.
@end itemize

The required resources are provided by the @lmake engine to the backend as a @code{dict} which is the one of the job's rule after f-string interpretation.

The pressure is provided in the form of @code{float} computed as the accumulated ETE along the critical path to the final targets asked on the @lmake command line.
To do that, future job ETE have to be estimated.
For jobs that have already run, last successful execution time is used.
When this information is not available, i.e. when the job has never run successfully, a moving average of the execution times of the jobs sharing the same rule is used as a best guess.

The @lmake backend also provides the current ETA (@pxref{eta-estimation}) of the final targets to allow the backends from different repository to take the best collective decision.

As of now, the only existing backend is the local backend, but a Slurm backend is scheduled shortly.

In addition to dedicated resources, all backends manage the following 3 resources :
@itemize @minus
@item @code{cpu} : The number of threads the job is expected to run in parallel. The backend is expected to reserve enough resources for such a number of threads to run smoothly.
@item @code{mem} : The memory size the job is expected to need to run smoothly.
The backend is expected to ensure that such memory is available for the job.
Unit must be coherent with the one used in the configuration. It is MB by default.
@item @code{tmp} : The size of necessary temporary disk space.
@end itemize

@anchor{local-backend}
@section Local backend

The local backend launches jobs locally, on the host running the @lmake command.
Also, there is no cooperation between backends from different repositories and the user has to ensure there is no global resource conflict.

This backend is configured by providing entries in the @code{lmake.config.backends.local} @code{dict}.
The key identifies the resource and the value is a @code{int} that identifies a quantity.

Then, each rule whose @code{backend} attribute is @code{'local'} provides a @code{resources} attribute such that :
@itemize @minus
@item The key identifies a resource (which must match a resource in the configuration).
@item The value (possibly tailored by job through the use of the f-string syntax) is either
@itemize @minus
@item a @code{int} or a @code{str} that can be interpreted as  @code{int}
@item or a @code{str} of the form @code{'a<b'} where @code{a} and @code{b} can be interpreted as @code{int}
@end itemize
This later form instruct the local backend that as much as @code{b} resources is preferable, but @code{a} is enough to run the job.
@end itemize
The variable available to the job as global variables (python case) or environment variables (shell case) contains the actual quantity of resources allocated to this job.

The local backend ensures that the sum of all the resources of the running jobs never overshoot the configured available quantity.

By default, the configuration contains the 2 generic resources : @code{cpu} and @code{mem} configured respectively as the overall number of available cpus and the overall available memory (in MB).
@itemize @minus
@item @code{cpu} : The number of cpu as returned by @code{os.wched_getaffinity(0)}.
@item @code{mem} : The physical memory size as returned by @code{s.sysconf('SC_PHYS_PAGES')*os.sysconf('SC_PAGE_SIZE')} in MB.
@end itemize
Each rule has a default @code{resources} attribute requiring @code{1} @code{cpu}.

@anchor{autodep}
@section Autodep

Autodep is a mechanism through which jobs are spied to automatically detect which disk accesses are done.
From this information @lmake can determine if accesses were within the constraints provided by the rule and can list the hidden dependencies.

Several methods are available to spy jobs.
Not all methods are supported on all systems, though.

In all cases, the environment variable @code{LMAKE_AUTO_DEP_ENV} must remain in the environment untouched for the autodep mechanis to work correctly.

@subsection @code{'None'} or @code{'none'}

The job is not instrumented.
The only intrusion is the presence of the environment variable @code{LMAKE_AUTODEP_ENV}.

The only way to report activity is through the use of @code{ldepend} / @code{ltarget} or similar functions available in the @code{lmake} module.

The main advantage is that this method is not invasive (or marginally).
The main inconvenient is that no automatic hidden dependencies are recorded, one has to explicitely call @code{ldepend} and experience shows it is very difficult not to forget some.

This method is @strong{not} recommanded.

@subsection @code{'LdPreload'} or @code{'ld_preload'}

The job is run with a library loaded using the @code{LD_PRELOAD} environment variable that catches some calls to the @file{libc.so} (such as @code{open}) to track activity.
This environment variable may be modified as long as the librairy introduced by @lmake stays present.

This requires @file{libc.so} to be dynamically linked.

This method is very performant.

The main advantage is that this method is available even on rather old versions of Linux.
The main inconvenient is that it is somewhat invasive and there are cases of incompatibilities (e.g. the use of the @code{jemalloc} package).
Also, it will not run correctly if some commands have the @file{libc} statically linked and this will go undetected.

This method is recommanded on systems that lack the rtld-audit capability.

@subsection @code{'LdAudit'} or @code{'ld_audit'}

This method is similar to @code{ld_preload} except that the rtld-audit (through the @code{LD_AUDIT} environment variable) mechanism is used instead of @code{LD_PRELOAD},
which is less invasive (cases where it is not transparent are very awkward).
This environment variable may be modified as long as the librairy introduced by @lmake stays present.

This also requires @file{libc.so} to be dynamically linked but failure to do so can be detected and an error is generated, mandating the use of another method (except @code{ld_preload}).

The main advantage is that is is both performant, very little invasive and static linkage of @code{libc} is exceptional (and can be detected).
The main inconvenient is that it requires a rather recent version of Linux and there are cases of incompatibilites
(e.g. code written in @code{rust}, including the rust compilers @code{cargo} and @code{rustc}).

This method is recommanded on systems that support it.

@subsection @code{'Ptrace'} or @code{'ptrace'}

The job is run @code{ptrace}'ed. The seccomp mechanism is used to reduce the performance hit to the minimum possible but still, it is often unacceptable.
There is no requirement that @file{libc.so} be dynamically linked.
It is almost not invasive (mostly the job cannot use ptrace itself, i.e. you will not be able to run an executable level debugger).

Th main adavantage is that it works with a statically linked @code{libc}.
The main inconvenient is that the performance hit can be severe.

This method is recommanded as a fall back when the previous (@code{ld_preload} and @code{ld_audit}) methods cannot be used.

@anchor{link-support}
@section Link support
@lmake has several levels of symbolic link support :
@itemize @minus
@item If @code{'None'} or @code{'none'}, Symbolic links are not supported, no effort is done to resolve them.
@item If @code{'File'} or @code{'file'}, Symbolic links are supported only when they point to files (much like hard links), so intermediate directories are not checked for symbolic links.
@item If @code{'Full'} or @code{'full'}, All symbolic links are supported. This is the most secure but also the most heavy in terms of performance as all intermediate directories have to be checked.
@end itemize

@anchor{rule-selection}
@section Rule selection

When @lmake needs to ensure that a file is up to date, the first action is to identify which rule, if any, must be used to generate it.
This rule selection process works in several steps described below.

A file is deemed buildable if the rule selection process leads to a job that generates the file.

@subsection Up-hill directory
The first step is to see if a up-hill directory (i.e. one of the dirtory along the directory path leading to the file) is (recursively) buildable.

If it is the case, the rule selection process stops here and the file is not buildable. Else the process continue.

The rules are split into groups. Each group has either @code{Rule}'s, @code{AntiRule}'s  or @code{SourceRule}'s and contain all of them which share a given @code{prio}.
Groups are ordered with higher @code{prio} first and within each @code{prio}, @code{SourceRule}'s come first, then @code{AntiRule}'s then @code{Rule}'s.

The following steps is executed for each group in order, until a rule is found or the file declared not buildable.

@subsection Match a target
For a given rule, the file is matched against each target in turn.
Static targets are tried first in user order, then star targets in user order, and matching stops at the first match.

If a target matches, the matching defines the value of the static stems (i.e. the stems that appear without a @code{*}).
Else, the rule does not apply.

If the rule is an @code{AntiRule}, the rule selection process stops and the file is not buildable.

@subsection Check static dependencies

The definition of the static stems allow to compute :
@itemize @minus
@item The other targets of the rule. Static targets become the associated file, star targets becomes regular expressions in which static stems are expanded.
@item Static dependencies by interpreting them as f-strings in which static stems and targets are defined.
@end itemize

Static dependencies are then analyzed to see if the are (recursively) buildable, and if any is not buildable, the rule does not apply.

@subsection Group recap
After these 2 previous steps have been done for the rules of a group, the applicable rules are analyzed the following way :
@itemize
@item If no rule apply, next group is analyzed.
@item If the file matches several rules as a sure target (i.e. a static target or a star target with the @code{phony} flag),
the file is deemed buildable, but if required to run, no job will be executed and the file will be in error.
@item If the file matches some rules as a non-sure target (i.e. a star target without the @code{phony} flag), the corresponding jobs are run.
If no such jobs generate the file, next group is analyzed.
If several of them generate the file, the file is buildable and in error.
@end itemize

@anchor{critical-deps}
@section Critical deps

The question of critical deps is a performance only question. Semantically, whether a dep is critical or not has no impact on the content of the files built by @lmake.

During dependency analysis, when a dep (call it @file{dep1}) has been used and turns out to be out-of-date, @lmake must choose between 2 strategies regarding the deps that follow :
@itemize @bullet
@item
One possibility is to anticipate that the modification of @file{dep1} has no impact on the list of following deps.
With such an anticipation, @lmake will keep the following deps, i.e. when ensuring that deps are up-to-date before launching a job, @lmake will launch all necessary jobs to rebuild
all dependencies in parallel, even if the deps have been explicitely declared parallel.
@item
Another possivility is to anticipate that such a modification of @file{dep1} will drastically change the list of following deps.
With such an anticipation, as soone as @lmake sees a modified dep, it will stop its analysis as the following deps, acquired with an out-of-date content of @file{dep1} is meaningless.
@end itemize

The first strategy is speculative : launch everything you hear about, and we will see later what is useful.
The second strategy is conservative : build only what is certain to be required.

Generally speaking, a speculative approach is much better, but there are exceptions.

Typical use of critical deps is when you have a report that is built from the results of tests provided by a list of tests (a test suite).

For example, let's say you have :
@itemize @minus
@item 2 tests whose reports are built in @file{test1.rpt} and @file{test2.rpt} by some rather heavy means
@item a test suite @file{test_suite.lst} listing these reports
@item a rule that builds @file{test_suite.rpts} by collating reports listed in @file{test_suite.lst}
@end itemize

In such a situation, the rule building @file{test_suite.rpts} typically has @file{test_suite.lst} as a static dependency but the actual reports @file{test1.rpt} and @file{test2.rpt} are
hidden dependencies, i.e. automatically discovered when building @file{test_suite.rpts}.

Suppose now that you make a modification that makes @file{test2.rpt} very heavy to generate. Knowing that, you change your test_suite so list a lighter @file{test3.rpt} instead.
The succession of jobs would then be the following :
@itemize @minus
@item @file{test1.rpt} and @file{test2.rpt} are rebuilt as they are out-of-date after your modification.
@item @file{test_suite.rpts} is rebuilt to collate theses reports.
@item @lmake then sees that @file{test3.rpt} is needed instead of @file{test2.rpt}.
@item Hence, @file{test3.rpt} is (re)built.
@item @file{test_suite.rpts} is finally built from @file{test1.rpt} and @file{test3.rpt}.
@end itemize

There are 2 losses of performance here :
@itemize @minus
@item @file{test2.rpt} is unnecessarily rebuilt.
@item @file{test1.rpt} and @file{test3.rpt} are rebuilt sequentially.
@end itemize

The problem lies in the fact that @file{test1.rpt} and @file{test2.rpt} are rebuilt before @lmake had a chance to re-analyze the test suite showing that the new tests are test1 and test3.
Generally speaking, this is a good strategy : such modifications of the dependency graph happens rather rarely and speculating that it is pretty stable by building known dependencies before
launching a job is the right option.
But here, because collating is very light (something like just executing @code{cat} on the reports), it is better to check @file{tests_suilte.lst} first,
and if it changed, rerun the collation before ensuring (old) tests have run.

This is the purpose of the @code{critical} flag.
Such a flag can either be passed when declaring static deps in a rule, or dynamically using @code{lmake.depend} or @code{ldepend}.

The collating rule would look like :
@itemize @minus
@item Set the @code{critial} flag on @file{test_suite.lst} (before or after actually reading it, this has no impact).
@item Read @file{test_suite.lst}.
@item Call @code{ldepend} on the reports listed in @file{test_suite.lst}.
This is optional, just to generate parallel dependencies instead of automatic sequential dependencies (but if done, it must be before actually reading the reports).
@item Collate reports listed in @file{test_suite.lst}.
@end itemize

And the succession of job would be :
@itemize @minus
@item @file{test_suite.rpts} is rebuilt before analyzing @file{test1.rpt} and @file{test2.rpt} because @file{test_suite.lst} has changed.
@item @lmake sees that @file{test3.rpt} is needed instead of @file{test2.rpt}.
@item Hence, @file{test1.rpt} and @file{test3.rpt} are (re)built in parallel.
@item @file{test_suite.rpts} is finally built from @file{test1.rpt} and @file{test3.rpt}.
@end itemize

@anchor{hierarchical-repositories}
@section Hierarchical repositories

Hierarchical repositories are repositories that contain repositories, i.e. some @Lmakefile are present in sub-directories.

In that situation, it is reasonable to assume that the @Lmakefile are made to handle building files underneath it.

To support this situation, @lmake allow you to simply import these @Lmakefile and the @code{cwd} attributes will automatically be set to the right value so that :
@itemize
@item Targets only match within the sub-repo (and escape is possibly by setting the @code{top} flag to the target to provide global rules).
@item The same applies to deps.
@item @code{cmd} is run from this sub-repository, i.e. its cwd is set accordingly.
@item The priority of the rule is boosted by adding to it the directory depth of the sub-repository times @code{lmake.config.sub_prio_boost}.
@end itemize

@anchor{eta-estimation}
@section ETA estimation

An ETA estimation is made possible because the execution time for each job is recorded in @lmake book-keeping after all successful runs
(if a job ends in error, it may very well have been much faster and the previous execution time is probably a better estimate than this one).
When a job has never run successfully, an ETE is used instead of its actual execution time by taking a moving average of all the jobs of the same rule.

This being given, a precise ETA would require a fake execution of the jobs yet to be run which can take all dependencies and resources into account.
But this is way too expensive, so a faster process must be done, even at the expense of precision.

In all cases, the ETA assumes that no new hidden dependencies are discovered and that no file is steady so that all jobs currently remaining will actually be executed.

2 approaches can be considered to estimate the time necessary to carry out remaining jobs :
@itemize
@item Resources limited : dependencies are ignored, only resources are considered.
Roughly, the time is the division of the quantity of resources necessary by the quantity of resources available.
For example, if you need 10 minutes of processing and you have 2 cpus, this will last 10/2=5 minutes.
@item Dependencies limited : resources are ignored and only dependencies are considered. This means you only look at the critical path.
For example if you need to run a 2 minutes job followed by a 3 minutes job, and in parallel you must run a 4 minutes job, this will last 2+3=5 minutes.
@end itemize

@lmake uses the first approach. For that it must know the critical resource for each job.
This is the purpose of the @code{n_tokens} and @code{job_tokens} attributes of the rules.
Each job accounts for ETE*@code{job_tokens}/@code{n_tokens}, and all these are accumulated to produce an overall time.
The ETA is then the current time + this accumulated time.

@anchor{video-mode}
@section Video mode and colors

If lmake is connected to a terminal, then the terminal foreground and background colors are probed and if the brightness of the background color is less than that of the foreground color,
video mode is set to normal, else it is set to reverse.

In that case, lmake output is colored and the (configurable) color set is chosen depending on video mode.

@anchor{resource-buckets}
@section Resource buckets

It may be wise to quantify resources with relatively large steps for resources @code{mem} and @code{tmp}, especially if these may be computed with a formula.

The reason is linked to the way the backends select jobs.
When a backend (actually both the local backend and the slurm essentially work the same way) search for the next job to launch, it walk through the available jobs to
find the eligible one with the highest priority.
When doing that, only jobs with different resources need to be compared as for a given set of resources, they can be pre-ordered by priority.
As a consequence, the running time is proportional to the number of different resources.
If the @code{mem} and @code{tmp} needed space is computed from some metrics, it may be very well possible that each job has a different number, leading to a selection process
whose time is proportional to the number of waiting jobs, which can be very high (maybe millions).
To help reduce this overhead, one may want to put jobs into buckets with defined values for these resources.
This can be done with a sound formula to compute the values.
But as this is potentially important for @lmake itself, @lmake provides an easy means to achieve this goal by defining a given precision.
After all, you probably do not care if the reserved memory is 990MB or 1024MB.

The @code{config.backends.precisions} field allows you to easily define the adequate granularity. The larger this number, the finer the granularity.
A fine granularity allows a better use of the available resources.
A coarser graniularity allows a more efficient job selection process.
So the right answer is a sound balance between these two aspects.
A value of 4 or 8 is probably a reasonable value.

In presence of jobs with a high degree of parallelism requiring a lot of cpus, the same may be applied for the required number of cpus.

@anchor{tmp}
@section Mapping the temporary directory

Mapping the temporary directory feature is an answer to some situations which are apparently against the @lmake execution model.

@lmake sees jobs as having some inputs and generating some outputs.
But some tools operate on data (typically a directory) without making a distinction between input and output.

Imagine, for example you have 2 closely related tools :
@itemize
@item Let's call these 2 tools phase1 and phase2.
@item phase1 is used to prepare a directory, for example it generates some source files and put the result in the directory.
@item phase2 operates on this directory, for example it compiles the sources files prepared by phase1 and puts the compiled files next to the sources, in the same directory.
@item Suppose, in addition, that phase2 takes and argument, for example it may have several optimization levels for the compilation process.
@end itemize

Then, you want to organize your flow to have a first job using phase1, then several dependent jobs using phase2, potentially running in parallel.
One way to do that is to set up your flow the following way :
@itemize
@item Name the output of phase1 @file{phase1.out}
@item name the output of phases @file{phase2.arg.out} where @file{arg} may have several values.
@item In the rule to run phase1, simply drive it to generate its data in @file{phase1.out}.
@item In the rule to run phase 2, first copy @file{phase1.out} to @file{phase2.arg.out}, then use phase2 to operate on @file{phase2.arg.out}.
The copy process can be further optimized by linking in some situations, but his is not the purpose of this discussion.
@end itemize

This is fine, as long as copying the data is allowed.
Some tools store absolute paths in their own data, so that the copy of @file{phase1.out} to @file{phase2.arg.out} invalidates the data and makes them unusable.
In that case, a modified flow may be :
@itemize
@item In the rule to run phase1, drive it to generate its data in $TMPDIR, then copy $TMPDIR to @file{phase1.out}.
@item In the rule to run phase2, first copy @file{phase1.out} to $TMPDIR, then use phase2 to operate on $TMPDIR, then copy $TMPDIR to @file{phase2.arg.out}.
@end itemize

The problem is that the $TMPDIR used by phase1 may (and typically is) different from the $TMPDIR used for phase2.
This is not a bad @lmake design or a lack of luck, this is unavoidable if you want to run several instances of phase2 in parallel : they cannot all have the same $TMPDIR.

To face this situation, you can ask @lmake to arrange so that each of these jobs see $TMPDIR as a fixed name, for example /tmp, although the true underlying files are in different directories.
This way, the flow shown above works as expected.

This seems like an awkward situation, but is common practice in the CAD tools domain.

@chapter FAQ

@section How do I prevent @lmake to set dependencies to a given directory
Maybe somewhat counter-intuitive, the solution is to declare a target.
If you declare a target matching all files in your directory with the following flags :
@itemize @minus
@item @code{'-Match'} : this prevents matching on these files from other rules.
In exchange you gain a lot of flexibility (for example your are not obliged to specify all static stems).
@item @code{'-Dep'} : this prevents read matching files to become a dependency (as normally the case, even for a target).
This is the major goal of this target.
@item @code{'-Write'} : you may want to add this flag to consider writing to such files as an error, good if you are supposed to have read-only accesses.
@item @code{'Incremental'} : you may want to add this flag if, on the contrary, you want to allow the rule to do update (i.e. a read followed by a write) to matching files.
@item @code{'-Crc'} : good for peformance if you write a lot of files and these files are not going to be overwritten by a more official rule.
In the later case, not computing a checksum will prevent @lmake from detecting a steady file and this may trigger the spurious execution of a depending job.
@end itemize

@section @code{gcc} does not generate dependencies on some generated @file{.h} files, how to handle this ?
When @code{gcc} starts, it looks at all its include directories listed through options such as @code{-I} (@code{-iquote}, @code{-isystem} and @code{-idirafter}).
If a directory does not exist, it is removed from its internal list and when a file is included with @code{#include}, such directories are not tried.
As a consequence, no dep to files within these directories are generated.
To circumvent this adverse optimization done by @code{gcc}, all directories that lie in the repository must exist before @code{gcc} is started.
An easy way to ensure that by creating a dependency to a marker file within each such directory and to create a very simple rule that generates such marker file.

An exemple is shown here :

@example
@group
class Mrkr(lmake.Rule) :
	prio   = -lmake.inf         # in case of clash with another rule the other rule is perfect, as long as mrkr is not a directory
	target = '@{__dir__@}mrkr'
	cmd    = ''                 # target is open as its stdout, this is enough, we have nothing to put in the target
class Gcc(lmake.Rule) :
	targets = @{ 'OBJ' : '@{File:.+@}.o' @}
	deps    = @{ 'SRC' : '@{File:.+@}.c' @}
	cmd     = 'ldepend a/mrkr b/mrkr c/mrkr ; gcc -Ia -Ib -Ic -c -o $OBJ $SRC'
@end group
@end example

@XXX{to be completed}

@chapter Glossary

@table @asis
@item CAD
Computer Aided Design.
A domain used to produce various objects, in partiulcar integrated ciruits, characterized by heavy processing and complex flows.
@item diamond rule
A feature of Python that allows the following behavior :
@itemize
@item A class @code{D} inherits from @code{B} and @code{C} in that order.
@item Both @code{B} and @code{C} inherit from a class @code{A}.
@item A method @code{m} is defined on @code{A} and @code{C} but not on @code{B}.
@item Then if @code{m} is called from an instance of @code{D}, @code{C.m} will be called and not @code{B.m} (which turns out to be @code{A.m}).
@end itemize
This feature is a central point that makes Python multiple inheritance easy to use and enables the class hierarchy shopping list style.
@item ETA
Estimated Time of Arrival. This is the date at which a given event (such as a job being completed) is estimated to occur.
@item ETE
Estimated Time En route. This is the remaining time necessary to complete a task.
@item LRU
Least Recently Used. A classical cache replacement policy where the entry that was least recently used is discarded when a new one is allocated.
@item MRO
Method Research Order, the inheritance chain from the current class to its most basic base, usually @code{object}.
Python computes the MRO in such a way as to enforce the diamond rule.
@end table

@bye
